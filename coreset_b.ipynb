{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263ea903",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Use CORESET to enlarge differences among samples rather than sampling from uncertain words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d6bdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Label\n",
    "# 0: Physical\n",
    "# 1: Mental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce8e00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c17ec4e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To use nltk's wordnet, you should download WordNet from https://www.nltk.org/nltk_data/ and then unzip wordnet.zip\n",
    "under your home directory with path as /home_path/nltk_data/corpora/\n",
    "\n",
    "'''\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "60a7854f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext as ft\n",
    "# we use fasttext embedding vector to represent word\n",
    "# As 'cc.en.300.bin' is very large, it is not included in the submission. Download URL: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
    "# Check more details in website: https://fasttext.cc/docs/en/crawl-vectors.html\n",
    "\n",
    "model=ft.load_model('source/cc.en.300.bin') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a54ce25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7292, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj=pd.read_csv('Data/adj.csv') # load adjectives from `high_entropy.ipynb`\n",
    "adj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5503d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "028f5577",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "testset=pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3531c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CORESET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eb381",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    All labeling steps below are implemented by two persons. If the labeling results disagree, we ask a third person to arbitrate.\n",
    "    \n",
    "    In iteration T, The L2 distance of each valid adjective against each training samples used in iteration T-1 is computed and the max distance of each valid adjective is recorded. Lastly, by sorting according to max distance descendly, we choose the topK words and join them to the training samples used in iteration T-1 as training samples of iteration T. We will repeat this process for some times in iteration T. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "579c17ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "topK=10 \n",
    "repeat=12 # repeat times\n",
    "batch_size=1500 # candset batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8da083aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# find samples given core words by CORESET strategy\n",
    "def points2points_l2_norm(m1,m2):\n",
    "    # return point-wise L2 distance\n",
    "    # `m1` ndarray [N,D]\n",
    "    # `m2` ndarray [M,D]\n",
    "\n",
    "    N = m1.shape[0]\n",
    "    M=m2.shape[0]\n",
    "    m1 = np.expand_dims(m1, axis=0)\n",
    "    m1 = np.repeat(m1, repeats=M, axis=0)  # [M,N,D]\n",
    "\n",
    "    m2 = np.expand_dims(m2, axis=1)  # [M,1,D]\n",
    "    m2 = np.repeat(m2, repeats=N, axis=1)  # [M,N,D]\n",
    "\n",
    "    dist = np.sqrt(np.sum((m1 - m2) * (m1 - m2), axis=2).T)  # [N,M]\n",
    "\n",
    "    return dist\n",
    "\n",
    "def find_samples(cands,cores,model,topk,only_words=True):\n",
    "    # return word list or tuple(word,score)\n",
    "    \n",
    "    # get embeddings\n",
    "    core_emb=[]\n",
    "    for w in cores:\n",
    "        emb=model.get_word_vector(w).reshape((1,-1))\n",
    "        core_emb.append(emb)\n",
    "    core_emb=np.concatenate(core_emb,axis=0)\n",
    "\n",
    "    cand_emb=[]\n",
    "    for w in cands:\n",
    "        try:\n",
    "            emb=model.get_word_vector(w).reshape((1,-1))\n",
    "        except:\n",
    "            print(\"#%s# failed to get embedding. \"%w)\n",
    "            emb=np.zeros((1,300))\n",
    "        cand_emb.append(emb)\n",
    "    cand_emb=np.concatenate(cand_emb,axis=0)\n",
    "    \n",
    "    # calculate L2 distance\n",
    "    dist=points2points_l2_norm(cand_emb,core_emb)\n",
    "\n",
    "    min_d=dist.min(axis=1)\n",
    "\n",
    "    q=[]\n",
    "    for w,d in zip(cands,min_d):\n",
    "        q.append((w,d))\n",
    "\n",
    "    q.sort(key=lambda x: -x[1])\n",
    "    \n",
    "    if only_words:\n",
    "        res=[x[0] for x in q]\n",
    "        return res[:topk]\n",
    "    else:\n",
    "        return q[:topk]\n",
    "\n",
    "def find_samples_batch(cands,cores,model,topk,batch_size,only_words=True):\n",
    "    '''\n",
    "    Split cands into batches to make distance computing available in memory. \n",
    "    [len(cands),len(cores)] tensor -> [len(batch_size),len(cores)] * batch_num\n",
    "    '''\n",
    "    # return word list or tuple(word,score) \n",
    "    q=[]\n",
    "    \n",
    "    N=len(cands)//batch_size+1\n",
    "    for i in range(N):\n",
    "        _cands=cands[i*batch_size:(i+1)*batch_size]\n",
    "        if len(_cands)==0:\n",
    "            continue\n",
    "        q+=find_samples(_cands,cores,model,topk,only_words=False)\n",
    "        \n",
    "    q.sort(key=lambda x: -x[1])\n",
    "    \n",
    "    if only_words:\n",
    "        res=[x[0] for x in q]\n",
    "        return res[:topk]\n",
    "    else:\n",
    "        return q[:topk]  \n",
    "\n",
    "\n",
    "# initialize candidate set\n",
    "# candidate words are from all valid adjectives except testset\n",
    "adj_cand=[]\n",
    "for w in adj['word']:\n",
    "    if w not in testset['word']:\n",
    "        adj_cand.append(w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661e6a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57357354",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d7415d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly annotate some positive and negative words for training. Proportion of samples, 1:1\n",
    "# `desc`: `physical` adj, describe physical attributes\n",
    "# `opin`: `mental` adj, usually relates to mental attributes\n",
    "\n",
    "desc=['anemic','arranged','assorted','available','baked','bitter','black','blue','broken','cherry',\n",
    "      'citric','corrugated','commercial','cooked','crispy','crushed','crusty','decorative','dietetic',\n",
    "     'digestible','dried','drippy','edible','empty','fake']\n",
    "opin=['amazing','awesome','awful','aware','bad','basic','beneficial','best','bold','bothersome','careful',\n",
    "      'casual','certain','cheap','clean','clear','cold','comfortable','common','comparable','competitive',\n",
    "     'complete','consistent','contributive','convenient','conventional','cool','costly','crazy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe88baf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_type='adj'\n",
    "trainset=[]\n",
    "        \n",
    "for w in desc:\n",
    "    defn=adj.loc[adj.word==w,'text'].values[0]\n",
    "    trainset.append((w,defn,0)) # 0: physical\n",
    "    \n",
    "for w in opin:\n",
    "    defn=adj.loc[adj.word==w,'text'].values[0]\n",
    "    trainset.append((w,defn,1)) # 1: mental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5407d14b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.DataFrame()\n",
    "train['word'],train['text'],train['target']=list(zip(*(trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6115e57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv('Data/train.v4.1.round1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914824b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is not done until iter 3. As sampling is only dependent on word embedding vector, there's no need to\n",
    "    do training for iter1 and iter2. Total iteration number is 5 for comparison with other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4c7b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258419d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "680c4229",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG=False # True: do debug and unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d558f1b2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cores=train['word'].tolist() # use words in train from last iteration as initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd449ba0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "21 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "22 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "23 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "24 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "25 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "26 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "27 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "28 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "29 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "30 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "31 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "32 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "33 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "34 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "35 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "36 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "37 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "38 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "39 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "40 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "41 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "42 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "43 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "44 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "45 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "46 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "47 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "48 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "49 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "50 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "51 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "52 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "53 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "54 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "55 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "56 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "57 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "58 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "59 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "60 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "61 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "62 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "63 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "64 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "65 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "66 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "67 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "68 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "69 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "70 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "71 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "72 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "73 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "74 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "75 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "76 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "77 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "78 birth_loop.\n",
      "#nan# failed to get embedding. \n",
      "79 birth_loop.\n",
      "#nan# failed to get embedding. \n"
     ]
    }
   ],
   "source": [
    "# detect all low_freq words and put them into cores\n",
    "\n",
    "# we start from 0 to 19 and then from 20 to 79\n",
    "birth_start=20\n",
    "birth_loop=60\n",
    "\n",
    "low_freq={}\n",
    "# birth run to inclue noise words into cores\n",
    "for i in range(birth_start,birth_start+birth_loop): \n",
    "    print('%d birth_loop.'%i)\n",
    "    # main action\n",
    "    _new=find_samples_batch(cands=adj_cand,cores=cores,model=model,\n",
    "                       topk=topK,batch_size=batch_size, only_words=True)\n",
    "    \n",
    "    # update states\n",
    "    cores+=_new\n",
    "    \n",
    "    low_freq[i]=_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "86500cac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['xc', 'xl', 'xx', 'gi', '64', 'iv', 'x', '59'],\n",
       " 1: ['il', '0', 'm', 'ex', 'v', 'k', 'gu', 'li'],\n",
       " 2: ['u', 'c', 'd', 'i', '99', '90', '95', 'up'],\n",
       " 3: ['no', 'l', '1', 'ok', 'go', 'on', '2', '3'],\n",
       " 4: ['in', '50', 'hep', 'xxx', '65', '69', '73', 'sec'],\n",
       " 5: ['rum', 'cod', 'otc', 'jet', 'dim', 'fey', 'neo', 'hip'],\n",
       " 6: ['18', 'lax', 'gay', 'fat', 'dun', 'pet', 'nee', 'nth'],\n",
       " 7: ['uric', 'ace', 'coy', 'bay', '9th', 'lit', 'pat', 'manx'],\n",
       " 8: ['mid', 'shy', '170', 'fly', '140', '145', 'tan', 'mum'],\n",
       " 9: ['net', '30', 'pro', 'ago', 'otic', 'ill', 'gaga', 'gamy'],\n",
       " 10: ['raw', 'apt', '39', 'bum', '96', 'wee', 'pop', 'mown'],\n",
       " 11: ['fab', 'dud', 'echt', 'icy', 'sly', '32', 'dank', '75'],\n",
       " 12: ['ver', 'wet', '31', 'lay', 'deaf', 'pied', 'lewd', 'achy'],\n",
       " 13: ['9', 'low', 'ten', 'hind', 'cut', '75th', 'sear', 'rust'],\n",
       " 14: ['key', 'wan', 'oral', 'fit', '45', 'ashy', 'bated', 'rapt'],\n",
       " 15: ['foul', 'won', 'thai', 'wiry', 'saudi', 'off', 'inky', 'gory'],\n",
       " 16: ['drab', 'boxy', '89', 'avid', 'spry', 'anal', 'sad', 'luxe'],\n",
       " 17: ['awry', 'hot', 'ruby', 'meek', 'puff', 'top', 'beta', 'natal'],\n",
       " 18: ['due', 'humic', 'salt', 'strep', 'arid', 'dry', 'sewn', 'dyed'],\n",
       " 19: ['bush', 'nude', 'bald', 'molar', 'mono', 'deft', 'buff', 'idle']}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9b7fdfed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{20: ['eyed', 'waxy', 'carpal', 'rash', 'big', 'oozy', 'anti', 'old'],\n",
       " 21: ['loamy', 'rosy', 'few', 'far', 'nosy', 'mint', 'jade', 'numb'],\n",
       " 22: ['skim', 'cosy', 'cest', 'aged', 'cubic', 'bias', 'algal', 'oily'],\n",
       " 23: ['saute', 'cyan', 'wavy', 'tall', 'bone', '98', '44', 'unfed'],\n",
       " 24: ['odd', 'sage', 'gouty', 'wroth', 'limp', 'slim', '10', 'rank'],\n",
       " 25: ['fetal', 'own', 'born', 'smug', 'halal', 'calm', 'wily', 'rife'],\n",
       " 26: ['potty', 'holy', 'welsh', 'hazy', 'peppy', 'out', '60', 'iron'],\n",
       " 27: ['airy', 'port', 'amino', 'hazel', 'damp', 'solo', 'ripe', 'snug'],\n",
       " 28: ['fecal', 'oaken', 'mute', '80', 'teen', 'twin', 'bare', 'cuban'],\n",
       " 29: ['parve', 'dirt', 'oval', 'loud', 'boggy', 'peaty', 'mass', 'rude'],\n",
       " 30: ['rose', 'tarry', 'yogic', 'rear', 'camp', 'nasal', 'boric', 'posh'],\n",
       " 31: ['moot', 'musky', '19th', 'new', 'liege', 'polar', 'lush', 'spiny'],\n",
       " 32: ['tannic', 'nappy', 'ionic', 'star', 'worn', 'gelid', 'pale', 'dire'],\n",
       " 33: ['edgy', 'renal', 'acid', 'tidal', 'winy', 'set', 'sole', 'mealy'],\n",
       " 34: ['gold', 'rawer', 'optic', 'east', 'briny', 'tart', 'deep', 'hmong'],\n",
       " 35: ['lunar', 'trim', 'any', 'lazy', 'sudsy', 'sore', 'male', 'shed'],\n",
       " 36: ['lean', 'nigh', 'grim', 'puny', 'gamey', 'mild', 'silty', 'mad'],\n",
       " 37: ['downy', 'self', 'prima', '23', 'mock', 'vain', '500th', 'gassy'],\n",
       " 38: ['flip', 'two', 'boss', 'dryer', 'nonfat', '25', 'sable', 'texan'],\n",
       " 39: ['beady', 'evil', 'lone', 'raspy', 'blest', 'filmy', 'shut', 'faux'],\n",
       " 40: ['85', 'tied', 'dear', 'swiss', 'spayed', 'jerky', 'teary', 'oiled'],\n",
       " 41: ['bushy', 'tame', 'corned', 'dual', 'rich', 'chic', 'tonal', 'gummy'],\n",
       " 42: ['enteral',\n",
       "  'tippy',\n",
       "  'adagio',\n",
       "  'thin',\n",
       "  'hardy',\n",
       "  'ungreased',\n",
       "  'scaly',\n",
       "  'fatty'],\n",
       " 43: ['bent', '12', 'balmy', 'fizzy', 'lite', 'size', 'viral', 'humid'],\n",
       " 44: ['waxed', 'pussy', 'gusty', 'barky', 'wooly', 'olive', '135th', 'riper'],\n",
       " 45: ['tops', '91', 'dull', 'glace', 'fusty', 'pulpy', 'musty', 'sexy'],\n",
       " 46: ['2nd', 'tarter', 'firm', 'solar', 'slow', 'undue', 'scurvy', 'nosed'],\n",
       " 47: ['aural', 'mined', 'fetid', 'foamy', 'greek', 'vast', 'roman', 'nuts'],\n",
       " 48: ['uncut', '51', 'wide', 'void', 'avian', 'sane', 'mini', '63'],\n",
       " 49: ['boney', 'mirky', 'styptic', 'epic', 'mere', 'irish', 'plumb', 'ionian'],\n",
       " 50: ['steep', 'valved', 'atrial', 'itchy', 'vestal', 'fond', 'sour', 'dizzy'],\n",
       " 51: ['obese', 'pubic', 'mossy', 'shot', 'pure', '45th', 'rush', 'smoky'],\n",
       " 52: ['torn', 'syrian', 'lucid', 'daft', 'tubed', 'limper', 'driest', 'zero'],\n",
       " 53: ['corked', 'nubby', 'sign', '35', 'laid', 'malted', '55', 'seedy'],\n",
       " 54: ['leafy',\n",
       "  'mucous',\n",
       "  'peptic',\n",
       "  'celiac',\n",
       "  'woody',\n",
       "  'sick',\n",
       "  'sapid',\n",
       "  'footed'],\n",
       " 55: ['campy', 'rare', 'agile', 'baggy', 'indie', 'amber', 'naval', 'webby'],\n",
       " 56: ['baltic',\n",
       "  'sandy',\n",
       "  'silken',\n",
       "  'slavic',\n",
       "  'feral',\n",
       "  'vinous',\n",
       "  'zesty',\n",
       "  'busy'],\n",
       " 57: ['88', 'weedy', 'umber', 'leaky', 'purer', 'flat', 'red', 'needy'],\n",
       " 58: ['septic', 'tiled', 'tiny', 'piggy', 'resiny', 'catty', 'taboo', 'runny'],\n",
       " 59: ['tonic', 'tinny', 'fair', 'lithe', 'gonzo', 'milky', 'tense', 'turbid'],\n",
       " 60: ['spinal', 'meet', 'vile', 'necked', 'soft', 'toned', 'frizzy', 'cuter'],\n",
       " 61: ['asian',\n",
       "  'gilled',\n",
       "  'attic',\n",
       "  'perkier',\n",
       "  'postal',\n",
       "  'vulvar',\n",
       "  'huffy',\n",
       "  'lest'],\n",
       " 62: ['frail', 'wavier', 'poor', 'base', 'bumpy', 'unfit', 'scrub', 'birch'],\n",
       " 63: ['nitric', 'lurid', 'icky', 'mated', 'dutch', 'away', 'sorrel', 'dead'],\n",
       " 64: ['coral', 'liver', 'suave', 'nippy', 'dazed', 'glued', 'snowy', 'civic'],\n",
       " 65: ['fiver', 'furry', 'safe', 'stale', 'sworn', 'sneak', 'plummy', 'paid'],\n",
       " 66: ['buggy',\n",
       "  'whiny',\n",
       "  'shaven',\n",
       "  'beat',\n",
       "  'boozy',\n",
       "  'stout',\n",
       "  'edged',\n",
       "  'enteric'],\n",
       " 67: ['nervy', 'laced', 'tuscan', 'pushy', 'ripest', '5', 'straw', 'cured'],\n",
       " 68: ['comic', 'pasty', 'aloof', 'wild', 'alien', 'unkept', 'mussy', 'brushy'],\n",
       " 69: ['gamier', 'latin', '94', 'pudgy', 'wheezy', 'alpha', 'firmest', 'vivid'],\n",
       " 70: ['gross', 'zany', 'lame', 'brute', 'larval', 'grave', 'juicy', 'sold'],\n",
       " 71: ['minty', 'aired', 'rowdy', 'keen', 'wispy', 'witty', 'upwind', 'olden'],\n",
       " 72: ['hipped',\n",
       "  'truer',\n",
       "  'floury',\n",
       "  'weak',\n",
       "  'cystic',\n",
       "  'merry',\n",
       "  'kenyan',\n",
       "  'gluey'],\n",
       " 73: ['game',\n",
       "  'fossil',\n",
       "  'airier',\n",
       "  'pearly',\n",
       "  'ferric',\n",
       "  'brindle',\n",
       "  'hurt',\n",
       "  'spicer'],\n",
       " 74: ['sissy', 'drafty', 'gushy', 'late', 'sappy', 'moist', 'honey', 'dark'],\n",
       " 75: ['vocal', 'fast', 'perky', 'stern', 'civil', 'royal', 'horny', 'ruddy'],\n",
       " 76: ['ebony', 'fishy', 'sent', 'bully', 'warm', 'high', 'stark', 'silky'],\n",
       " 77: ['sheer',\n",
       "  'palatal',\n",
       "  'matte',\n",
       "  'matted',\n",
       "  'arable',\n",
       "  'side',\n",
       "  'rudest',\n",
       "  'risen'],\n",
       " 78: ['plane',\n",
       "  'rectal',\n",
       "  'rabid',\n",
       "  'fatal',\n",
       "  'squat',\n",
       "  'median',\n",
       "  'neural',\n",
       "  'inert'],\n",
       " 79: ['kept', 'eerie', '37', 'slimy', 'areal', 'andean', 'one', 'unripe']}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a4543a20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save for future backup\n",
    "\"\"\"with open(\"Data/coreset_low_freq.json\", \"w\") as outfile:\n",
    "    json.dump(low_freq, outfile)\n",
    "    \n",
    "with open(\"Data/coreset_cores_iter2.json\", \"w\") as outfile:\n",
    "    json.dump(cores, outfile)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e6154",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    From above result, iter0-19(160 words) in `low_freq` are regarded as noisy words. As the embedding vectors of these noisy words are usually very far from normal words, if they were not included in `core`, we would pick them up for annotation, which is not desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "58d7fd53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9f7a0f3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 repeat.\n",
      "#nan# failed to get embedding. \n",
      "1 repeat.\n",
      "#nan# failed to get embedding. \n",
      "2 repeat.\n",
      "#nan# failed to get embedding. \n",
      "3 repeat.\n",
      "#nan# failed to get embedding. \n",
      "4 repeat.\n",
      "#nan# failed to get embedding. \n",
      "5 repeat.\n",
      "#nan# failed to get embedding. \n",
      "6 repeat.\n",
      "#nan# failed to get embedding. \n",
      "7 repeat.\n",
      "#nan# failed to get embedding. \n",
      "Runtime: 29.55 sec\n"
     ]
    }
   ],
   "source": [
    "# sampling states\n",
    "new_samples=[] # samples extracted out in this iteration\n",
    "\n",
    "# remove iter 20-79 words in cores, only keep words in iter1 and noise words\n",
    "for i in range(20,80):\n",
    "    for w in low_freq[i]:\n",
    "        if w in cores:\n",
    "            cores.remove(w)\n",
    "        \n",
    "if DEBUG: # only for debug and unit test\n",
    "    d_samples={}\n",
    "\n",
    "start=time.time()\n",
    "for i in range(repeat): \n",
    "    print('%d repeat.'%i)\n",
    "    # main action\n",
    "    _new=find_samples_batch(cands=adj_cand,cores=cores,model=model,\n",
    "                       topk=topK,batch_size=batch_size, only_words=True)\n",
    "    \n",
    "    # update states\n",
    "    new_samples+=_new\n",
    "    cores+=_new\n",
    "    \n",
    "    if DEBUG:\n",
    "        d_samples[i]=_new\n",
    "dur=time.time()-start\n",
    "print(\"Runtime: %.2f sec\"%dur)\n",
    "\n",
    "# after sampling, the `new_samples` will be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "57504ad3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc2=['eyed','waxy','carpal','rash','big','oozy','far','mint','jade',\n",
    "       'skim','cubic','oily','saute','cyan','wavy','tall','bone','welsh',\n",
    "      'hazy','iron','damp']\n",
    "\n",
    "opin2=['anti','rosy','few','nosy','numb','aged','bias','wroth','own',\n",
    "       'smug','calm','wily','rife','potty','holy','peppy','rude','tarry',\n",
    "      'dire','lazy']\n",
    "\n",
    "\n",
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc2+opin2:\n",
    "    if w in testset['word']:\n",
    "        print(w)\n",
    "\n",
    "desc_all=desc+desc2\n",
    "opin_all=opin+opin2\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train2=pd.DataFrame()\n",
    "train2['word'],train2['text'],train2['target']=list(zip(*(trainset)))\n",
    "\n",
    "train2.to_csv('Data/train.v4.2.round2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13fc4f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is done by `train.py`. Remember setting Config.is_predict=False before training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2638963",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31b6249",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred=joblib.load('Data/pred.v4.2.round2') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aef732b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.575\n",
      "positive::recall 0.639\n",
      "negative::precision 0.783\n",
      "negative::recall 0.734\n",
      "F1: 0.61\n",
      "N F1: 0.76\n"
     ]
    }
   ],
   "source": [
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aabcf5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb241fa",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b541d5fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG=False # True: do debug and unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "97267a01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 repeat.\n",
      "#nan# failed to get embedding. \n",
      "1 repeat.\n",
      "#nan# failed to get embedding. \n",
      "2 repeat.\n",
      "#nan# failed to get embedding. \n",
      "3 repeat.\n",
      "#nan# failed to get embedding. \n",
      "4 repeat.\n",
      "#nan# failed to get embedding. \n",
      "5 repeat.\n",
      "#nan# failed to get embedding. \n",
      "6 repeat.\n",
      "#nan# failed to get embedding. \n",
      "7 repeat.\n",
      "#nan# failed to get embedding. \n",
      "8 repeat.\n",
      "#nan# failed to get embedding. \n",
      "9 repeat.\n",
      "#nan# failed to get embedding. \n",
      "10 repeat.\n",
      "#nan# failed to get embedding. \n",
      "11 repeat.\n",
      "#nan# failed to get embedding. \n",
      "Runtime: 73.86 sec\n"
     ]
    }
   ],
   "source": [
    "# sampling states\n",
    "new_samples=[] # samples extracted out in this iteration\n",
    "        \n",
    "if DEBUG: # only for debug and unit test\n",
    "    d_samples={}\n",
    "\n",
    "start=time.time()\n",
    "for i in range(repeat): \n",
    "    print('%d repeat.'%i)\n",
    "    # main action\n",
    "    _new=find_samples_batch(cands=adj_cand,cores=cores,model=model,\n",
    "                       topk=topK,batch_size=batch_size, only_words=True)\n",
    "    \n",
    "    # update states\n",
    "    new_samples+=_new\n",
    "    cores+=_new\n",
    "    \n",
    "    if DEBUG:\n",
    "        d_samples[i]=_new\n",
    "dur=time.time()-start\n",
    "print(\"Runtime: %.2f sec\"%dur)\n",
    "\n",
    "# after sampling, the `new_samples` will be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d0dd0d99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lean\n",
      "nigh\n",
      "grim\n",
      "puny\n",
      "gamey\n",
      "mild\n",
      "silty\n",
      "mad\n",
      "downy\n",
      "self\n",
      "prima\n",
      "23\n",
      "mock\n",
      "vain\n",
      "500th\n",
      "gassy\n",
      "flip\n",
      "two\n",
      "boss\n",
      "dryer\n",
      "nonfat\n",
      "25\n",
      "sable\n",
      "texan\n",
      "beady\n",
      "evil\n",
      "lone\n",
      "raspy\n",
      "blest\n",
      "filmy\n",
      "shut\n",
      "faux\n",
      "85\n",
      "tied\n",
      "dear\n",
      "swiss\n",
      "spayed\n",
      "jerky\n",
      "teary\n",
      "oiled\n",
      "bushy\n",
      "tame\n",
      "corned\n",
      "dual\n",
      "rich\n",
      "chic\n",
      "tonal\n",
      "gummy\n",
      "enteral\n",
      "tippy\n",
      "adagio\n",
      "thin\n",
      "hardy\n",
      "ungreased\n",
      "scaly\n",
      "fatty\n",
      "bent\n",
      "12\n",
      "balmy\n",
      "fizzy\n",
      "lite\n",
      "size\n",
      "viral\n",
      "waxed\n",
      "pussy\n",
      "gusty\n",
      "barky\n",
      "wooly\n",
      "olive\n",
      "135th\n",
      "riper\n",
      "tops\n",
      "91\n",
      "dull\n",
      "glace\n",
      "fusty\n",
      "pulpy\n",
      "musty\n",
      "sexy\n",
      "2nd\n",
      "tarter\n",
      "firm\n",
      "solar\n",
      "slow\n",
      "undue\n",
      "scurvy\n",
      "nosed\n",
      "aural\n",
      "mined\n",
      "fetid\n",
      "foamy\n",
      "greek\n",
      "vast\n",
      "roman\n",
      "nuts\n",
      "uncut\n",
      "51\n",
      "wide\n",
      "void\n",
      "avian\n",
      "sane\n",
      "mini\n",
      "63\n",
      "boney\n",
      "mirky\n",
      "styptic\n",
      "epic\n",
      "mere\n",
      "irish\n",
      "plumb\n",
      "ionian\n",
      "steep\n",
      "valved\n",
      "atrial\n",
      "itchy\n",
      "vestal\n",
      "fond\n",
      "sour\n",
      "dizzy\n",
      "obese\n"
     ]
    }
   ],
   "source": [
    "for w in new_samples:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "112cf7af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc3=['lean','nigh','silty','downy','prima','23','500th','gassy','flip',\n",
    "       'dryer','nonfat','sable','texan','beady','filmy','shut','faux','tied',\n",
    "      'swiss','jerky','oiled','corned','tonal','gummy','roman']\n",
    "\n",
    "opin3=['grim','puny','gamey','mild','mad','mock','vain','evil','lone',\n",
    "       'raspy','blest','dear','teary','tame','rich','chic','balmy','dull',\n",
    "      'sexy','sane','itchy','fond','dizzy']\n",
    "\n",
    "\n",
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc3+opin3:\n",
    "    if w in testset['word']:\n",
    "        print(w)\n",
    "\n",
    "desc_all=desc+desc2+desc3\n",
    "opin_all=opin+opin2+opin3\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train3=pd.DataFrame()\n",
    "train3['word'],train3['text'],train3['target']=list(zip(*(trainset)))\n",
    "\n",
    "train3.to_csv('Data/train.v4.3.round3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8c12f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c56ff0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.575\n",
      "positive::recall 0.639\n",
      "negative::precision 0.783\n",
      "negative::recall 0.734\n",
      "F1: 0.61\n",
      "N F1: 0.76\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.3.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b7e396d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"Data/coreset_cores_iter3.json\", \"w\") as outfile:\n",
    "    json.dump(cores, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267cd83a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RunTwoMore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa5958",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We only provide the evaluation results of another two runs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c874fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.615\n",
      "positive::recall 0.889\n",
      "negative::precision 0.917\n",
      "negative::recall 0.688\n",
      "F1: 0.73\n",
      "N F1: 0.79\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.3.2.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56ccfde5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.667\n",
      "positive::recall 0.833\n",
      "negative::precision 0.891\n",
      "negative::recall 0.766\n",
      "F1: 0.74\n",
      "N F1: 0.82\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.3.3.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17bf5c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0678d47e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "b692db05",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 repeat.\n",
      "#nan# failed to get embedding. \n",
      "1 repeat.\n",
      "#nan# failed to get embedding. \n",
      "2 repeat.\n",
      "#nan# failed to get embedding. \n",
      "3 repeat.\n",
      "#nan# failed to get embedding. \n",
      "4 repeat.\n",
      "#nan# failed to get embedding. \n",
      "5 repeat.\n",
      "#nan# failed to get embedding. \n",
      "6 repeat.\n",
      "#nan# failed to get embedding. \n",
      "7 repeat.\n",
      "#nan# failed to get embedding. \n",
      "8 repeat.\n",
      "#nan# failed to get embedding. \n",
      "9 repeat.\n",
      "#nan# failed to get embedding. \n",
      "10 repeat.\n",
      "#nan# failed to get embedding. \n",
      "11 repeat.\n",
      "#nan# failed to get embedding. \n",
      "Runtime: 98.67 sec\n"
     ]
    }
   ],
   "source": [
    "DEBUG=False # True: do debug and unit test\n",
    "\n",
    "# sampling states\n",
    "new_samples=[] # samples extracted out in this iteration\n",
    "        \n",
    "if DEBUG: # only for debug and unit test\n",
    "    d_samples={}\n",
    "\n",
    "start=time.time()\n",
    "for i in range(repeat): \n",
    "    print('%d repeat.'%i)\n",
    "    # main action\n",
    "    _new=find_samples_batch(cands=adj_cand,cores=cores,model=model,\n",
    "                       topk=topK,batch_size=batch_size, only_words=True)\n",
    "    \n",
    "    # update states\n",
    "    new_samples+=_new\n",
    "    cores+=_new\n",
    "    \n",
    "    if DEBUG:\n",
    "        d_samples[i]=_new\n",
    "dur=time.time()-start\n",
    "print(\"Runtime: %.2f sec\"%dur)\n",
    "\n",
    "# after sampling, the `new_samples` will be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "4809db7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubic\n",
      "mossy\n",
      "shot\n",
      "pure\n",
      "45th\n",
      "rush\n",
      "smoky\n",
      "torn\n",
      "syrian\n",
      "lucid\n",
      "daft\n",
      "tubed\n",
      "limper\n",
      "driest\n",
      "zero\n",
      "corked\n",
      "nubby\n",
      "sign\n",
      "35\n",
      "laid\n",
      "malted\n",
      "seedy\n",
      "leafy\n",
      "mucous\n",
      "peptic\n",
      "celiac\n",
      "woody\n",
      "sick\n",
      "sapid\n",
      "footed\n",
      "campy\n",
      "rare\n",
      "agile\n",
      "baggy\n",
      "indie\n",
      "amber\n",
      "naval\n",
      "webby\n",
      "baltic\n",
      "sandy\n",
      "silken\n",
      "feral\n",
      "vinous\n",
      "zesty\n",
      "busy\n",
      "88\n",
      "resiny\n",
      "weedy\n",
      "umber\n",
      "rainy\n",
      "leaky\n",
      "purer\n",
      "flat\n",
      "red\n",
      "needy\n",
      "septic\n",
      "tiled\n",
      "tiny\n",
      "piggy\n",
      "catty\n",
      "taboo\n",
      "runny\n",
      "tonic\n",
      "tinny\n",
      "fair\n",
      "lithe\n",
      "gonzo\n",
      "milky\n",
      "tense\n",
      "turbid\n",
      "spinal\n",
      "meet\n",
      "vile\n",
      "necked\n",
      "soft\n",
      "toned\n",
      "frizzy\n",
      "cuter\n",
      "asian\n",
      "gilled\n",
      "attic\n",
      "perkier\n",
      "postal\n",
      "vulvar\n",
      "huffy\n",
      "lest\n",
      "slavic\n",
      "frail\n",
      "wavier\n",
      "poor\n",
      "base\n",
      "bumpy\n",
      "unfit\n",
      "scrub\n",
      "birch\n",
      "nitric\n",
      "lurid\n",
      "icky\n",
      "mated\n",
      "dutch\n",
      "away\n",
      "sorrel\n",
      "dead\n",
      "coral\n",
      "liver\n",
      "suave\n",
      "nippy\n",
      "dazed\n",
      "glued\n",
      "civic\n",
      "55\n",
      "fiver\n",
      "furry\n",
      "safe\n",
      "stale\n",
      "sworn\n",
      "sneak\n",
      "plummy\n",
      "paid\n",
      "buggy\n"
     ]
    }
   ],
   "source": [
    "for w in new_samples:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "5d94e432",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc4=['mossy','shot','pure','rush','smoky','torn','tubed','limper','driest',\n",
    "       'corked','nubby','laid','leafy','mucous','woody','agile','baggy','indie',\n",
    "      'amber','baltic','silken','rainy']\n",
    "\n",
    "opin4=['lucid','daft','sick','sapid','campy','rare','feral','zesty','busy',\n",
    "       'taboo','gonzo','vile','necked','toned','cuter','perkier','huffy','poor',\n",
    "      'unfit','lurid']\n",
    "\n",
    "\n",
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc4+opin4:\n",
    "    if w in testset['word']:\n",
    "        print(w)\n",
    "\n",
    "desc_all=desc+desc2+desc3+desc4\n",
    "opin_all=opin+opin2+opin3+opin4\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train4=pd.DataFrame()\n",
    "train4['word'],train4['text'],train4['target']=list(zip(*(trainset)))\n",
    "\n",
    "train4.to_csv('Data/train.v4.4.2.round4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "fab68473",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 10 repeats give out enough training samples, therefore we runback `cores` by 2 repeats.\n",
    "cores=cores[:len(cores)-2*topK]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2990977a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c831af34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.600\n",
      "positive::recall 0.750\n",
      "negative::precision 0.836\n",
      "negative::recall 0.719\n",
      "F1: 0.67\n",
      "N F1: 0.77\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.4.2.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecbdf99",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RunTwoMore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130552e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We only provide the evaluation results of another two runs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd07b8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.636\n",
      "positive::recall 0.778\n",
      "negative::precision 0.857\n",
      "negative::recall 0.750\n",
      "F1: 0.70\n",
      "N F1: 0.80\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.4.3.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc138209",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.653\n",
      "positive::recall 0.889\n",
      "negative::precision 0.922\n",
      "negative::recall 0.734\n",
      "F1: 0.75\n",
      "N F1: 0.82\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.4.5.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948cc0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa566a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "4fa6bae9",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 repeat.\n",
      "#nan# failed to get embedding. \n",
      "1 repeat.\n",
      "#nan# failed to get embedding. \n",
      "2 repeat.\n",
      "#nan# failed to get embedding. \n",
      "3 repeat.\n",
      "#nan# failed to get embedding. \n",
      "4 repeat.\n",
      "#nan# failed to get embedding. \n",
      "5 repeat.\n",
      "#nan# failed to get embedding. \n",
      "6 repeat.\n",
      "#nan# failed to get embedding. \n",
      "7 repeat.\n",
      "#nan# failed to get embedding. \n",
      "8 repeat.\n",
      "#nan# failed to get embedding. \n",
      "9 repeat.\n",
      "#nan# failed to get embedding. \n",
      "10 repeat.\n",
      "#nan# failed to get embedding. \n",
      "11 repeat.\n",
      "#nan# failed to get embedding. \n",
      "Runtime: 115.55 sec\n"
     ]
    }
   ],
   "source": [
    "DEBUG=False # True: do debug and unit test\n",
    "\n",
    "# sampling states\n",
    "new_samples=[] # samples extracted out in this iteration\n",
    "        \n",
    "if DEBUG: # only for debug and unit test\n",
    "    d_samples={}\n",
    "\n",
    "start=time.time()\n",
    "for i in range(repeat): \n",
    "    print('%d repeat.'%i)\n",
    "    # main action\n",
    "    _new=find_samples_batch(cands=adj_cand,cores=cores,model=model,\n",
    "                       topk=topK,batch_size=batch_size, only_words=True)\n",
    "    \n",
    "    # update states\n",
    "    new_samples+=_new\n",
    "    cores+=_new\n",
    "    \n",
    "    if DEBUG:\n",
    "        d_samples[i]=_new\n",
    "dur=time.time()-start\n",
    "print(\"Runtime: %.2f sec\"%dur)\n",
    "\n",
    "# after sampling, the `new_samples` will be annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "3ff20015",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "away\n",
      "sorrel\n",
      "dead\n",
      "coral\n",
      "liver\n",
      "suave\n",
      "nippy\n",
      "dazed\n",
      "glued\n",
      "civic\n",
      "55\n",
      "fiver\n",
      "furry\n",
      "safe\n",
      "stale\n",
      "sworn\n",
      "sneak\n",
      "plummy\n",
      "paid\n",
      "buggy\n",
      "whiny\n",
      "shaven\n",
      "beat\n",
      "boozy\n",
      "stout\n",
      "edged\n",
      "enteric\n",
      "nervy\n",
      "laced\n",
      "tuscan\n",
      "pushy\n",
      "ripest\n",
      "5\n",
      "straw\n",
      "cured\n",
      "comic\n",
      "pasty\n",
      "aloof\n",
      "wild\n",
      "alien\n",
      "unkept\n",
      "mussy\n",
      "brushy\n",
      "gamier\n",
      "latin\n",
      "94\n",
      "pudgy\n",
      "wheezy\n",
      "alpha\n",
      "firmest\n",
      "vivid\n",
      "gross\n",
      "zany\n",
      "lame\n",
      "brute\n",
      "larval\n",
      "humid\n",
      "grave\n",
      "juicy\n",
      "sold\n",
      "minty\n",
      "aired\n",
      "rowdy\n",
      "keen\n",
      "wispy\n",
      "witty\n",
      "upwind\n",
      "olden\n",
      "hipped\n",
      "truer\n",
      "floury\n",
      "weak\n",
      "cystic\n",
      "merry\n",
      "kenyan\n",
      "gluey\n",
      "game\n",
      "misty\n",
      "fossil\n",
      "airier\n",
      "pearly\n",
      "ferric\n",
      "brindle\n",
      "hurt\n",
      "spicer\n",
      "sissy\n",
      "drafty\n",
      "gushy\n",
      "late\n",
      "sappy\n",
      "moist\n",
      "honey\n",
      "dark\n",
      "vocal\n",
      "fast\n",
      "perky\n",
      "dusky\n",
      "stern\n",
      "civil\n",
      "royal\n",
      "horny\n",
      "ebony\n",
      "fishy\n",
      "sent\n",
      "bully\n",
      "warm\n",
      "high\n",
      "stark\n",
      "kinky\n",
      "silky\n",
      "sheer\n",
      "palatal\n",
      "matte\n",
      "matted\n",
      "arable\n",
      "side\n",
      "rudest\n",
      "risen\n",
      "plane\n",
      "rectal\n"
     ]
    }
   ],
   "source": [
    "for w in new_samples:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "6ef5ef42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc5=['away','sorrel','dead','coral','liver','furry','stale','paid','buggy',\n",
    "       'shaven','beat','edged','laced','ripest','straw','upwind','brushy','latin',\n",
    "      'gross','larval','humid','aired']\n",
    "\n",
    "opin5=['suave','nippy','dazed','safe','sworn','sworn','plummy','whiny','nervy',\n",
    "       'pushy','comic','aloof','unkept','firmest','vivid','lame','rowdy','witty',\n",
    "      'truer','merry']\n",
    "\n",
    "\n",
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc5+opin5:\n",
    "    if w in testset['word']:\n",
    "        print(w)\n",
    "\n",
    "desc_all=desc+desc2+desc3+desc4+desc5\n",
    "opin_all=opin+opin2+opin3+opin4+opin5\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train5=pd.DataFrame()\n",
    "train5['word'],train5['text'],train5['target']=list(zip(*(trainset)))\n",
    "\n",
    "train5.to_csv('Data/train.v4.5.round5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2072e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cdac93b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.549\n",
      "positive::recall 0.778\n",
      "negative::precision 0.837\n",
      "negative::recall 0.641\n",
      "F1: 0.64\n",
      "N F1: 0.73\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.5.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87c2ff4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RunTwoMore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f969166",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We only provide the evaluation results of another two runs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6dbbc12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.579\n",
      "positive::recall 0.917\n",
      "negative::precision 0.930\n",
      "negative::recall 0.625\n",
      "F1: 0.71\n",
      "N F1: 0.75\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.5.2.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7fa2951",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.651\n",
      "positive::recall 0.778\n",
      "negative::precision 0.860\n",
      "negative::recall 0.766\n",
      "F1: 0.71\n",
      "N F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v4.5.3.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "# testset performance\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "    \n",
    "    \n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5755b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d54eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Iter2: Annotate 120 words where we pick 20-20 for training.\n",
    "    Iter3: Annotate 120 words where we  pick 20-20 for training.\n",
    "    Iter4: Annotate 100 words where we  pick 20-20 for training.\n",
    "    Iter5: Annotate 80 words where we  pick 20-20 for training.    \n",
    "    Annotate 80~120words/iter. This method needs to annotate more samples than HighEntropy.\n",
    "    \n",
    "    For classification performance, CORESET doesn't beat HighEntropy, but better than Random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244afb7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}