{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2993a39a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Implementation of HighEntropy and Random methods. Candidate adjective extraction is inclued in this notebook.\n",
    "\n",
    "# Label\n",
    "# 0: Physical\n",
    "# 1: Mental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce8e00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c17ec4e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "To use nltk's wordnet, you should download WordNet from https://www.nltk.org/nltk_data/ and then unzip wordnet.zip\n",
    "under your home directory with path as /home_path/nltk_data/corpora/\n",
    "\n",
    "'''\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import tqdm\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import joblib\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca288cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('barbeque', 'NN'),\n",
       " ('flavor', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('these', 'DT'),\n",
       " ('chips', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('really', 'RB'),\n",
       " ('perfect', 'JJ'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\"\"\"\n",
    "Number Tag Description\n",
    "1.\tCC\tCoordinating conjunction\n",
    "2.\tCD\tCardinal number\n",
    "3.\tDT\tDeterminer\n",
    "4.\tEX\tExistential there\n",
    "5.\tFW\tForeign word\n",
    "6.\tIN\tPreposition or subordinating conjunction\n",
    "7.\tJJ\tAdjective\n",
    "8.\tJJR\tAdjective, comparative\n",
    "9.\tJJS\tAdjective, superlative\n",
    "10.\tLS\tList item marker\n",
    "11.\tMD\tModal\n",
    "12.\tNN\tNoun, singular or mass\n",
    "13.\tNNS\tNoun, plural\n",
    "14.\tNNP\tProper noun, singular\n",
    "15.\tNNPS\tProper noun, plural\n",
    "16.\tPDT\tPredeterminer\n",
    "17.\tPOS\tPossessive ending\n",
    "18.\tPRP\tPersonal pronoun\n",
    "19.\tPRP$\tPossessive pronoun\n",
    "20.\tRB\tAdverb\n",
    "21.\tRBR\tAdverb, comparative\n",
    "22.\tRBS\tAdverb, superlative\n",
    "23.\tRP\tParticle\n",
    "24.\tSYM\tSymbol\n",
    "25.\tTO\tto\n",
    "26.\tUH\tInterjection\n",
    "27.\tVB\tVerb, base form\n",
    "28.\tVBD\tVerb, past tense\n",
    "29.\tVBG\tVerb, gerund or present participle\n",
    "30.\tVBN\tVerb, past participle\n",
    "31.\tVBP\tVerb, non-3rd person singular present\n",
    "32.\tVBZ\tVerb, 3rd person singular present\n",
    "33.\tWDT\tWh-determiner\n",
    "34.\tWP\tWh-pronoun\n",
    "35.\tWP$\tPossessive wh-pronoun\n",
    "36.\tWRB\tWh-adverb\n",
    "\"\"\"\n",
    "\n",
    "# Usage Sample:\n",
    "#text='The barbeque flavor of these chips is really perfect!'\n",
    "#tokens = nltk.word_tokenize(text)\n",
    "#tagged = nltk.pos_tag(tokens)\n",
    "\n",
    "\n",
    "# self-defined tagging\n",
    "def tagging(text,return_type='list'):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    if return_type=='str':\n",
    "        return \" \".join([\"%s /%s\" % (w, tag) for w,tag in tagged])\n",
    "    if return_type=='list':\n",
    "        return [(w, tag) for w, tag in tagged]\n",
    "\n",
    "tagging(text='The barbeque flavor of these chips is really perfect!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82bfd67",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build (Adj, Noun) Relations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7fb74f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract \"JJ+NN\" relations by using pos_tags\n",
    "def extract_relation(text,rtype='JJ+NN'):\n",
    "    relations=[]\n",
    "    pos_tags=tagging(text)\n",
    "    \n",
    "    if rtype=='JJ+NN':\n",
    "        last_w=''\n",
    "        last_tag=''\n",
    "        for w,tag in pos_tags:\n",
    "            if last_w:\n",
    "                if 'J' in last_tag and 'N' in tag:\n",
    "                    relations.append((last_w,w))\n",
    "            last_w=w\n",
    "            last_tag=tag\n",
    "    \n",
    "    return relations\n",
    "\n",
    "# validate JJ+NN relations by WordNet POS flag\n",
    "# if a word not exists in wordnet, we still keep this piece of relation. Further check will be done.\n",
    "def validate_j_n(relation):\n",
    "    adj, n =relation[0],relation[1]\n",
    "    \n",
    "    is_valid1=False\n",
    "    syns=wn.synsets(n)\n",
    "    if syns:\n",
    "        for syn in syns:\n",
    "            tag=syn.name().split('.')[1]\n",
    "            if tag=='n':\n",
    "                is_valid1=True\n",
    "                break\n",
    "    else: # if not exist in wordnet, not judge anything\n",
    "        is_valid1=True\n",
    "            \n",
    "    is_valid2=False\n",
    "    syns=wn.synsets(adj)\n",
    "    if syns:\n",
    "        for syn in syns:\n",
    "            tag=syn.name().split('.')[1]\n",
    "            if tag=='a' or tag == 's':\n",
    "                is_valid2=True\n",
    "                break\n",
    "    else: # if not exist in wordnet, not judge anything\n",
    "        is_valid2=True\n",
    "        \n",
    "    if is_valid1 and is_valid2:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "validate_j_n(('extra','crunchy'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c21f4181",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 568454 rows and 10 columns\n"
     ]
    }
   ],
   "source": [
    "# we don't provide this data as it's too large. \n",
    "# Download URL: https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews\n",
    "\n",
    "source_dir='amazon_food_review/'\n",
    "nRowsRead = 1000000 # specify 'None' if want to read whole file\n",
    "df = pd.read_csv(source_dir+'Reviews.csv', delimiter=',', nrows = nRowsRead)\n",
    "df.dataframeName = 'Reviews.csv'\n",
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1fd186a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 568454/568454 [34:25<00:00, 275.22it/s]  \n"
     ]
    }
   ],
   "source": [
    "relations=[]\n",
    "for t in tqdm.tqdm(df['Text']):\n",
    "    relations+=extract_relation(t,rtype='JJ+NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fc9a82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/jj_nn_relation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(relations, 'Data/jj_nn_relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f29021",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "relations_new=[r for r in relations if validate_j_n(r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d630529",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2497195"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relations_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cb81e54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('several', 'of'),\n",
       " ('good', 'quality'),\n",
       " ('processed', 'meat'),\n",
       " ('better', 'than'),\n",
       " ('sure', 'if'),\n",
       " ('few', 'centuries'),\n",
       " ('pillowy', 'citrus'),\n",
       " ('tiny', 'squares'),\n",
       " ('powdered', 'sugar'),\n",
       " ('tiny', 'mouthful'),\n",
       " ('yummy', 'treat'),\n",
       " ('familiar', 'with'),\n",
       " ('secret', 'ingredient'),\n",
       " ('cherry', 'soda'),\n",
       " ('great', 'price'),\n",
       " ('wide', 'assortment'),\n",
       " ('wild', 'hair'),\n",
       " ('enjoyable', 'with'),\n",
       " ('many', 'flavors'),\n",
       " ('only', 'complaint'),\n",
       " ('much', 'red/black'),\n",
       " ('licorice-flavored', 'pieces'),\n",
       " ('particular', 'favorites'),\n",
       " ('delightful', 'treat'),\n",
       " ('great', 'flavors'),\n",
       " ('expensive', 'version'),\n",
       " ('beach-themed', 'party'),\n",
       " ('healthy', 'dog'),\n",
       " ('good', 'for'),\n",
       " ('small', 'puppies'),\n",
       " ('required', 'amount'),\n",
       " ('unique', 'combination'),\n",
       " ('hot', 'sauce'),\n",
       " ('bummed.', '<'),\n",
       " ('ecstatic', 'because'),\n",
       " ('it.', '<'),\n",
       " ('hot', 'sauce'),\n",
       " ('hot', 'sauce'),\n",
       " ('other', 'sauce.'),\n",
       " ('incredible', 'service'),\n",
       " ('skinny', 'boy'),\n",
       " ('higher', 'food'),\n",
       " ('more', 'than'),\n",
       " ('new', 'bag'),\n",
       " ('new', 'food'),\n",
       " ('similar', 'reviews'),\n",
       " ('new', 'food'),\n",
       " ('good', 'flavor'),\n",
       " ('guilty', 'pleasure'),\n",
       " ('good', 'for'),\n",
       " ('fresh', 'so'),\n",
       " ('satisfied', 'with'),\n",
       " ('favorite', 'candy'),\n",
       " ('oldest', 'confectionery'),\n",
       " ('dry', 'cool'),\n",
       " ('longest', 'Licorice'),\n",
       " ('Record-Breaking', 'Twist'),\n",
       " ('reasonable', 'price'),\n",
       " ('many', 'times'),\n",
       " ('timely', 'manner'),\n",
       " ('<', 'br'),\n",
       " ('generous', 'amounts'),\n",
       " ('16-ounce', 'bag'),\n",
       " ('superb', 'product'),\n",
       " ('<', 'br'),\n",
       " ('faithful', 'buyer'),\n",
       " ('advertised.', '<'),\n",
       " ('glad', 'Amazon'),\n",
       " ('hard', 'time'),\n",
       " ('unique', 'size'),\n",
       " ('unnecessary', 'sugar'),\n",
       " ('great', 'that'),\n",
       " ('much', 'guilt'),\n",
       " ('impressed', 'that'),\n",
       " ('sugary', 'sweets.'),\n",
       " ('unique', 'combination'),\n",
       " ('hot', 'sauce'),\n",
       " ('bummed.', '<'),\n",
       " ('ecstatic', 'because'),\n",
       " ('it.', '<'),\n",
       " ('hot', 'sauce'),\n",
       " ('hot', 'sauce'),\n",
       " ('other', 'sauce.'),\n",
       " ('incredible', 'service'),\n",
       " ('huge', 'coffee'),\n",
       " ('little', 'machine'),\n",
       " ('most', 'of'),\n",
       " ('other', 'products'),\n",
       " ('non-coffee', 'drinker'),\n",
       " ('<', 'br'),\n",
       " ('little', 'Dolche'),\n",
       " ('good', 'Coffee/Latte/Cappuccino/etc'),\n",
       " ('less', 'than'),\n",
       " ('good', 'for'),\n",
       " ('great', 'price'),\n",
       " ('great', 'taste'),\n",
       " ('great', 'if'),\n",
       " ('instant', 'oatmeal'),\n",
       " ('good', 'as'),\n",
       " ('stovetop', 'preparation')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_new[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d1d9f2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3958/2828025 [00:00<00:02, 1015168.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bummed.\n",
      "it.\n",
      "advertised.\n",
      "non-coffee\n",
      "issue.\n",
      "non-instant\n",
      "up.\n",
      "great.\n",
      "often.\n",
      "convenient.\n",
      "..\n",
      "these.\n",
      "problems.\n",
      "tuned.\n",
      "like.\n",
      "up'.\n",
      "lower.\n",
      "refreshing.\n",
      "lunch.\n",
      "deal.There\n",
      "go.Fifty\n",
      "sugar.The\n",
      "them.\n",
      "skinny.\n",
      "effective.\n",
      "much.\n",
      "oil.\n",
      "all.\n",
      "dogs.\n",
      "safe.\n",
      "ingredients.\n",
      "out.\n",
      "anything.\n",
      "non-organic\n",
      "first.\n",
      "fans.\n",
      "fluffy.\n",
      "allergy.\n",
      "non-baked\n",
      "feet.\n",
      "beer.\n",
      "crispy.\n",
      "exists.\n",
      "saying.\n",
      "adult.\n",
      "about.\n",
      "required.\n",
      "there.\n",
      "long.\n",
      "opposite.\n",
      "rancid.\n",
      "now.\n",
      "used.\n",
      "stale.\n",
      "again.\n",
      "ok.\n",
      "scissors.\n",
      "too.\n",
      "for.\n",
      "non-existent.\n",
      "natural.\n",
      "non-manufactured\n",
      "important.\n",
      "'affection-ados'.\n",
      "bergamot.\n",
      "ready.\n",
      "well.\n",
      "right.\n",
      "3.5-Ounce\n",
      "treat.\n",
      "flat.\n",
      "widely.\n",
      "2-pack.\n",
      "tasty.\n",
      "weight.\n",
      "organic.\n",
      "delicious.\n",
      "us.\n",
      "good.\n",
      ".....\n",
      "favorite.\n",
      "bothersome.\n",
      "non-animal\n",
      "dishes.\n",
      "ordered.\n",
      "nice.\n",
      "work.\n",
      "unwind.\n",
      "bigger.\n",
      "alive.\n",
      "dinner.\n",
      "quickly.\n",
      "squeaky.\n",
      "differently.\n",
      "straight.\n",
      "perfect.\n",
      "amazon.com-land\n",
      "fast.\n",
      "anymore.\n",
      "eating.\n",
      "non-healthful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check bad adj extracted directly from `relations`\n",
    "\n",
    "limit=100\n",
    "visited=set()\n",
    "for r in tqdm.tqdm(relations):\n",
    "    w=r[0]\n",
    "    if w not in visited and ('non-' in w or '.' in w):\n",
    "        print(w)\n",
    "        visited.add(w)\n",
    "        if len(visited)>limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e289cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract Valid Adjectives "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c85d89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Actually we could scan each piece of review word by word and use WordNet to judge if a word is adjective. Instead, in this work we first build JJ+NN relations and then get adj from those relations. There should not be much difference between these two paths as the review corpus is extremely large with more than half a million samples. Moreover, we need this set of relations to build common knowledge about nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf56f9eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "relations=joblib.load('Data/jj_nn_relation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "389ad827",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get all adjectives\n",
    "adj_all=set([x[0] for x in relations_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5ae7a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46617"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(adj_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "628a8402",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved in health or physical condition\n",
      "having or indicating good health in body or mind; free from infirmity or disease\n",
      "financially secure and functioning well\n",
      "promoting health; healthful; ; ; ; ; - C.B.Davis\n",
      "exercising or showing good judgment\n",
      "large in amount or extent or degree\n"
     ]
    }
   ],
   "source": [
    "for syn in wn.synsets('healthier'):\n",
    "    tag=syn.name().split('.')[1]\n",
    "    if (tag=='a' or tag == 's'): # match\n",
    "        print(syn.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "724793f7",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ruined by overcooking; treated by heating to a high temperature but below the melting or fusing point; destroyed or badly damaged by fire'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate word type by WordNet\n",
    "def wn_validate_type(word,word_type):\n",
    "    res=[]\n",
    "    syns=wn.synsets(word)\n",
    "    for syn in syns:\n",
    "        tag=syn.name().split('.')[1]\n",
    "        if word_type=='adj' and (tag=='a' or tag == 's'): # match\n",
    "            return True\n",
    "        if word_type=='verb' and (tag=='v' or tag == 'v'): # match\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# extract word definition from WordNet\n",
    "def wn_ext_defn(word,word_type):\n",
    "    res=[]\n",
    "    syns=wn.synsets(word)\n",
    "    for syn in syns:\n",
    "        tag=syn.name().split('.')[1]\n",
    "        if word_type=='adj' and (tag=='a' or tag == 's'): # match\n",
    "            res.append(syn.definition())\n",
    "        if word_type=='verb' and (tag=='v' or tag == 'v'): # match\n",
    "            res.append(syn.definition())\n",
    "    return '; '.join(res)\n",
    "wn_ext_defn(word='burnt',word_type='adj')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5bf36de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46617/46617 [00:01<00:00, 43080.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10939\n"
     ]
    }
   ],
   "source": [
    "# Validate word definitions provided by WordNet\n",
    "# func `wn_validate_type` is actually not necessary whose function has already fulfilled in `validate_j_n`\n",
    "\n",
    "adjset=[]\n",
    "word_type='adj'\n",
    "for w in tqdm.tqdm(set(adj_all)):\n",
    "    w=w.replace('.','').replace(\"'\",'')\n",
    "    _defn=wn_ext_defn(w,word_type)\n",
    "    if wn_validate_type(w,'adj') and _defn: # exclude []\n",
    "        adjset.append((w,_defn,-1)) # -1: unknown\n",
    "\n",
    "print(len(adjset))\n",
    "\n",
    "adj=pd.DataFrame()\n",
    "adj['word'],adj['text'],adj['target']=list(zip(*(adjset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2c20d4f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove not-strings\n",
    "# use lowercase\n",
    "adj['word']=adj['word'].apply(lambda x:x.lower() if isinstance(x,str) else x)\n",
    "adj[['word','text','target']].drop_duplicates().to_csv('Data/adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7de4b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a54ce25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7292, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check size\n",
    "adj=pd.read_csv('Data/adj.csv')\n",
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec97cc0a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check words containing token '-'\n",
    "cnt=0\n",
    "z=[]\n",
    "for w in adj['word'].tolist():\n",
    "    if isinstance(w,str):\n",
    "        w=w.lower()\n",
    "        if '-' in w:\n",
    "            cnt+=1\n",
    "            z.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46828a35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de6aa910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seventy-six',\n",
       " 'stuck-up',\n",
       " 'right-wing',\n",
       " 'acid-tasting',\n",
       " 'african-american',\n",
       " 'true-blue',\n",
       " 'off-the-shelf',\n",
       " 'long-term',\n",
       " 'twenty-four',\n",
       " 'no-go',\n",
       " 'tongue-in-cheek',\n",
       " 'pumped-up',\n",
       " 'oven-ready',\n",
       " 'flesh-eating',\n",
       " 'dust-covered',\n",
       " 'fifty-four',\n",
       " 'tailor-made',\n",
       " 'make-believe',\n",
       " 'half-hearted',\n",
       " 'time-tested',\n",
       " 'born-again',\n",
       " 'first-year',\n",
       " 'creamy-white',\n",
       " 'high-voltage',\n",
       " 'across-the-board',\n",
       " 'tax-free',\n",
       " 'full-bodied',\n",
       " 'world-class',\n",
       " 'hard-to-please',\n",
       " 'mind-boggling',\n",
       " 'twenty-one',\n",
       " 'one-man',\n",
       " 'self-propelled',\n",
       " 'gray-green',\n",
       " 'factory-made',\n",
       " 'left-handed',\n",
       " 'top-grade',\n",
       " 'top-secret',\n",
       " 'kidney-shaped',\n",
       " 'sky-blue',\n",
       " 'red-hot',\n",
       " 'upside-down',\n",
       " 'yellow-green',\n",
       " 'strong-willed',\n",
       " 'pancake-like',\n",
       " 'off-line',\n",
       " 'brand-new',\n",
       " 'off-the-wall',\n",
       " 'over-the-top',\n",
       " 'ninety-five']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(z)\n",
    "z[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a94f7e11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-poisonous\n"
     ]
    }
   ],
   "source": [
    "for w in adj['word'].tolist():\n",
    "    if isinstance(w,str):\n",
    "        w=w.lower()\n",
    "        if 'non-' in w or '.' in w:\n",
    "            print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fb274c3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'not producing poison'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('non-poisonous')[0].definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64a377",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    From above exploration, there are 642/7292 adj with '-' inside and 1/7292 with 'non-'. All of them have valid definitions in WordNet. So we keep them as valid adjectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5503d8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Build TestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "028f5577",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Manually annotate a testset for evaluating model performance\n",
    "# Randomly chosen from valid adjectives.\n",
    "# Size of testset is 100.\n",
    "\n",
    "import random\n",
    "cand_words=list()\n",
    "K=100\n",
    "test_words=random.sample(adj['word'].tolist(),K)    \n",
    "test_words_df=pd.DataFrame({'word':test_words})\n",
    "\n",
    "testset=pd.merge(adj,test_words_df,on='word',how='inner')\n",
    "\n",
    "# print out for annotation\n",
    "_s=''\n",
    "for w in test_words:\n",
    "    _s+=\"'%s':0,\"%w\n",
    "#print(_s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86b0f546",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Annotation\n",
    "# All labeling steps below are implemented by two annotators. If the labeling results disagree, \n",
    "# we ask a third expert to arbitrate.\n",
    "test_man_labels={'teary-eyed':0,'meaningless':1,'41st':0,'unprotected':0,'malicious':1,'glossy':0,'discerning':1,\n",
    "            'present':0,'federal':0,'noble':1,'air-dried':0,'together':1,'strong-willed':1,'circumspect':1,\n",
    "            'developing':0,'unchanged':1,'impolite':1,'pavlovian':0,'limber':0,'braised':0,'obese':0,\n",
    "            'carefree':1,'compositional':0,'temporary':0,'peppery':0,'granulated':0,'infinitesimal':0,\n",
    "            'electrolytic':0,'lessened':1,'turbulent':0,'plain':0,'cute':1,'velvet':0,'unnameable':1,\n",
    "            'singular':1,'infernal':1,'checked':0,'case-by-case':0,'skim':0,'engorged':0,'pro':1,'systemic':0,\n",
    "            'done':1,'haphazard':0,'recurrent':0,'thinner':0,'galactic':0,'elapsed':0,'putrid':0,'noisiest':0,\n",
    "            'disreputable':1,'arrant':0,'antsy':1,'corn-fed':0,'molecular':0,'genteel':1,'41':0,'hotter':0,\n",
    "            'liver':0,'faster':0,'home-cured':0,'d':0,'nauseated':0,'relentless':1,'bouncy':0,'sensuous':1,\n",
    "            'splendid':0,'stirring':1,'malleable':0,'permanent':0,'potent':0,'enamored':1,'laid':0,'gothic':0,\n",
    "            'concerted':0,'unnamed':0,'finite':0,'caramel':0,'extra':1,'greenish':0,'incidental':1,'lazier':1,\n",
    "            'medium-size':0,'sorry':1,'desperate':1,'nether':0,'algerian':0,'truncated':0,'pussy':0,\n",
    "            'undisputed':1,'faddish':1,'tied':0,'fondest':1,'louder':0,'deadly':0,'automated':0,'manic':1,\n",
    "            'delinquent':1,'emphasised':1,'rhetorical':1}\n",
    "testset['target']=testset['word'].apply(lambda x: test_man_labels[x])\n",
    "testset.to_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebe4f98d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36\n"
     ]
    }
   ],
   "source": [
    "# distribution \n",
    "cnt=0\n",
    "for _w,_label in zip(testset['word'],testset['target']):\n",
    "    if _label:\n",
    "        cnt+=1\n",
    "print(cnt/len(testset['word']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3531c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HighEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eb381",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    \n",
    "    In each iteration, about 40 words are selected out for training. Iterations stop if performance converges.\n",
    "    \n",
    "    We run three times with different random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f6bfcd0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "K=20 # number of positive samples in each round and negative samples have equal number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661e6a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57357354",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b9c88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adj.sample(frac=0.01)[['word','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9d7415d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly choose some positive and negative words for training. Proportion of samples, 1:1\n",
    "# `desc`: `physical` adj, describe physical attributes\n",
    "# `opin`: `mental` adj, usually relates to mental attributes\n",
    "\n",
    "desc=['anemic','arranged','assorted','available','baked','bitter','black','blue','broken','cherry',\n",
    "      'citric','corrugated','commercial','cooked','crispy','crushed','crusty','decorative','dietetic',\n",
    "     'digestible','dried','drippy','edible','empty','fake']\n",
    "opin=['amazing','awesome','awful','aware','bold','bothersome','careful',\n",
    "      'casual','certain','crazy','dulled','nosy','fussy','ignorant','preferable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3031a6b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc+opin:\n",
    "    if w in testset['word']:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fe88baf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word_type='adj'\n",
    "trainset=[]\n",
    "        \n",
    "for w in desc:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5407d14b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train=pd.DataFrame()\n",
    "train['word'],train['text'],train['target']=list(zip(*(trainset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6115e57",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train.to_csv('Data/train.v6.1.round1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7914824b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is done by `train.py` with trainset `Data/train.v6.1.round1.csv`. Remember setting Config.is_predict=False in `train.py` before training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278c16a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6a624",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We use the trained model to make predictions over all valid adjectives. Higher the output probability, more \n",
    "    possible that this word is mental.\n",
    "    \n",
    "    The words with probability around 0.5 are uncertain words which need human-annotation for next round training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57ce2f03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred=joblib.load('Data/pred.v6.1.1.round1') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82dbf26a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# show uncertain words\n",
    "uw=[]\n",
    "for i,w in enumerate(adj['word'].tolist()):        \n",
    "    if pred[i]>0.45 and pred[i]<0.55:\n",
    "        uw.append((w,round(pred[i][0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4878423",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4187"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d64c9f1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adequate', 0.47),\n",
       " ('left-wing', 0.45),\n",
       " ('unconscionable', 0.47),\n",
       " ('pricier', 0.53),\n",
       " ('sublingual', 0.55),\n",
       " ('i', 0.46),\n",
       " ('orange-red', 0.52),\n",
       " ('darling', 0.49),\n",
       " ('ago', 0.46),\n",
       " ('folksy', 0.48),\n",
       " ('sloppy', 0.46),\n",
       " ('defective', 0.48),\n",
       " ('key', 0.46),\n",
       " ('judicious', 0.46),\n",
       " ('skeptical', 0.47),\n",
       " ('acceptable', 0.47),\n",
       " ('indiscernible', 0.48),\n",
       " ('empowered', 0.46),\n",
       " ('audible', 0.48),\n",
       " ('expedient', 0.46),\n",
       " ('eventual', 0.5),\n",
       " ('unsure', 0.48),\n",
       " ('newfound', 0.51),\n",
       " ('tippy', 0.46),\n",
       " ('converted', 0.46),\n",
       " ('oriental', 0.47),\n",
       " ('lamer', 0.48),\n",
       " ('artificial', 0.46),\n",
       " ('ill-fitting', 0.51),\n",
       " ('idle', 0.46),\n",
       " ('gastric', 0.45),\n",
       " ('stimulant', 0.46),\n",
       " ('humorous', 0.46),\n",
       " ('sixty-three', 0.52),\n",
       " ('accustomed', 0.48),\n",
       " ('behavioral', 0.45),\n",
       " ('wonderful', 0.48),\n",
       " ('likable', 0.47),\n",
       " ('croatian', 0.47),\n",
       " ('prepackaged', 0.46),\n",
       " ('overabundant', 0.49),\n",
       " ('overweight', 0.46),\n",
       " ('helpful', 0.47),\n",
       " ('unturned', 0.52),\n",
       " ('unsaturated', 0.45),\n",
       " ('unwarranted', 0.48),\n",
       " ('edged', 0.46),\n",
       " ('53', 0.54),\n",
       " ('shrewd', 0.46),\n",
       " ('celtic', 0.46),\n",
       " ('inflamed', 0.47),\n",
       " ('deluxe', 0.46),\n",
       " ('marginal', 0.45),\n",
       " ('romantic', 0.5),\n",
       " ('sturdiest', 0.46),\n",
       " ('zesty', 0.45),\n",
       " ('routine', 0.48),\n",
       " ('choosy', 0.53),\n",
       " ('undeterred', 0.48),\n",
       " ('additional', 0.48),\n",
       " ('frigid', 0.49),\n",
       " ('invariable', 0.47),\n",
       " ('lucky', 0.45),\n",
       " ('addictive', 0.48),\n",
       " ('prominent', 0.45),\n",
       " ('episodic', 0.45),\n",
       " ('cramped', 0.46),\n",
       " ('replaceable', 0.48),\n",
       " ('unrelated', 0.47),\n",
       " ('best-selling', 0.49),\n",
       " ('any', 0.51),\n",
       " ('smokier', 0.47),\n",
       " ('proper', 0.45),\n",
       " ('ancient', 0.48),\n",
       " ('unorthodox', 0.47),\n",
       " ('sear', 0.46),\n",
       " ('robust', 0.46),\n",
       " ('minus', 0.46),\n",
       " ('sheltered', 0.46),\n",
       " ('credible', 0.46),\n",
       " ('65', 0.54),\n",
       " ('frothy', 0.46),\n",
       " ('fancy', 0.47),\n",
       " ('intended', 0.48),\n",
       " ('sacrificial', 0.48),\n",
       " ('leisurely', 0.49),\n",
       " ('applicable', 0.45),\n",
       " ('all', 0.45),\n",
       " ('unnerved', 0.45),\n",
       " ('healthful', 0.47),\n",
       " ('shitty', 0.54),\n",
       " ('explosive', 0.48),\n",
       " ('perfect', 0.46),\n",
       " ('extended', 0.47),\n",
       " ('must', 0.5),\n",
       " ('angry', 0.45),\n",
       " ('back', 0.47),\n",
       " ('unlikely', 0.47),\n",
       " ('better-known', 0.48),\n",
       " ('neurotoxic', 0.47)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uw[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4c7b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258419d7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02ac7866",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# choose round2 training samples from those most uncertain words in round1\n",
    "desc2=['defective','indiscernible','empowered','audible','newfound','tippy','downward','wooly','oriental',\n",
    "       'incendiary','prepackaged','wonderful','helpful','sealed','romantic','ongoing','adjacent','cheesy',\n",
    "      'extra','present','warmer','noticeable','fifty-four',]\n",
    "\n",
    "opin2=['humorous','sloppy','unnerved','judicious','burdensome','hip','acceptable','imbalanced','unsure',\n",
    "       'accustomed','unnerved','angry','asserted','jerky','desired','depressed','dreamier','anguished',\n",
    "      'unimpressed','unloved','infuriating','emphasised','homesick']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "785b5099",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc2+opin2:\n",
    "    if w in testset['word']:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd959c14",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(desc2+opin2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "059a70d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc_all=desc+desc2\n",
    "opin_all=opin+opin2\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train2=pd.DataFrame()\n",
    "train2['word'],train2['text'],train2['target']=list(zip(*(trainset)))\n",
    "\n",
    "train2.to_csv('Data/train.v6.2.round2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85f532a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d13e998",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is done by `train.py` with trainset `Data/train.v6.2.round2.csv`. Remember setting Config.is_predict=False in `train.py` before training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee835b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad085b1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred=joblib.load('Data/pred.v6.2.1.round2') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71983cb6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# show uncertain words\n",
    "\n",
    "uw=[]\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "        \n",
    "    if pred[i]>0.49 and pred[i]<0.51:\n",
    "        uw.append((w,round(pred[i][0],2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daa4a717",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c61ddc7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reductive', 0.51),\n",
       " ('crisper', 0.49),\n",
       " ('habit-forming', 0.49),\n",
       " ('noticed', 0.5),\n",
       " ('tidier', 0.49),\n",
       " ('virtual', 0.5),\n",
       " ('discarded', 0.5),\n",
       " ('countless', 0.5),\n",
       " ('alluring', 0.51),\n",
       " ('recognizable', 0.51),\n",
       " ('haunted', 0.5),\n",
       " ('hourlong', 0.5),\n",
       " ('repeatable', 0.5),\n",
       " ('mythical', 0.5),\n",
       " ('controlled', 0.49),\n",
       " ('paler', 0.49),\n",
       " ('snazzy', 0.51),\n",
       " ('uppermost', 0.51),\n",
       " ('prime', 0.49),\n",
       " ('merciful', 0.5),\n",
       " ('upper', 0.5),\n",
       " ('enticing', 0.51),\n",
       " ('wacky', 0.5),\n",
       " ('full', 0.51),\n",
       " ('void', 0.49),\n",
       " ('uncontrollable', 0.5),\n",
       " ('tenable', 0.5),\n",
       " ('ambiguous', 0.51),\n",
       " ('whacky', 0.5),\n",
       " ('stuffy', 0.5),\n",
       " ('causal', 0.5),\n",
       " ('intricate', 0.5),\n",
       " ('riper', 0.5),\n",
       " ('fashionable', 0.5),\n",
       " ('restorative', 0.51),\n",
       " ('corrected', 0.5),\n",
       " ('liable', 0.5),\n",
       " ('shortest', 0.49),\n",
       " ('abysmal', 0.5),\n",
       " ('curly-haired', 0.5),\n",
       " ('lengthy', 0.5),\n",
       " ('evil', 0.49),\n",
       " ('strengthened', 0.5),\n",
       " ('glacial', 0.49),\n",
       " ('steeper', 0.5),\n",
       " ('orange-brown', 0.5),\n",
       " ('salvageable', 0.49),\n",
       " ('fullest', 0.51),\n",
       " ('cloudy', 0.51),\n",
       " ('favourable', 0.5),\n",
       " ('overfull', 0.51),\n",
       " ('conscionable', 0.51),\n",
       " ('alive', 0.5),\n",
       " ('vilest', 0.49),\n",
       " ('short', 0.49),\n",
       " ('fuller', 0.51),\n",
       " ('nonstandard', 0.5),\n",
       " ('fiendish', 0.5),\n",
       " ('piquant', 0.51),\n",
       " ('stinking', 0.5),\n",
       " ('nebulous', 0.5),\n",
       " ('protracted', 0.5),\n",
       " ('4th', 0.5),\n",
       " ('passing', 0.51),\n",
       " ('cloudier', 0.51),\n",
       " ('preferable', 0.5),\n",
       " ('pretend', 0.49),\n",
       " ('ripest', 0.5),\n",
       " ('twenty-second', 0.51),\n",
       " ('tidy', 0.49),\n",
       " ('fourth', 0.5),\n",
       " ('curled', 0.51),\n",
       " ('republican', 0.51),\n",
       " ('greediest', 0.5),\n",
       " ('world-class', 0.5),\n",
       " ('trustworthy', 0.5),\n",
       " ('ashy', 0.51),\n",
       " ('particular', 0.49),\n",
       " ('gray-black', 0.51),\n",
       " ('imitation', 0.51),\n",
       " ('satirical', 0.5),\n",
       " ('balmy', 0.5),\n",
       " ('myriad', 0.5),\n",
       " ('expert', 0.5),\n",
       " ('overpriced', 0.5),\n",
       " ('purplish-red', 0.5),\n",
       " ('mythological', 0.5),\n",
       " ('convex', 0.49),\n",
       " ('rampant', 0.5),\n",
       " ('greedy', 0.5),\n",
       " ('tasteless', 0.5),\n",
       " ('itchy', 0.51),\n",
       " ('struck', 0.5),\n",
       " ('hep', 0.5),\n",
       " ('pale', 0.49),\n",
       " ('unsubstantiated', 0.49),\n",
       " ('rewarding', 0.5),\n",
       " ('vile', 0.49),\n",
       " ('gargantuan', 0.51),\n",
       " ('wasteful', 0.49),\n",
       " ('unadorned', 0.49),\n",
       " ('lengthier', 0.5),\n",
       " ('shorter', 0.49),\n",
       " ('noble', 0.5),\n",
       " ('greatest', 0.5),\n",
       " ('sensual', 0.5),\n",
       " ('jumbo', 0.51),\n",
       " ('approximate', 0.5),\n",
       " ('wanting', 0.49),\n",
       " ('back-to-back', 0.51),\n",
       " ('hairy', 0.49),\n",
       " ('invisible', 0.51),\n",
       " ('self-confessed', 0.51),\n",
       " ('addictive', 0.49),\n",
       " ('unwieldy', 0.49),\n",
       " ('30th', 0.5),\n",
       " ('giant', 0.51),\n",
       " ('cosmopolitan', 0.5),\n",
       " ('well-kept', 0.5),\n",
       " ('simplified', 0.5),\n",
       " ('resilient', 0.49),\n",
       " ('preconceived', 0.5),\n",
       " ('snotty', 0.49),\n",
       " ('attributable', 0.49),\n",
       " ('beauteous', 0.49),\n",
       " ('demeaning', 0.49),\n",
       " ('various', 0.49),\n",
       " ('blemished', 0.51),\n",
       " ('adolescent', 0.5),\n",
       " ('nimble', 0.5),\n",
       " ('self-contained', 0.5),\n",
       " ('straight', 0.5),\n",
       " ('appealing', 0.5),\n",
       " ('flattened', 0.5),\n",
       " ('abrasive', 0.49),\n",
       " ('volatile', 0.51),\n",
       " ('manageable', 0.5),\n",
       " ('celebrated', 0.5),\n",
       " ('incompetent', 0.5),\n",
       " ('ironic', 0.51),\n",
       " ('crisp', 0.49),\n",
       " ('innumerable', 0.5),\n",
       " ('ripe', 0.5),\n",
       " ('approachable', 0.51),\n",
       " ('sunburnt', 0.5),\n",
       " ('agile', 0.5),\n",
       " ('faux', 0.51),\n",
       " ('olden', 0.51),\n",
       " ('lengthiest', 0.5),\n",
       " ('visual', 0.49),\n",
       " ('obsessed', 0.49),\n",
       " ('perfect', 0.5),\n",
       " ('hospitable', 0.5),\n",
       " ('worldly', 0.51),\n",
       " ('ordinary', 0.49),\n",
       " ('gilled', 0.5),\n",
       " ('hip', 0.5),\n",
       " ('heatable', 0.51),\n",
       " ('sunburned', 0.5),\n",
       " ('fervent', 0.51),\n",
       " ('make-believe', 0.49),\n",
       " ('demonic', 0.5),\n",
       " ('dependable', 0.5),\n",
       " ('hipper', 0.5),\n",
       " ('stabilizing', 0.5),\n",
       " ('overt', 0.51),\n",
       " ('climactic', 0.5),\n",
       " ('steep', 0.5),\n",
       " ('material', 0.49),\n",
       " ('weeklong', 0.49),\n",
       " ('thrown-away', 0.5),\n",
       " ('understood', 0.49)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(uw)\n",
    "uw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96174c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e897a46",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6835b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "019e25f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repellent, 0.520, serving or tending to repel; highly offensive; arousing aversion or disgust; incapable of absorbing or mixing with\n",
      "--------\n",
      "stuffed, 0.520, filled with something; crammed with food\n",
      "--------\n",
      "humane, 0.520, pertaining to or concerned with the humanities; marked or motivated by concern with the alleviation of suffering; showing evidence of moral and intellectual advancement\n",
      "--------\n",
      "untested, 0.510, not tried or tested by experience; not yet proved or subjected to testing\n",
      "--------\n",
      "sanitized, 0.510, made sanitary\n",
      "--------\n",
      "pretentious, 0.510, making claim to or creating an appearance of (often undeserved) importance or distinction; intended to attract notice and impress others; (of a display) tawdry or vulgar\n",
      "--------\n",
      "funkier, 0.520, offensively malodorous; (of jazz) having the soulful feeling of early blues; stylish and modern in an unconventional way; in a state of cowardly fright\n",
      "--------\n",
      "unsightly, 0.530, unpleasant to look at\n",
      "--------\n",
      "educated, 0.530, possessing an education (especially having more than average knowledge); characterized by full comprehension of the problem involved\n",
      "--------\n",
      "ended, 0.520, having come or been brought to a conclusion\n",
      "--------\n",
      "limited, 0.530, small in range or scope; subject to limits or subjected to limits; including only a part; mediocre; not excessive; having a specific function or scope; not unlimited\n",
      "--------\n",
      "separate, 0.510, independent; not united or joint; standing apart; not attached to or supported by anything; separated according to race, sex, class, or religion; have the connection undone; having become separate\n",
      "--------\n",
      "melodramatic, 0.530, having the excitement and emotional appeal of melodrama; characteristic of acting or a stage performance; often affected\n",
      "--------\n",
      "under, 0.520, located below or beneath something else; lower in rank, power, or authority\n",
      "--------\n",
      "competent, 0.520, properly or sufficiently qualified or capable or efficient; adequate for the purpose; legally qualified or sufficient\n",
      "--------\n",
      "adhesive, 0.520, tending to adhere\n",
      "--------\n",
      "commemorative, 0.530, intended as a commemoration\n",
      "--------\n",
      "toothless, 0.530, lacking teeth; lacking necessary force for effectiveness\n",
      "--------\n",
      "understated, 0.520, exhibiting restrained good taste\n",
      "--------\n",
      "overloaded, 0.520, loaded past capacity\n",
      "--------\n",
      "varied, 0.510, characterized by variety; widely different; broken away from sameness or identity or duplication\n",
      "--------\n",
      "incurable, 0.530, incapable of being cured; unalterable in disposition or habits\n",
      "--------\n",
      "repugnant, 0.530, offensive to the mind\n",
      "--------\n",
      "perennial, 0.530, lasting three seasons or more; lasting an indefinitely long time; suggesting self-renewal; recurring again and again\n",
      "--------\n",
      "altruistic, 0.530, showing unselfish concern for the welfare of others\n",
      "--------\n",
      "ocular, 0.510, of or relating to or resembling the eye; relating to or using sight; visible; - Shakespeare\n",
      "--------\n",
      "subordinate, 0.530, lower in rank or importance; subject or submissive to authority or the control of another; (of a clause) unable to stand alone syntactically as a complete sentence\n",
      "--------\n",
      "opposite, 0.530, being directly across from each other; facing; - Longfellow; of leaves etc; growing in pairs on either side of a stem; moving or facing away from each other; the other one of a complementary pair; altogether different in nature or quality or significance; ; - Charles Reade; characterized by opposite extremes; completely opposed\n",
      "--------\n",
      "forgiving, 0.530, inclined or able to forgive and show mercy; providing absolution\n",
      "--------\n",
      "kindest, 0.510, having or showing a tender and considerate and helpful nature; used especially of persons and their behavior; agreeable, conducive to comfort; tolerant and forgiving under provocation\n",
      "--------\n",
      "parked, 0.530, that have been left\n",
      "--------\n",
      "unhindered, 0.520, not slowed or blocked or interfered with\n",
      "--------\n",
      "apparent, 0.530, clearly revealed to the mind or the senses or judgment; appearing as such but not necessarily so\n",
      "--------\n",
      "rudimentary, 0.520, being or involving basic facts or principles; being in the earliest stages of development; not fully developed in mature animals\n",
      "--------\n",
      "fatter, 0.520, having an (over)abundance of flesh; having a relatively large diameter; containing or composed of fat; lucrative; marked by great fruitfulness\n",
      "--------\n",
      "fiery, 0.510, characterized by intense emotion; like or suggestive of fire; very intense\n",
      "--------\n",
      "ubiquitous, 0.530, being present everywhere at once\n",
      "--------\n",
      "livid, 0.520, anemic looking from illness or emotion; ; ; ; ; - Mary W. Shelley; (of a light) imparting a deathlike luminosity; ; - E.A.Poe; furiously angry; discolored by coagulation of blood beneath the skin\n",
      "--------\n",
      "superstitious, 0.520, showing ignorance of the laws of nature and faith in magic or chance\n",
      "--------\n",
      "uncorrected, 0.510, left faulty or wrong; not subjected to correction or discipline\n",
      "--------\n",
      "turbulent, 0.510, characterized by unrest or disorder or insubordination; (of a liquid) agitated vigorously; in a state of turbulence\n",
      "--------\n",
      "satisfactory, 0.520, giving satisfaction; meeting requirements\n",
      "--------\n",
      "furious, 0.510, marked by extreme and violent energy; marked by extreme anger; (of the elements) as if showing violent anger\n",
      "--------\n",
      "off-white, 0.530, of something having a color tending toward white\n",
      "--------\n",
      "cooperative, 0.510, involving the joint activity of two or more; done with or working with others for a common purpose or benefit; willing to adjust to differences in order to obtain agreement\n",
      "--------\n",
      "real, 0.520, being or occurring in fact or actuality; having verified existence; not illusory; ; ; ; ; ; - Longfellow; no less than what is stated; worthy of the name; not to be taken lightly; capable of being treated as fact; being or reflecting the essential or genuine character of something; ; - G.K.Chesterton; of, relating to, or representing an amount that is corrected for inflation; having substance or capable of being treated as fact; not imaginary; ; ; - Shakespeare; (of property) fixed or immovable; coinciding with reality; - F.A.Olafson\n",
      "--------\n",
      "shoddy, 0.530, cheap and shoddy; - Judith Crist; of inferior workmanship and materials; designed to deceive or mislead either deliberately or inadvertently\n",
      "--------\n",
      "neighborly, 0.530, exhibiting the qualities expected in a friendly neighbor\n",
      "--------\n",
      "nigher, 0.530, not far distant in time or space or degree or circumstances; being on the left side\n",
      "--------\n",
      "novel, 0.520, original and of a kind not seen before; pleasantly new or different\n",
      "--------\n",
      "centered, 0.530, being or placed in the center\n",
      "--------\n",
      "firm, 0.520, marked by firm determination or resolution; not shakable; not soft or yielding to pressure; strong and sure; not subject to revision or change; (of especially a person's physical features) not shaking or trembling; not liable to fluctuate or especially to fall; securely established; possessing the tone and resiliency of healthy tissue; securely fixed in place; unwavering in devotion to friend or vow or cause; ; ; - Campaign song for William Henry Harrison\n",
      "--------\n",
      "redeeming, 0.510, bringing about salvation or redemption from sin; compensating for some fault or defect\n",
      "--------\n",
      "unappealing, 0.520, (of characters in literature or drama) tending to evoke antipathetic feelings; not able to attract favorable attention\n",
      "--------\n",
      "cohesive, 0.520, causing cohesion; cohering or tending to cohere; well integrated\n",
      "--------\n",
      "brief, 0.520, of short duration or distance; concise and succinct; (of clothing) very short\n",
      "--------\n",
      "ready, 0.520, completely prepared or in condition for immediate action or use or progress; (of especially money) immediately available; mentally disposed; made suitable and available for immediate use; apprehending and responding with speed and sensitivity\n",
      "--------\n",
      "16th, 0.510, coming next after the fifteenth in position\n",
      "--------\n",
      "eminent, 0.520, standing above others in quality or position; of imposing height; especially standing out above others\n",
      "--------\n",
      "firmest, 0.520, marked by firm determination or resolution; not shakable; not soft or yielding to pressure; strong and sure; not subject to revision or change; (of especially a person's physical features) not shaking or trembling; not liable to fluctuate or especially to fall; securely established; possessing the tone and resiliency of healthy tissue; securely fixed in place; unwavering in devotion to friend or vow or cause; ; ; - Campaign song for William Henry Harrison\n",
      "--------\n",
      "far-off, 0.520, very far away in space or time\n",
      "--------\n",
      "splashier, 0.530, characterized by water flying about haphazardly; marked by ostentation but often tasteless; covered with patches of bright color\n",
      "--------\n",
      "legendary, 0.520, so celebrated as to having taken on the nature of a legend; celebrated in fable or legend\n",
      "--------\n",
      "haired, 0.520, having or covered with hair\n",
      "--------\n",
      "respectable, 0.520, characterized by socially or conventionally acceptable morals; deserving of esteem and respect; large in amount or extent or degree\n",
      "--------\n",
      "well-rounded, 0.520, many-sided\n",
      "--------\n",
      "prestigious, 0.530, having an illustrious reputation; respected; exerting influence by reason of high status or prestige\n",
      "--------\n",
      "intermediate, 0.510, lying between two extremes in time or space or state; around the middle of a scale of evaluation\n",
      "--------\n",
      "abhorrent, 0.530, offensive to the mind\n",
      "--------\n",
      "28th, 0.520, coming next after the twenty-seventh in position\n",
      "--------\n",
      "precise, 0.530, sharply exact or accurate or delimited; (of ideas, images, representations, expressions) characterized by perfect conformity to fact or truth ; strictly correct\n",
      "--------\n",
      "torrential, 0.520, relating to or resulting from the action of a torrent; resembling a torrent in force and abundance; ; ; - Winthrop Sargeant; pouring in abundance\n",
      "--------\n",
      "progressive, 0.530, favoring or promoting progress; favoring or promoting reform (often by government action); (of taxes) adjusted so that the rate increases as the amount of income increases; gradually advancing in extent; (of a card game or a dance) involving a series of sections for which the participants successively change place or relative position; advancing in severity\n",
      "--------\n",
      "recurring, 0.530, coming back\n",
      "--------\n",
      "cognitive, 0.530, of or being or relating to or involving cognition\n",
      "--------\n",
      "low-level, 0.520, not intense; lower in rank or importance; at a low level in rank or importance; occurring at a relatively low altitude\n",
      "--------\n",
      "over, 0.520, having come or been brought to a conclusion\n",
      "--------\n",
      "expected, 0.530, considered likely or probable to happen or arrive\n",
      "--------\n",
      "zesty, 0.520, having an agreeably pungent taste; marked by spirited enjoyment\n",
      "--------\n",
      "funky, 0.520, offensively malodorous; (of jazz) having the soulful feeling of early blues; stylish and modern in an unconventional way; in a state of cowardly fright\n",
      "--------\n",
      "allusive, 0.510, characterized by indirect references\n",
      "--------\n",
      "globular, 0.530, having the shape of a sphere or ball; ; ; - Zane Grey\n",
      "--------\n",
      "tired, 0.510, depleted of strength or energy; repeated too often; overfamiliar through overuse\n",
      "--------\n",
      "forced, 0.520, produced by or subjected to forcing; forced or compelled; made necessary by an unexpected situation or emergency; lacking spontaneity; not natural\n",
      "--------\n",
      "firmer, 0.520, marked by firm determination or resolution; not shakable; not soft or yielding to pressure; strong and sure; not subject to revision or change; (of especially a person's physical features) not shaking or trembling; not liable to fluctuate or especially to fall; securely established; possessing the tone and resiliency of healthy tissue; securely fixed in place; unwavering in devotion to friend or vow or cause; ; ; - Campaign song for William Henry Harrison\n",
      "--------\n",
      "fattest, 0.520, having an (over)abundance of flesh; having a relatively large diameter; containing or composed of fat; lucrative; marked by great fruitfulness\n",
      "--------\n",
      "indestructible, 0.530, not easily destroyed; very long lasting\n",
      "--------\n",
      "horrific, 0.520, grossly offensive to decency or morality; causing horror; causing fear or dread or terror\n",
      "--------\n",
      "fascinating, 0.530, capable of arousing and holding the attention; capturing interest as if by a spell\n",
      "--------\n",
      "nigh, 0.530, not far distant in time or space or degree or circumstances; being on the left side\n",
      "--------\n",
      "selfless, 0.530, showing unselfish concern for the welfare of others\n",
      "--------\n",
      "damaging, 0.510, (sometimes followed by `to') causing harm or injury; designed or tending to discredit, especially without positive or helpful suggestions\n",
      "--------\n",
      "second-best, 0.520, next to the best\n",
      "--------\n",
      "ball-shaped, 0.530, having the shape of a sphere or ball; ; ; - Zane Grey\n",
      "--------\n",
      "omnipresent, 0.530, being present everywhere at once\n",
      "--------\n",
      "bleak, 0.520, offering little or no hope; ; ; - J.M.Synge; providing no shelter or sustenance; unpleasantly cold and damp\n",
      "--------\n",
      "realizable, 0.520, capable of being realized; capable of existing or taking place or proving true; possible to do\n",
      "--------\n",
      "verbal, 0.510, communicated in the form of words; of or relating to or formed from words in general; of or relating to or formed from a verb; relating to or having facility in the use of words; expressed in spoken words; prolix; - Shakespeare\n",
      "--------\n",
      "elementary, 0.520, easy and not involved or complicated; of or pertaining to or characteristic of elementary school or elementary education; of or being the essential or basic part\n",
      "--------\n",
      "inconspicuous, 0.520, not prominent or readily noticeable\n",
      "--------\n",
      "great, 0.530, relatively large in size or number or extent; larger than others of its kind; of major significance or importance; remarkable or out of the ordinary in degree or magnitude or effect; very good; uppercase; in an advanced stage of pregnancy\n",
      "--------\n",
      "splendid, 0.520, having great beauty and splendor; very good;of the highest quality; characterized by grandeur\n",
      "--------\n",
      "humanitarian, 0.510, marked by humanistic values and devotion to human welfare; of or relating to or characteristic of humanitarianism\n",
      "--------\n",
      "loosened, 0.510, straightened out\n",
      "--------\n",
      "necessary, 0.520, absolutely essential; unavoidably determined by prior circumstances\n",
      "--------\n",
      "weighty, 0.520, having relatively great weight; heavy; powerfully persuasive; of great gravity or crucial import; requiring serious thought; weighing heavily on the spirit; causing anxiety or worry; excessively fat\n",
      "--------\n",
      "wrong, 0.520, not correct; not in conformity with fact or truth; contrary to conscience or morality or law; not appropriate for a purpose or occasion; not functioning properly; based on or acting or judging in error; not in accord with established usage or procedure; used of the side of cloth or clothing intended to face inward; badly timed; characterized by errors; not agreeing with a model or not following established rules; ; ; the wrong side of the road\"\n",
      "--------\n",
      "briefest, 0.520, of short duration or distance; concise and succinct; (of clothing) very short\n",
      "--------\n",
      "indicative, 0.530, relating to the mood of verbs that is used simple in declarative statements; (usually followed by `of') pointing out or revealing clearly\n",
      "--------\n",
      "inoffensive, 0.510, not causing anger or annoyance; giving no offense; substituting a mild term for a harsher or distasteful one\n",
      "--------\n",
      "superb, 0.530, of surpassing excellence; surpassingly good\n",
      "--------\n",
      "corresponding, 0.520, accompanying; similar especially in position or purpose; conforming in every respect\n",
      "--------\n",
      "well-informed, 0.510, possessing sound knowledge\n",
      "--------\n",
      "prolific, 0.510, intellectually productive; bearing in abundance especially offspring\n",
      "--------\n",
      "untried, 0.510, not tried or tested by experience; not yet proved or subjected to testing\n",
      "--------\n",
      "disgusted, 0.510, having a strong distaste from surfeit\n",
      "--------\n",
      "risk-free, 0.520, thought to be devoid of risk\n",
      "--------\n",
      "well-adjusted, 0.530, free from psychological disorder\n",
      "--------\n",
      "greater, 0.520, greater in size or importance or degree; relatively large in size or number or extent; larger than others of its kind; of major significance or importance; remarkable or out of the ordinary in degree or magnitude or effect; very good; uppercase; in an advanced stage of pregnancy\n",
      "--------\n",
      "papery, 0.520, thin and paperlike; of or like paper\n",
      "--------\n",
      "garish, 0.520, tastelessly showy\n",
      "--------\n",
      "abbreviated, 0.510, (of clothing) very short; cut short in duration\n",
      "--------\n",
      "faddish, 0.510, intensely fashionable for a short time\n",
      "--------\n",
      "folksy, 0.520, characteristic of country life; very informal and familiar\n",
      "--------\n",
      "level, 0.520, having a surface without slope, tilt in which no part is higher or lower than another; not showing abrupt variations; ; - Louis Auchincloss; being on a precise horizontal plane; oriented at right angles to the plumb; of the score in a contest\n",
      "--------\n",
      "sheeny, 0.520, reflecting light\n",
      "--------\n",
      "splashy, 0.530, characterized by water flying about haphazardly; marked by ostentation but often tasteless; covered with patches of bright color\n",
      "--------\n",
      "juvenile, 0.510, of or relating to or characteristic of or appropriate for children or young people; displaying or suggesting a lack of maturity\n",
      "--------\n",
      "existential, 0.530, derived from experience or the experience of existence; - Benjamin Farrington; - John Dewey; of or as conceived by existentialism; relating to or dealing with existence (especially with human existence)\n",
      "--------\n",
      "shoddier, 0.530, cheap and shoddy; - Judith Crist; of inferior workmanship and materials; designed to deceive or mislead either deliberately or inadvertently\n",
      "--------\n",
      "efficacious, 0.510, marked by qualities giving the power to produce an intended effect; -Aldous Huxley; producing or capable of producing an intended result or having a striking effect; -LewisMumford\n",
      "--------\n",
      "drafty, 0.520, not airtight\n",
      "--------\n",
      "everyday, 0.520, found in the ordinary course of events; ; ; - Anita Diamant; appropriate for ordinary or routine occasions; commonplace and ordinary\n",
      "--------\n",
      "kind, 0.510, having or showing a tender and considerate and helpful nature; used especially of persons and their behavior; agreeable, conducive to comfort; tolerant and forgiving under provocation\n",
      "--------\n",
      "inflationary, 0.510, associated with or tending to cause increases in inflation\n",
      "--------\n",
      "all-round, 0.520, many-sided\n",
      "--------\n",
      "all-around, 0.520, many-sided\n",
      "--------\n",
      "profitable, 0.510, yielding material gain or profit\n",
      "--------\n",
      "bleakest, 0.520, offering little or no hope; ; ; - J.M.Synge; providing no shelter or sustenance; unpleasantly cold and damp\n",
      "--------\n",
      "fat, 0.520, having an (over)abundance of flesh; having a relatively large diameter; containing or composed of fat; lucrative; marked by great fruitfulness\n",
      "--------\n",
      "irremovable, 0.520, incapable of being removed or away or dismiss\n",
      "--------\n",
      "shoddiest, 0.530, cheap and shoddy; - Judith Crist; of inferior workmanship and materials; designed to deceive or mislead either deliberately or inadvertently\n",
      "--------\n",
      "stately, 0.520, impressive in appearance; of size and dignity suggestive of a statue; refined or imposing in manner or appearance; befitting a royal court\n",
      "--------\n",
      "changing, 0.520, marked by continuous change or effective action\n",
      "--------\n",
      "fuzzy, 0.520, covering with fine light hairs; indistinct or hazy in outline; confused and not coherent; not clearly thought out\n",
      "--------\n",
      "hands-on, 0.510, involving active participation\n",
      "--------\n",
      "collateral, 0.520, descended from a common ancestor but through different lines; serving to support or corroborate; accompany, concomitant; situated or running side by side\n",
      "--------\n",
      "astonishing, 0.520, surprising greatly; so surprisingly impressive as to stun or overwhelm\n",
      "--------\n",
      "unpalatable, 0.520, not pleasant or acceptable to the taste or mind\n",
      "--------\n",
      "eccentric, 0.530, conspicuously or grossly unconventional or unusual; not having a common center; not concentric\n",
      "--------\n",
      "fizzy, 0.530, hissing and bubbling\n",
      "--------\n",
      "awry, 0.520, turned or twisted toward one side; - G.K.Chesterton; not functioning properly\n",
      "--------\n",
      "transitional, 0.520, of or relating to or characterized by transition\n",
      "--------\n",
      "flash, 0.520, tastelessly showy\n",
      "--------\n",
      "amusing, 0.520, providing enjoyment; pleasantly entertaining; arousing or provoking laughter\n",
      "--------\n",
      "important, 0.530, of great significance or value; important in effect or meaning; of extreme importance; vital to the resolution of a crisis; having authority or ascendancy or influence; having or suggesting a consciousness of high position\n",
      "--------\n",
      "energizing, 0.520, supplying motive force; - H.O.Taylor\n",
      "--------\n",
      "fizzing, 0.530, hissing and bubbling\n",
      "--------\n",
      "time-consuming, 0.520, of a task that takes time and patience\n",
      "--------\n",
      "ever-changing, 0.520, marked by continuous change or effective action\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# Find more Mental Uncertain Words\n",
    "\n",
    "uw=[]\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "        \n",
    "    if pred[i]>0.51 and pred[i]<0.53:\n",
    "        uw.append((w,round(pred[i][0],2)))\n",
    "        \n",
    "random.shuffle(uw)\n",
    "\n",
    "for w,s in uw:\n",
    "    t=adj.loc[adj.word==w,'text'].values[0]\n",
    "    print(\"%s, %.3f, %s\"%(w,s,t))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99d2b1ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# annotate training samples from those most uncertain words in round2, 1:1\n",
    "desc3=['reductive','crisper','noticed','discarded','countless','mythical','snazzy','uppermost','full',\n",
    "       'tenable','ambiguous','stuffy','intricate','abysmal','strengthened','orange-brown','salvageable',\n",
    "       'alive','stinking','nebulous']\n",
    "\n",
    "opin3=['alluring','haunted','merciful','wacky','evil','conscionable','fiendish','addictive','demeaning',\n",
    "       'appealing','ironic','understood','satisfactory','pretentious','repugnant','altruistic','kindest',\n",
    "       'furious','horrific','fascinating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9d2bb117",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc3+opin3:\n",
    "    if w in testset['word']:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95488b79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc_all=desc+desc2+desc3\n",
    "opin_all=opin+opin2+opin3\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train=pd.DataFrame()\n",
    "train['word'],train['text'],train['target']=list(zip(*(trainset)))\n",
    "\n",
    "train.to_csv('Data/train.v6.3.round3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9318542",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d531ac89",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is done by `train.py` with trainset `Data/train.v6.3.round3.csv`. Remember setting Config.is_predict=False in `train.py` before training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bba2bb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "365bbbc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.696\n",
      "positive::recall 0.444\n",
      "negative::precision 0.740\n",
      "negative::recall 0.891\n",
      "F1: 0.54\n",
      "N F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.3.1.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd118f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### UncertainWords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b9e1336",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Uncertain words\n",
    "uw=[]\n",
    "for i,w in enumerate(adj['word'].tolist()):        \n",
    "    if pred[i]>0.48 and pred[i]<0.52:\n",
    "        uw.append((w,round(pred[i][0],4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7ceafd2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecf00c63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "involved, 0.483, connected by participation or association or use; entangled or hindered as if e.g. in mire; emotionally involved; highly complex or intricate and occasionally devious; ; ; ; ; ; ; ; - Sir Walter Scott; enveloped\n",
      "--------\n",
      "lenient, 0.492, tolerant or lenient; not strict; characterized by tolerance and mercy\n",
      "--------\n",
      "right-wing, 0.511, believing in or supporting tenets of the political right\n",
      "--------\n",
      "wispy, 0.495, thin and weak; - Edmund Wilson; lacking clarity or distinctness\n",
      "--------\n",
      "unchecked, 0.511, not restrained or controlled\n",
      "--------\n",
      "svelte, 0.494, showing a high degree of refinement and the assurance that comes from wide social experience; moving and bending with ease; being of delicate or slender build; - Frank Norris\n",
      "--------\n",
      "concerned, 0.480, feeling or showing worry or solicitude; involved in or affected by or having a claim to or share in; culpably involved\n",
      "--------\n",
      "offending, 0.517, offending against or breaking a law or rule\n",
      "--------\n",
      "barbecued, 0.519, cooked over an outdoor grill\n",
      "--------\n",
      "impromptu, 0.483, with little or no preparation or forethought\n",
      "--------\n",
      "detrimental, 0.515, (sometimes followed by `to') causing harm or injury\n",
      "--------\n",
      "grizzly, 0.501, showing characteristics of age, especially having grey or white hair; -Coleridge\n",
      "--------\n",
      "beautiful, 0.503, delighting the senses or exciting intellectual or emotional admiration; (of weather) highly enjoyable\n",
      "--------\n",
      "plush, 0.494, characterized by extravagance and profusion\n",
      "--------\n",
      "dastardly, 0.506, despicably cowardly; - F.D. Roosevelt\n",
      "--------\n",
      "deceptive, 0.481, causing one to believe what is not true or fail to believe what is true; designed to deceive or mislead either deliberately or inadvertently\n",
      "--------\n",
      "obedient, 0.517, dutifully complying with the commands or instructions of those in authority; ; ; ; - Edmund Burke\n",
      "--------\n",
      "sincerest, 0.485, open and genuine; not deceitful; characterized by a firm and humorless belief in the validity of your opinions\n",
      "--------\n",
      "obsequious, 0.507, attempting to win favor from influential people by flattery; attentive in an ingratiating or servile manner\n",
      "--------\n",
      "calculating, 0.489, used of persons\n",
      "--------\n",
      "modern-day, 0.493, characteristic of the present\n",
      "--------\n",
      "craziest, 0.505, affected with madness or insanity; foolish; totally unsound; possessed by inordinate excitement; bizarre or fantastic; intensely enthusiastic about or preoccupied with\n",
      "--------\n",
      "urbane, 0.502, showing a high degree of refinement and the assurance that comes from wide social experience\n",
      "--------\n",
      "glorified, 0.497, accorded sacrosanct or authoritative standing\n",
      "--------\n",
      "provable, 0.497, capable of being demonstrated or proved; ; ; - Walter Bagehot\n",
      "--------\n",
      "such, 0.499, of so extreme a degree or extent\n",
      "--------\n",
      "granted, 0.506, acknowledged as a supposition\n",
      "--------\n",
      "meatless, 0.496, lacking meat\n",
      "--------\n",
      "inseparable, 0.500, not capable of being separated\n",
      "--------\n",
      "after-school, 0.489, outside regular school hours\n",
      "--------\n",
      "warmed, 0.493, having been warmed up\n",
      "--------\n",
      "jittery, 0.512, characterized by jerky movements; being in a tense state\n",
      "--------\n",
      "congested, 0.498, overfull as with blood\n",
      "--------\n",
      "21st, 0.488, coming next after the twentieth in position\n",
      "--------\n",
      "mincing, 0.489, affectedly dainty or refined\n",
      "--------\n",
      "disconcerting, 0.481, causing an emotional disturbance; - Herb Caen\n",
      "--------\n",
      "ascetic, 0.518, pertaining to or characteristic of an ascetic or the practice of rigorous self-discipline; practicing great self-denial; - William James\n",
      "--------\n",
      "bracing, 0.502, imparting vitality and energy\n",
      "--------\n",
      "forgetful, 0.506, (of memory) deficient in retentiveness or range; not mindful or attentive; - G.B.Shaw; failing to keep in mind\n",
      "--------\n",
      "after-hours, 0.487, after closing time especially a legally established closing time\n",
      "--------\n",
      "convinced, 0.492, persuaded of; very sure; having a strong belief or conviction\n",
      "--------\n",
      "enough, 0.509, sufficient for the purpose\n",
      "--------\n",
      "egregious, 0.488, conspicuously and outrageously bad or reprehensible\n",
      "--------\n",
      "bold, 0.490, fearless and daring; clear and distinct; very steep; having a prominent and almost vertical front\n",
      "--------\n",
      "unpalatable, 0.489, not pleasant or acceptable to the taste or mind\n",
      "--------\n",
      "key, 0.481, serving as an essential component\n",
      "--------\n",
      "happy, 0.507, enjoying or showing or marked by joy or pleasure; marked by good fortune; eagerly disposed to act or to be of service; well expressed and to the point\n",
      "--------\n",
      "nonalcoholic, 0.497, characterized by the absence of alcohol\n",
      "--------\n",
      "boldest, 0.490, fearless and daring; clear and distinct; very steep; having a prominent and almost vertical front\n",
      "--------\n",
      "asthmatic, 0.514, relating to breathing with a whistling sound\n",
      "--------\n",
      "mum, 0.490, failing to speak or communicate etc when expected to\n",
      "--------\n",
      "fizzy, 0.507, hissing and bubbling\n",
      "--------\n",
      "nearby, 0.495, close at hand\n",
      "--------\n",
      "second-best, 0.488, next to the best\n",
      "--------\n",
      "peaceful, 0.487, not disturbed by strife or turmoil or war; peacefully resistant in response to injustice\n",
      "--------\n",
      "dissenting, 0.506, disagreeing, especially with a majority\n",
      "--------\n",
      "rescued, 0.518, delivered from danger\n",
      "--------\n",
      "wild, 0.490, marked by extreme lack of restraint or control; in a natural state; not tamed or domesticated or cultivated; in a state of extreme emotion; deviating widely from an intended course; (of colors or sounds) intensely vivid or loud; without a basis in reason or fact; talking or behaving irrationally; involving risk or danger; fanciful and unrealistic; foolish; located in a dismal or remote area; desolate; intensely enthusiastic about or preoccupied with; without civilizing influences; ; ; ; -Margaret Meade; (of the elements) as if showing violent anger\n",
      "--------\n",
      "seedy, 0.501, full of seeds; shabby and untidy; ; - Mark Twain; somewhat ill or prone to illness; morally degraded; ; ; ; - Seattle Weekly; - James Joyce\n",
      "--------\n",
      "acting, 0.485, serving temporarily especially as a substitute\n",
      "--------\n",
      "mechanic, 0.497, resembling the action of a machine; - Emily Dickenson\n",
      "--------\n",
      "poverty-stricken, 0.481, poor enough to need help from others\n",
      "--------\n",
      "inviting, 0.482, attractive and tempting\n",
      "--------\n",
      "sane, 0.492, mentally healthy; free from mental disorder; marked by sound judgment\n",
      "--------\n",
      "exemplary, 0.501, worthy of imitation; being or serving as an illustration of a type; serving to warn\n",
      "--------\n",
      "obscure, 0.491, not clearly understood or expressed; ; -Anatole Broyard; - P.A.Sorokin; - John Locke; marked by difficulty of style or expression; difficult to find; not famous or acclaimed; not drawing attention; remote and separate physically or socially; ; - W.H.Hudson\n",
      "--------\n",
      "sedate, 0.500, characterized by dignity and propriety; dignified and somber in manner or character and committed to keeping promises\n",
      "--------\n",
      "perkier, 0.493, characterized by liveliness and lightheartedness\n",
      "--------\n",
      "air-filled, 0.518, full of air\n",
      "--------\n",
      "given, 0.488, acknowledged as a supposition; (usually followed by `to') naturally disposed toward\n",
      "--------\n",
      "three-way, 0.489, involving three parties or elements\n",
      "--------\n",
      "swish, 0.513, elegant and fashionable; ; ; ; - Julia Child\n",
      "--------\n",
      "fused, 0.496, joined together into a whole\n",
      "--------\n",
      "sneak, 0.494, marked by quiet and caution and secrecy; taking pains to avoid being observed\n",
      "--------\n",
      "righteous, 0.488, characterized by or proceeding from accepted standards of morality or justice; - James 5:16; morally justified\n",
      "--------\n",
      "welcome, 0.504, giving pleasure or satisfaction or received with pleasure or freely granted\n",
      "--------\n",
      "mildest, 0.496, moderate in type or degree or effect or force; far from extreme; humble in spirit or manner; suggesting retiring mildness or even cowed submissiveness; mild and pleasant\n",
      "--------\n",
      "mightiest, 0.483, having or showing great strength or force or intensity; ; ; - Bulwer-Lytton\n",
      "--------\n",
      "happiest, 0.507, enjoying or showing or marked by joy or pleasure; marked by good fortune; eagerly disposed to act or to be of service; well expressed and to the point\n",
      "--------\n",
      "deprived, 0.495, marked by deprivation especially of the necessities of life or healthful environmental influences\n",
      "--------\n",
      "thoughtful, 0.512, having intellectual depth; exhibiting or characterized by careful thought; acting with or showing thought and good sense; taking heed; giving close and thoughtful attention; considerate of the feelings or well-being of others\n",
      "--------\n",
      "deserving, 0.484, worthy of being treated in a particular way; ;  (often used ironically)\n",
      "--------\n",
      "on-site, 0.500, taking place or located at the site\n",
      "--------\n",
      "invigorating, 0.509, imparting strength and vitality\n",
      "--------\n",
      "relaxing, 0.516, affording physical or mental rest\n",
      "--------\n",
      "milder, 0.496, moderate in type or degree or effect or force; far from extreme; humble in spirit or manner; suggesting retiring mildness or even cowed submissiveness; mild and pleasant\n",
      "--------\n",
      "possessed, 0.499, influenced or controlled by a powerful force such as a strong emotion; frenzied as if possessed by a demon\n",
      "--------\n",
      "unromantic, 0.493, neither expressive of nor exciting sexual love or romance\n",
      "--------\n",
      "anomalous, 0.516, deviating from the general or common order or type\n",
      "--------\n",
      "wedded, 0.492, having been taken in marriage\n",
      "--------\n",
      "flyaway, 0.501, guided by whim and fancy; (of hair or clothing) worn loose\n",
      "--------\n",
      "idealized, 0.494, exalted to an ideal perfection or excellence\n",
      "--------\n",
      "clueless, 0.482, totally uninformed about what is going on; not having even a clue from which to infer what is occurring\n",
      "--------\n",
      "white-haired, 0.511, showing characteristics of age, especially having grey or white hair; -Coleridge; favorite\n",
      "--------\n",
      "reputable, 0.491, having a good reputation\n",
      "--------\n",
      "pivotal, 0.520, being of crucial importance; ; - Henry Kissinger\n",
      "--------\n",
      "expectant, 0.491, marked by eager anticipation; in an advanced stage of pregnancy\n",
      "--------\n",
      "hard-to-please, 0.500, (of persons)\n",
      "--------\n",
      "adherent, 0.508, sticking fast\n",
      "--------\n",
      "fleshly, 0.520, marked by the appetites and passions of the body\n",
      "--------\n",
      "tortuous, 0.507, highly complex or intricate and occasionally devious; ; ; ; ; ; ; ; - Sir Walter Scott; marked by repeated turns and bends; not straightforward\n",
      "--------\n",
      "noisiest, 0.515, full of or characterized by loud and nonmusical sounds; attracting attention by showiness or bright colors\n",
      "--------\n",
      "sensible, 0.503, showing reason or sound judgment; able to feel or perceive; readily perceived by the senses; aware intuitively or intellectually of something sensed; ; - Henry Hallam; - Edmund Burke\n",
      "--------\n",
      "balanced, 0.491, being in a state of proper equilibrium\n",
      "--------\n",
      "fatal, 0.512, bringing death; having momentous consequences; of decisive importance; - Saturday Rev; (of events) having extremely unfortunate or dire consequences; bringing ruin; ; ; ; - Charles Darwin; - Douglas MacArthur; controlled or decreed by fate; predetermined\n",
      "--------\n",
      "elite, 0.508, selected as the best\n",
      "--------\n",
      "nonpareil, 0.509, eminent beyond or above comparison\n",
      "--------\n",
      "puffed, 0.508, gathered for protruding fullness\n",
      "--------\n",
      "unctuous, 0.483, unpleasantly and excessively suave or ingratiating in manner or speech\n",
      "--------\n",
      "directive, 0.514, showing the way by conducting or leading; imposing direction on\n",
      "--------\n",
      "struck, 0.510, (used in combination) affected by something overwhelming\n",
      "--------\n",
      "uncooperative, 0.498, unwilling to cooperate; intentionally unaccommodating\n",
      "--------\n",
      "ludicrous, 0.491, broadly or extravagantly humorous; resembling farce; incongruous;inviting ridicule\n",
      "--------\n",
      "upsetting, 0.481, causing an emotional disturbance; - Herb Caen\n",
      "--------\n",
      "pretentious, 0.481, making claim to or creating an appearance of (often undeserved) importance or distinction; intended to attract notice and impress others; (of a display) tawdry or vulgar\n",
      "--------\n",
      "worried, 0.518, afflicted with or marked by anxious uneasiness or trouble or grief; mentally upset over possible misfortune or danger etc\n",
      "--------\n",
      "jumped-up, 0.500, (British informal) upstart\n",
      "--------\n",
      "puff, 0.508, gathered for protruding fullness\n",
      "--------\n",
      "lucid, 0.491, (of language) transparently clear; easily understandable; ; ; - Robert Burton; having a clear mind; capable of thinking and expressing yourself in a clear and consistent manner; transmitting light; able to be seen through with clarity\n",
      "--------\n",
      "returnable, 0.518, that may be returned\n",
      "--------\n",
      "envious, 0.518, showing extreme cupidity; painfully desirous of another's advantages\n",
      "--------\n",
      "glamorous, 0.511, having an air of allure, romance and excitement\n",
      "--------\n",
      "raucous, 0.489, unpleasantly loud and harsh; disturbing the public peace; loud and rough\n",
      "--------\n",
      "sporting, 0.494, exhibiting or calling for sportsmanship or fair play; relating to or used in sports; involving risk or willingness to take a risk; preoccupied with the pursuit of pleasure and especially games of chance\n",
      "--------\n",
      "happier, 0.507, enjoying or showing or marked by joy or pleasure; marked by good fortune; eagerly disposed to act or to be of service; well expressed and to the point\n",
      "--------\n",
      "depleted, 0.513, no longer sufficient\n",
      "--------\n",
      "hyperactive, 0.481, more active than normal\n",
      "--------\n",
      "objectionable, 0.517, causing disapproval or protest; liable to objection or debate; used of something one might take exception to\n",
      "--------\n",
      "ungenerous, 0.504, lacking in magnanimity; - Times Litt. Sup.; unwilling to spend\n",
      "--------\n",
      "nightly, 0.491, happening every night\n",
      "--------\n",
      "threatening, 0.484, threatening or foreshadowing evil or tragic developments; darkened by clouds\n",
      "--------\n",
      "unidentifiable, 0.519, impossible to identify\n",
      "--------\n",
      "affectionate, 0.502, having or displaying warmth or affection\n",
      "--------\n",
      "tolerant, 0.514, showing respect for the rights or opinions or practices of others; tolerant and forgiving under provocation; showing or characterized by broad-mindedness; able to tolerate environmental conditions or physiological stress; showing the capacity for endurance\n",
      "--------\n",
      "commercialized, 0.516, organized principally for financial gain\n",
      "--------\n",
      "ungodly, 0.512, characterized by iniquity; wicked because it is believed to be a sin\n",
      "--------\n",
      "classiest, 0.513, elegant and fashionable; ; ; ; - Julia Child\n",
      "--------\n",
      "childish, 0.510, indicating a lack of maturity\n",
      "--------\n",
      "susceptible, 0.510, (often followed by `of' or `to') yielding readily to or capable of; easily impressed emotionally\n",
      "--------\n",
      "all-important, 0.508, of the greatest importance\n",
      "--------\n",
      "stealthy, 0.494, marked by quiet and caution and secrecy; taking pains to avoid being observed\n",
      "--------\n",
      "bodacious, 0.496, incorrigible; unrestrained by convention or propriety; ; ; - Los Angeles Times; ; ; - Bertrand Russell\n",
      "--------\n",
      "high-grade, 0.517, surpassing in quality\n",
      "--------\n",
      "transitional, 0.492, of or relating to or characterized by transition\n",
      "--------\n",
      "vigorous, 0.501, characterized by forceful and energetic action or activity; strong and active physically or mentally; - W.H.Hudson\n",
      "--------\n",
      "long-winded, 0.504, using or containing too many words\n",
      "--------\n",
      "soft-boiled, 0.481, easily moved to pity or sorrow; (eggs) having the yolk still liquid\n",
      "--------\n",
      "precursory, 0.492, warning of future misfortune\n",
      "--------\n",
      "violent, 0.508, acting with or marked by or resulting from great force or energy or emotional intensity; effected by force or injury rather than natural causes; (of colors or sounds) intensely vivid or loud; marked by extreme intensity of emotions or convictions; inclined to react violently; fervid; characterized by violence or bloodshed; - Andrea Parke; - Thomas Gray; - Hudson Strode\n",
      "--------\n",
      "amateur, 0.514, engaged in as a pastime; lacking professional skill or expertise\n",
      "--------\n",
      "serious, 0.512, concerned with work or important matters rather than play or trivialities; of great consequence; causing fear or anxiety by threatening great harm; appealing to the mind; completely lacking in playfulness; requiring effort or concentration; complex and not easy to answer or solve\n",
      "--------\n",
      "catchy, 0.498, having concealed difficulty; likely to attract attention\n",
      "--------\n",
      "salubrious, 0.506, promoting health; healthful; ; ; ; ; - C.B.Davis; favorable to health of mind or body\n",
      "--------\n",
      "chockful, 0.507, packed full to capacity\n",
      "--------\n",
      "responsive, 0.493, containing or using responses; alternating; readily reacting or replying to people or events or stimuli; showing emotion; reacting to a stimulus\n",
      "--------\n",
      "resolved, 0.495, determined; explained or answered\n",
      "--------\n",
      "verbose, 0.504, using or containing too many words\n",
      "--------\n",
      "insufferable, 0.509, used of persons or their behavior\n",
      "--------\n",
      "feeble, 0.482, pathetically lacking in force or effectiveness; lacking strength or vigor; lacking bodily or muscular strength or vitality; lacking strength; - Nathaniel Hawthorne\n",
      "--------\n",
      "ardent, 0.514, characterized by intense emotion; characterized by strong enthusiasm; glowing or shining like fire; - Alexander Pope\n",
      "--------\n",
      "umpteenth, 0.493, last in an indefinitely numerous series\n",
      "--------\n",
      "13th, 0.488, coming next after the twelfth in position\n",
      "--------\n",
      "compliant, 0.516, disposed or willing to comply\n",
      "--------\n",
      "jam-packed, 0.489, filled to capacity\n",
      "--------\n",
      "cheerful, 0.503, being full of or promoting cheer; having or showing good spirits; pleasantly (even unrealistically) optimistic\n",
      "--------\n",
      "incapable, 0.481, (followed by `of') lacking capacity or ability; not being susceptible to or admitting of something (usually followed by `of'); (followed by `of') not having the temperament or inclination for; not meeting requirements\n",
      "--------\n",
      "taken, 0.495, understood in a certain way; made sense of; be affected with an indisposition\n",
      "--------\n",
      "electric, 0.484, using or providing or producing or transmitting or operated by electricity; (of a situation) exceptionally tense; affected by emotion as if by electricity; thrilling\n",
      "--------\n",
      "understood, 0.506, fully apprehended as to purport or meaning or explanation; implied by or inferred from actions or statements\n",
      "--------\n",
      "mighty, 0.483, having or showing great strength or force or intensity; ; ; - Bulwer-Lytton\n",
      "--------\n",
      "indicative, 0.489, relating to the mood of verbs that is used simple in declarative statements; (usually followed by `of') pointing out or revealing clearly\n",
      "--------\n",
      "dreadful, 0.486, causing fear or dread or terror; exceptionally bad or displeasing; very unpleasant\n",
      "--------\n",
      "rambunctious, 0.486, noisy and lacking in restraint or discipline\n",
      "--------\n",
      "surreal, 0.495, characterized by fantastic imagery and incongruous juxtapositions; --J.C.Powys; resembling a dream\n",
      "--------\n",
      "prudish, 0.512, exaggeratedly proper\n",
      "--------\n",
      "mimic, 0.506, constituting an imitation; - Archibald Alison\n",
      "--------\n",
      "testimonial, 0.496, expressing admiration or appreciation; of or relating to or constituting testimony\n",
      "--------\n",
      "ironic, 0.487, humorously sarcastic or mocking; characterized by often poignant difference or incongruity between what is expected and what actually is\n",
      "--------\n",
      "stressed, 0.516, suffering severe physical strain or distress; bearing a stress or accent\n",
      "--------\n",
      "heavy-laden, 0.495, burdened by cares; -Matt.11:28; bearing a physically heavy weight or load\n",
      "--------\n",
      "muddled, 0.492, confused and vague; used especially of thinking\n",
      "--------\n",
      "uppity, 0.503, presumptuously arrogant; ; - S.V.Benet; - NY Times\n",
      "--------\n",
      "mind-blowing, 0.504, intensely affecting the mind especially in producing hallucinations; intensely affecting the mind or emotions\n",
      "--------\n",
      "colloquial, 0.505, characteristic of informal spoken language or conversation\n",
      "--------\n",
      "fetching, 0.510, very attractive; capturing interest\n",
      "--------\n",
      "intent, 0.516, giving or marked by complete attention to; ; ; - Walter de la Mare\n",
      "--------\n",
      "painful, 0.520, causing physical or psychological pain; causing misery or pain or distress; exceptionally bad or displeasing; causing physical discomfort\n",
      "--------\n",
      "hourlong, 0.511, lasting for an hour\n",
      "--------\n",
      "comic, 0.491, arousing or provoking laughter; of or relating to or characteristic of comedy\n",
      "--------\n",
      "peckish, 0.514, somewhat hungry; easily irritated or annoyed\n",
      "--------\n",
      "engorged, 0.498, overfull as with blood\n",
      "--------\n",
      "sickening, 0.494, causing or able to cause nausea\n",
      "--------\n",
      "sincere, 0.485, open and genuine; not deceitful; characterized by a firm and humorless belief in the validity of your opinions\n",
      "--------\n",
      "cheating, 0.480, not faithful to a spouse or lover; violating accepted standards or rules\n",
      "--------\n",
      "persnickety, 0.513, (used colloquially) overly conceited or arrogant; -Laurent Le Sage; characterized by excessive precision and attention to trivial details\n",
      "--------\n",
      "amalgamated, 0.496, joined together into a whole\n",
      "--------\n",
      "melting, 0.493, becoming liquid\n",
      "--------\n",
      "wordy, 0.504, using or containing too many words\n",
      "--------\n",
      "overactive, 0.481, more active than normal\n",
      "--------\n",
      "backward, 0.491, directed or facing toward the back or rear; (used of temperament or behavior) marked by a retiring nature; retarded in intellectual development; having made less than normal progress\n",
      "--------\n",
      "unbridled, 0.511, not restrained or controlled\n",
      "--------\n",
      "classier, 0.513, elegant and fashionable; ; ; ; - Julia Child\n",
      "--------\n",
      "undercover, 0.519, conducted with or marked by hidden aims or methods\n",
      "--------\n",
      "stabilizing, 0.514, causing to become stable\n",
      "--------\n",
      "unsightly, 0.503, unpleasant to look at\n",
      "--------\n",
      "fateful, 0.515, having momentous consequences; of decisive importance; - Saturday Rev; ominously prophetic; (of events) having extremely unfortunate or dire consequences; bringing ruin; ; ; ; - Charles Darwin; - Douglas MacArthur; controlled or decreed by fate; predetermined\n",
      "--------\n",
      "catastrophic, 0.510, extremely harmful; bringing physical or financial ruin\n",
      "--------\n",
      "knowledgeable, 0.500, highly educated; having extensive information or understanding; alert and fully informed; thoroughly acquainted through study or experience; -W.H.Hudson; - Herbert Read\n",
      "--------\n",
      "unparalleled, 0.508, radically distinctive and without equal\n",
      "--------\n",
      "lone, 0.509, lacking companions or companionship; characterized by or preferring solitude; being the only one; single and isolated from others\n",
      "--------\n",
      "undefined, 0.495, not precisely limited, determined, or distinguished\n",
      "--------\n",
      "adept, 0.492, having or showing knowledge and skill and aptitude\n",
      "--------\n",
      "wicked, 0.490, morally bad in principle or practice; having committed unrighteous acts; intensely or extremely bad or unpleasant in degree or quality; naughtily or annoyingly playful; highly offensive; arousing aversion or disgust\n",
      "--------\n",
      "verbatim, 0.503, in precisely the same words used by a writer or speaker\n",
      "--------\n",
      "political, 0.484, involving or characteristic of politics or parties or politicians; - Daniel Goleman; of or relating to your views about social relationships involving authority or power; of or relating to the profession of governing\n",
      "--------\n",
      "uncomfortable, 0.486, conducive to or feeling mental discomfort; providing or experiencing physical discomfort\n",
      "--------\n",
      "prosaic, 0.502, not fanciful or imaginative; lacking wit or imagination; not challenging; dull and lacking excitement\n",
      "--------\n",
      "rarified, 0.515, having low density; of high moral or intellectual value; elevated in nature or style; ; - Oliver Franks\n",
      "--------\n",
      "unadvised, 0.481, without careful prior deliberation or counsel; having received no information\n",
      "--------\n",
      "uncool, 0.488, (spoken slang) unfashionable and boring\n",
      "--------\n",
      "cutting-edge, 0.518, in accord with the most fashionable ideas or style\n",
      "--------\n",
      "restful, 0.516, affording physical or mental rest\n",
      "--------\n",
      "top-grade, 0.517, surpassing in quality\n",
      "--------\n",
      "mild, 0.496, moderate in type or degree or effect or force; far from extreme; humble in spirit or manner; suggesting retiring mildness or even cowed submissiveness; mild and pleasant\n",
      "--------\n",
      "twenty-first, 0.488, coming next after the twentieth in position\n",
      "--------\n",
      "comforting, 0.515, providing freedom from worry; affording comfort or solace\n",
      "--------\n",
      "short-haired, 0.516, with short hair\n",
      "--------\n",
      "unethical, 0.495, not conforming to approved standards of social or professional behavior\n",
      "--------\n",
      "unconscious, 0.509, not conscious; lacking awareness and the capacity for sensory perception as if asleep or dead; without conscious volition; (followed by `of') not knowing or perceiving; - Charles Dickens\n",
      "--------\n",
      "hunted, 0.504, reflecting the fear or terror of one who is hunted\n",
      "--------\n",
      "back-to-back, 0.501, one after the other\n",
      "--------\n",
      "invalidated, 0.490, deprived of legal force\n",
      "--------\n",
      "bolder, 0.490, fearless and daring; clear and distinct; very steep; having a prominent and almost vertical front\n",
      "--------\n",
      "overabundant, 0.493, excessively abundant\n",
      "--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcendent, 0.484, exceeding or surpassing usual limits especially in excellence; beyond and outside the ordinary range of human experience or understanding\n",
      "--------\n",
      "classy, 0.513, elegant and fashionable; ; ; ; - Julia Child\n",
      "--------\n",
      "serious-minded, 0.498, acting with or showing thought and good sense\n",
      "--------\n",
      "gullible, 0.516, naive and easily deceived or tricked; easily tricked because of being too trusting\n",
      "--------\n",
      "unequaled, 0.508, radically distinctive and without equal\n",
      "--------\n",
      "wishful, 0.490, having or expressing desire for something; desiring or striving for recognition or advancement\n",
      "--------\n",
      "crazy, 0.505, affected with madness or insanity; foolish; totally unsound; possessed by inordinate excitement; bizarre or fantastic; intensely enthusiastic about or preoccupied with\n",
      "--------\n",
      "misguided, 0.480, poorly conceived or thought out; wrong in e.g. opinion or judgment\n",
      "--------\n",
      "innovative, 0.489, ahead of the times; being or producing something like nothing done or experienced or created before\n",
      "--------\n",
      "animal, 0.520, marked by the appetites and passions of the body\n",
      "--------\n",
      "fizzing, 0.507, hissing and bubbling\n",
      "--------\n",
      "meticulous, 0.505, marked by precise accordance with details; marked by extreme care in treatment of details\n",
      "--------\n",
      "contingent, 0.501, possible but not certain to occur; determined by conditions or circumstances that follow; uncertain because of uncontrollable circumstances; - George Eliot\n",
      "--------\n",
      "spiritual, 0.505, concerned with sacred matters or religion or the church; concerned with or affecting the spirit or soul; lacking material body or form or substance; ; -Lewis Mumford; resembling or characteristic of a phantom\n",
      "--------\n",
      "overwhelming, 0.481, so strong as to be irresistible; very intense\n",
      "--------\n",
      "diplomatic, 0.517, relating to or characteristic of diplomacy; using or marked by tact in dealing with sensitive matters or people\n",
      "--------\n",
      "hellish, 0.506, very unpleasant; extremely evil or cruel; expressive of cruelty or befitting hell\n",
      "--------\n",
      "newfangled, 0.512, (of a new kind or fashion) gratuitously new\n",
      "--------\n",
      "methodical, 0.485, characterized by method and orderliness\n",
      "--------\n",
      "evaporated, 0.511, drawn off in the form of vapor\n",
      "--------\n",
      "noisier, 0.515, full of or characterized by loud and nonmusical sounds; attracting attention by showiness or bright colors\n",
      "--------\n",
      "repetitive, 0.494, repetitive and persistent; characterized by repetition\n",
      "--------\n",
      "fly, 0.517, (British informal) not to be deceived or hoodwinked\n",
      "--------\n",
      "homeless, 0.509, without nationality or citizenship; physically or spiritually homeless or deprived of security; - James Stern\n",
      "--------\n",
      "sought-after, 0.502, being searched for\n",
      "--------\n",
      "ignorant, 0.503, uneducated in general; lacking knowledge or sophistication; uneducated in the fundamentals of a given art or branch of learning; lacking knowledge of a specific field; unaware because of a lack of relevant information or knowledge\n",
      "--------\n",
      "banned, 0.511, forbidden by law\n",
      "--------\n",
      "skilful, 0.492, having or showing knowledge and skill and aptitude\n",
      "--------\n",
      "vanished, 0.485, having passed out of existence\n",
      "--------\n",
      "inflationary, 0.510, associated with or tending to cause increases in inflation\n",
      "--------\n",
      "expert, 0.495, having or showing knowledge and skill and aptitude; of or relating to or requiring special knowledge to be understood\n",
      "--------\n",
      "high-pressure, 0.483, aggressively and persistently persuasive\n",
      "--------\n",
      "elliptical, 0.491, rounded like an egg; characterized by extreme economy of expression or omission of superfluous elements; ; - H.O.Taylor\n",
      "--------\n",
      "perky, 0.493, characterized by liveliness and lightheartedness\n",
      "--------\n",
      "schizophrenic, 0.497, suffering from some form of schizophrenia; of or relating to or characteristic of schizophrenia\n",
      "--------\n",
      "brimming, 0.489, filled to capacity\n",
      "--------\n",
      "dated, 0.495, marked by features of the immediate and usually discounted past\n",
      "--------\n",
      "must, 0.498, highly recommended\n",
      "--------\n",
      "broke, 0.488, lacking funds\n",
      "--------\n",
      "starved, 0.499, suffering from lack of food; extremely hungry\n",
      "--------\n",
      "nauseating, 0.494, causing or able to cause nausea\n",
      "--------\n",
      "multipurpose, 0.484, having multiple uses\n",
      "--------\n",
      "blanched, 0.506, anemic looking from illness or emotion; ; ; ; ; - Mary W. Shelley; (especially of plants) developed without chlorophyll by being deprived of light\n",
      "--------\n",
      "uncomplicated, 0.483, lacking complexity; easy and not involved or complicated\n",
      "--------\n",
      "bulimic, 0.509, suffering from bulimia\n",
      "--------\n",
      "ineffectual, 0.488, not producing an intended effect; producing no result or effect; lacking in power or forcefulness\n",
      "--------\n",
      "fortunate, 0.483, having unexpected good fortune; supremely favored; presaging good fortune\n",
      "--------\n",
      "uneasy, 0.493, lacking a sense of security or affording no ease or reassurance; lacking or not affording physical or mental rest; causing or fraught with or showing anxiety; socially uncomfortable; unsure and constrained in manner; relating to bodily unease that causes discomfort\n",
      "--------\n",
      "depressed, 0.498, lower than previously; flattened downward as if pressed from above or flattened along the dorsal and ventral surfaces; filled with melancholy and despondency\n",
      "--------\n",
      "wheezing, 0.514, relating to breathing with a whistling sound\n",
      "--------\n",
      "long-haired, 0.486, with long hair\n",
      "--------\n",
      "lecherous, 0.504, given to excessive indulgence in sexual activity\n",
      "--------\n",
      "punished, 0.506, subjected to a penalty (as pain or shame or restraint or loss) for an offense or fault or in order to coerce some behavior (as a confession or obedience)\n",
      "--------\n",
      "prodigious, 0.495, so great in size or force or extent as to elicit awe; of momentous or ominous significance; - Herman Melville; far beyond what is usual in magnitude or degree\n",
      "--------\n",
      "fortuitous, 0.508, having no cause or apparent cause; occurring by happy chance\n",
      "--------\n",
      "rosy, 0.497, reflecting optimism; having the pinkish flush of health; of blush color; presaging good fortune\n",
      "--------\n",
      "unsubtle, 0.496, lacking subtlety; obvious\n",
      "--------\n",
      "observant, 0.488, paying close attention especially to details; quick to notice; showing quick and keen perception; (of individuals) adhering strictly to laws and rules and customs\n",
      "--------\n",
      "apathetic, 0.513, showing little or no emotion or animation; marked by a lack of interest\n",
      "--------\n",
      "inconstant, 0.500, likely to change frequently often without apparent or cogent reason; variable; ; ; - Shakespeare\n",
      "--------\n",
      "hideous, 0.502, grossly offensive to decency or morality; causing horror; so extremely ugly as to be terrifying\n",
      "--------\n",
      "rabid, 0.510, of or infected by rabies; marked by excessive enthusiasm for and intense devotion to a cause or idea\n",
      "--------\n",
      "diabolical, 0.491, showing the cunning or ingenuity or wickedness typical of a devil; extremely evil or cruel; expressive of cruelty or befitting hell\n",
      "--------\n",
      "miserable, 0.498, very unhappy; full of misery; deserving or inciting pity; ; ; - Galsworthy; of the most contemptible kind; of very poor quality or condition; characterized by physical misery; contemptibly small in amount\n",
      "--------\n",
      "partial, 0.489, being or affecting only a part; not total; showing favoritism; (followed by `of' or `to') having a strong preference or liking for\n",
      "--------\n",
      "aversive, 0.488, tending to repel or dissuade\n",
      "--------\n",
      "catatonic, 0.488, characterized by catatonia especially either rigidity or extreme laxness of limbs\n",
      "--------\n",
      "attempted, 0.486, tried unsuccessfully\n",
      "--------\n",
      "28th, 0.480, coming next after the twenty-seventh in position\n",
      "--------\n",
      "inveterate, 0.490, habitual\n",
      "--------\n",
      "conversational, 0.505, characteristic of informal spoken language or conversation\n",
      "--------\n",
      "jumpy, 0.481, being in a tense state; causing or characterized by jolts and irregular movements\n",
      "--------\n",
      "untraditional, 0.485, not conforming to or in accord with tradition\n",
      "--------\n",
      "weary, 0.493, physically and mentally fatigued\n",
      "--------\n",
      "wildest, 0.490, marked by extreme lack of restraint or control; in a natural state; not tamed or domesticated or cultivated; in a state of extreme emotion; deviating widely from an intended course; (of colors or sounds) intensely vivid or loud; without a basis in reason or fact; talking or behaving irrationally; involving risk or danger; fanciful and unrealistic; foolish; located in a dismal or remote area; desolate; intensely enthusiastic about or preoccupied with; without civilizing influences; ; ; ; -Margaret Meade; (of the elements) as if showing violent anger\n",
      "--------\n",
      "taking, 0.510, very attractive; capturing interest\n",
      "--------\n",
      "blasphemous, 0.503, grossly irreverent toward what is held to be sacred; characterized by profanity or cursing\n",
      "--------\n",
      "wilder, 0.490, marked by extreme lack of restraint or control; in a natural state; not tamed or domesticated or cultivated; in a state of extreme emotion; deviating widely from an intended course; (of colors or sounds) intensely vivid or loud; without a basis in reason or fact; talking or behaving irrationally; involving risk or danger; fanciful and unrealistic; foolish; located in a dismal or remote area; desolate; intensely enthusiastic about or preoccupied with; without civilizing influences; ; ; ; -Margaret Meade; (of the elements) as if showing violent anger\n",
      "--------\n",
      "played, 0.517, (of games) engaged in\n",
      "--------\n",
      "flagrant, 0.488, conspicuously and outrageously bad or reprehensible\n",
      "--------\n",
      "satanic, 0.486, extremely evil or cruel; expressive of cruelty or befitting hell; of or relating to Satan\n",
      "--------\n",
      "intensified, 0.507, made more intense\n",
      "--------\n",
      "unsuspecting, 0.517, not suspicious; (often followed by `of') not knowing or expecting; not thinking likely\n",
      "--------\n",
      "affected, 0.506, acted upon; influenced; speaking or behaving in an artificial way to make an impression; being excited or provoked to the expression of an emotion\n",
      "--------\n",
      "miscellaneous, 0.483, consisting of a haphazard assortment of different kinds; ; ; ; ; ; - I.A.Richards; having many aspects\n",
      "--------\n",
      "pleasing, 0.499, giving pleasure and satisfaction\n",
      "--------\n",
      "uncompetitive, 0.486, not inclined to compete\n",
      "--------\n",
      "efficient, 0.484, being effective without wasting time or effort or expense; able to accomplish a purpose; functioning effectively; -G.B.Shaw\n",
      "--------\n",
      "chock-full, 0.507, packed full to capacity\n",
      "--------\n",
      "off-white, 0.489, of something having a color tending toward white\n",
      "--------\n",
      "unrivaled, 0.509, eminent beyond or above comparison\n",
      "--------\n",
      "hardcore, 0.506, intensely loyal; extremely explicit\n",
      "--------\n",
      "miniature, 0.513, being on a very small scale\n",
      "--------\n",
      "untoward, 0.511, not in keeping with accepted standards of what is right or proper in polite society; contrary to your interests or welfare\n",
      "--------\n",
      "unwary, 0.499, not alert to danger or deception; ; ; - O.J.Campbell\n",
      "--------\n",
      "brightly-colored, 0.504, having a bright color\n",
      "--------\n",
      "confusing, 0.490, causing confusion or disorientation; lacking clarity of meaning; causing confusion or perplexity\n",
      "--------\n",
      "exclamatory, 0.482, sudden and strong\n",
      "--------\n",
      "redeeming, 0.493, bringing about salvation or redemption from sin; compensating for some fault or defect\n",
      "--------\n",
      "cognitive, 0.488, of or being or relating to or involving cognition\n",
      "--------\n",
      "urgent, 0.507, compelling immediate action\n",
      "--------\n",
      "devious, 0.518, indirect in departing from the accepted or proper way; misleading; characterized by insincerity or deceit; evasive; deviating from a straight course\n",
      "--------\n",
      "affirmative, 0.507, affirming or giving assent; expecting the best; expressing or manifesting praise or approval\n",
      "--------\n",
      "anti-american, 0.480, opposed to the United States and its policies\n",
      "--------\n",
      "perverted, 0.483, (used of sexual behavior) showing or appealing to bizarre or deviant tastes; having an intended meaning altered or misrepresented; deviating from what is considered moral or right or proper or good\n",
      "--------\n",
      "acquainted, 0.505, having fair knowledge of\n",
      "--------\n",
      "gathered, 0.484, brought together in one place\n",
      "--------\n",
      "devout, 0.493, deeply religious;  H.L.Mencken; earnest\n",
      "--------\n",
      "affixed, 0.514, firmly attached\n",
      "--------\n",
      "clouded, 0.511, made troubled or apprehensive or distressed in appearance; filled or abounding with clouds; mentally disordered; unclear in form or expression; ; - H.G.Wells\n",
      "--------\n",
      "decided, 0.509, recognizable; marked\n",
      "--------\n",
      "noisy, 0.515, full of or characterized by loud and nonmusical sounds; attracting attention by showiness or bright colors\n",
      "--------\n",
      "immeasurable, 0.497, impossible to measure; beyond calculation or measure\n",
      "--------\n",
      "inoffensive, 0.509, not causing anger or annoyance; giving no offense; substituting a mild term for a harsher or distasteful one\n",
      "--------\n",
      "realistic, 0.493, aware or expressing awareness of things as they really are; representing what is real; not abstract or ideal; of or relating to the philosophical doctrine of realism\n",
      "--------\n",
      "state-of-the-art, 0.497, the highest level of development at a particular time (especially the present time)\n",
      "--------\n",
      "causal, 0.520, involving or constituting a cause; causing\n",
      "--------\n",
      "top-quality, 0.517, surpassing in quality\n",
      "--------\n",
      "aloof, 0.513, remote in manner\n",
      "--------\n",
      "constituent, 0.498, constitutional in the structure of something (especially your physical makeup)\n",
      "--------\n",
      "careful, 0.517, exercising caution or showing care or attention; cautiously attentive; unhurried and with care and dignity; full of cares or anxiety; -Luke 10.41; mindful of the future in spending money\n",
      "--------\n",
      "adagio, 0.518, (of tempo) leisurely\n",
      "--------\n",
      "strenuous, 0.486, characterized by or performed with much energy or force; taxing to the utmost; testing powers of endurance; ; ; - F.D.Roosevelt\n",
      "--------\n",
      "satiated, 0.482, supplied (especially fed) to satisfaction\n",
      "--------\n",
      "imaginary, 0.481, not based on fact; unreal; - F.D.Roosevelt\n",
      "--------\n",
      "perfunctory, 0.481, hasty and without attention to detail; not thorough; as a formality only\n",
      "--------\n",
      "dizzy, 0.495, having or causing a whirling sensation; liable to falling; lacking seriousness; given to frivolity\n",
      "--------\n",
      "crazier, 0.505, affected with madness or insanity; foolish; totally unsound; possessed by inordinate excitement; bizarre or fantastic; intensely enthusiastic about or preoccupied with\n",
      "--------\n",
      "eloquent, 0.515, expressing yourself readily, clearly, effectively\n",
      "--------\n",
      "posh, 0.513, elegant and fashionable; ; ; ; - Julia Child\n",
      "--------\n",
      "accepted, 0.513, generally approved or compelling recognition\n",
      "--------\n",
      "jammed, 0.489, filled to capacity\n",
      "--------\n",
      "giddy, 0.495, having or causing a whirling sensation; liable to falling; lacking seriousness; given to frivolity\n",
      "--------\n",
      "stilted, 0.516, artificially formal\n",
      "--------\n",
      "gingerly, 0.511, with extreme care or delicacy; ; - W.S.White\n",
      "--------\n",
      "existent, 0.486, having existence or being or actuality; being or occurring in fact or actuality; having verified existence; not illusory; ; ; ; ; ; - Longfellow; presently existing in fact and not merely potential or possible\n",
      "--------\n",
      "utilized, 0.497, put to use\n",
      "--------\n",
      "pragmatic, 0.495, concerned with practical matters; of or concerning the theory of pragmatism; guided by practical experience and observation rather than theory\n",
      "--------\n",
      "advertised, 0.485, called to public attention\n",
      "--------\n",
      "livid, 0.497, anemic looking from illness or emotion; ; ; ; ; - Mary W. Shelley; (of a light) imparting a deathlike luminosity; ; - E.A.Poe; furiously angry; discolored by coagulation of blood beneath the skin\n",
      "--------\n",
      "unrewarded, 0.503, having acquired or gained nothing\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# show uncertain words\n",
    "random.shuffle(uw)\n",
    "\n",
    "for w,s in uw:\n",
    "    t=adj.loc[adj.word==w,'text'].values[0]\n",
    "    print(\"%s, %.3f, %s\"%(w,s,t))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819e6eb4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RunTwoMore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9ef42",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We only provide the evaluation results of another two runs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8c55652",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.636\n",
      "positive::recall 0.583\n",
      "negative::precision 0.776\n",
      "negative::recall 0.812\n",
      "F1: 0.61\n",
      "N F1: 0.79\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.3.2.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18b33cf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.778\n",
      "positive::recall 0.583\n",
      "negative::precision 0.795\n",
      "negative::recall 0.906\n",
      "F1: 0.67\n",
      "N F1: 0.85\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.3.4.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3d728",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f88278",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0d4dca6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# annotate round4 training samples from most uncertain words in round3\n",
    "desc4=['involved','wispy','unchecked','offending','barbecued','detrimental','grizzly','beautiful','plush',\n",
    "       'provable','granted','meatless','inseparable','after-school','jittery','key','nonalcoholic','asthmatic'\n",
    "       ,'fizzy','nearby','second-best',]\n",
    "\n",
    "opin4=['lenient','right-wing','concerned','impromptu','dastardly','deceptive','obedient','sincerest','obsequious',\n",
    "       'craziest','disconcerting','ascetic','bracing','forgetful','convinced','bold','unpalatable','happy',\n",
    "       'dissenting','inviting','sane',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd53ef38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc4+opin4:\n",
    "    if w in testset['word']:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5b6d720",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "desc_all=desc+desc2+desc3+desc4\n",
    "opin_all=opin+opin2+opin3+opin4\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train=pd.DataFrame()\n",
    "train['word'],train['text'],train['target']=list(zip(*(trainset)))\n",
    "\n",
    "train.to_csv('Data/train.v6.4.round4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "059df820",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 3)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e8358",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is done by `train.py` with trainset `Data/train.v6.4.round4.csv`. Remember setting Config.is_predict=False in `train.py` before training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b0d32",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "493665d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.808\n",
      "positive::recall 0.583\n",
      "negative::precision 0.797\n",
      "negative::recall 0.922\n",
      "F1: 0.68\n",
      "N F1: 0.86\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.4.1.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbe59db0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.112,0.145]: 1027\n",
      "[0.145,0.179]: 1719\n",
      "[0.179,0.213]: 851\n",
      "[0.213,0.246]: 448\n",
      "[0.246,0.280]: 278\n",
      "[0.280,0.313]: 195\n",
      "[0.313,0.347]: 173\n",
      "[0.347,0.380]: 148\n",
      "[0.380,0.414]: 136\n",
      "[0.414,0.447]: 123\n",
      "[0.447,0.481]: 116\n",
      "[0.481,0.514]: 151\n",
      "[0.514,0.548]: 134\n",
      "[0.548,0.581]: 146\n",
      "[0.581,0.615]: 162\n",
      "[0.615,0.648]: 232\n",
      "[0.648,0.682]: 304\n",
      "[0.682,0.715]: 437\n",
      "[0.715,0.749]: 381\n",
      "[0.749,0.782]: 131\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "n,p=numpy.histogram(pred.flatten(),bins=20)\n",
    "for i in range(n.shape[0]):\n",
    "    print(\"[%.3f,%.3f]: %d\"%(p[i],p[i+1],n[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb9ee023",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27550741])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred>0.5)/pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb6088",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Uncertain Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "62a86294",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smarter, 0.508, showing mental alertness and calculation and resourcefulness; elegant and stylish; characterized by quickness and ease in learning; improperly forward or bold; painfully severe; quick and brisk; capable of independent and apparently intelligent action\n",
      "--------\n",
      "utopian, 0.516, of or pertaining to or resembling a utopia; characterized by or aspiring to impracticable perfection\n",
      "--------\n",
      "all-night, 0.519, lasting, open, or operating through the whole night\n",
      "--------\n",
      "fluffier, 0.520, like down or as soft as down\n",
      "--------\n",
      "corny, 0.487, dull and tiresome but with pretensions of significance or originality\n",
      "--------\n",
      "monotonous, 0.507, tediously repetitious or lacking in variety; sounded or spoken in a tone unvarying in pitch\n",
      "--------\n",
      "competent, 0.491, properly or sufficiently qualified or capable or efficient; adequate for the purpose; legally qualified or sufficient\n",
      "--------\n",
      "freaky, 0.499, strange and somewhat frightening; conspicuously or grossly unconventional or unusual\n",
      "--------\n",
      "verbal, 0.482, communicated in the form of words; of or relating to or formed from words in general; of or relating to or formed from a verb; relating to or having facility in the use of words; expressed in spoken words; prolix; - Shakespeare\n",
      "--------\n",
      "elaborate, 0.490, marked by complexity and richness of detail; developed or executed with care and in minute detail; ; - John Buchan\n",
      "--------\n",
      "prudish, 0.516, exaggeratedly proper\n",
      "--------\n",
      "neurotic, 0.510, characteristic of or affected by neurosis; affected with emotional disorder\n",
      "--------\n",
      "honored, 0.514, having an illustrious reputation; respected\n",
      "--------\n",
      "jumped-up, 0.480, (British informal) upstart\n",
      "--------\n",
      "fictional, 0.508, related to or involving literary fiction; formed or conceived by the imagination\n",
      "--------\n",
      "fluffiest, 0.520, like down or as soft as down\n",
      "--------\n",
      "rigorous, 0.508, rigidly accurate; allowing no deviation from a standard; demanding strict attention to rules and procedures\n",
      "--------\n",
      "fervent, 0.499, characterized by intense emotion; extremely hot; - Nathaniel Hawthorne; - Frances Trollope\n",
      "--------\n",
      "twilight, 0.481, lighted by or as if by twilight; -Henry Fielding\n",
      "--------\n",
      "decided, 0.518, recognizable; marked\n",
      "--------\n",
      "restful, 0.515, affording physical or mental rest\n",
      "--------\n",
      "litigious, 0.513, of or relating to litigation; inclined or showing an inclination to dispute or disagree, even to engage in law suits\n",
      "--------\n",
      "liveliest, 0.494, full of life and energy; full of zest or vigor; quick and energetic; elastic; rebounds readily; filled with events or activity; full of spirit\n",
      "--------\n",
      "economic, 0.488, of or relating to an economy, the system of production and management of material wealth; of or relating to the science of economics; using the minimum of time or resources necessary for effectiveness; concerned with worldly necessities of life (especially money); financially rewarding\n",
      "--------\n",
      "ideological, 0.509, of or pertaining to or characteristic of an orientation that characterizes the thinking of a group or nation; concerned with or suggestive of ideas\n",
      "--------\n",
      "hard-fought, 0.504, requiring great effort\n",
      "--------\n",
      "unforeseen, 0.485, not anticipated; - H.W.Glidden\n",
      "--------\n",
      "lively, 0.494, full of life and energy; full of zest or vigor; quick and energetic; elastic; rebounds readily; filled with events or activity; full of spirit\n",
      "--------\n",
      "fluffy, 0.520, like down or as soft as down\n",
      "--------\n",
      "fast-paced, 0.507, of communication that proceeds rapidly\n",
      "--------\n",
      "daintier, 0.502, affectedly dainty or refined; delicately beautiful; especially pleasing to the taste; excessively fastidious and easily disgusted\n",
      "--------\n",
      "workmanlike, 0.494, worthy of a good workman\n",
      "--------\n",
      "dressy, 0.509, in fancy clothing\n",
      "--------\n",
      "all-nighter, 0.519, lasting, open, or operating through the whole night\n",
      "--------\n",
      "unholy, 0.492, not hallowed or consecrated; extremely evil or cruel; expressive of cruelty or befitting hell; having committed unrighteous acts\n",
      "--------\n",
      "corrected, 0.513, having something undesirable neutralized\n",
      "--------\n",
      "downright, 0.490, characterized by plain blunt honesty; complete and without restriction or qualification; sometimes used informally as intensifiers\n",
      "--------\n",
      "effortless, 0.481, requiring or apparently requiring no effort; not showing effort or strain\n",
      "--------\n",
      "across-the-board, 0.490, broad in scope or content; ; ; ; ; - T.G.Winner\n",
      "--------\n",
      "balmy, 0.480, informal or slang terms for mentally irregular; mild and pleasant\n",
      "--------\n",
      "friendliest, 0.506, characteristic of or befitting a friend; inclined to help or support; not antagonistic or hostile; easy to understand or use; of or belonging to your own country's forces or those of an ally\n",
      "--------\n",
      "esteemed, 0.514, having an illustrious reputation; respected\n",
      "--------\n",
      "smartest, 0.508, showing mental alertness and calculation and resourcefulness; elegant and stylish; characterized by quickness and ease in learning; improperly forward or bold; painfully severe; quick and brisk; capable of independent and apparently intelligent action\n",
      "--------\n",
      "unequaled, 0.487, radically distinctive and without equal\n",
      "--------\n",
      "noted, 0.502, widely known and esteemed; worthy of notice or attention\n",
      "--------\n",
      "overabundant, 0.499, excessively abundant\n",
      "--------\n",
      "soapy, 0.514, resembling or having the qualities of soap; unpleasantly and excessively suave or ingratiating in manner or speech\n",
      "--------\n",
      "ago, 0.496, gone by; or in the past\n",
      "--------\n",
      "ruined, 0.501, destroyed physically or morally; doomed to extinction; brought to ruin\n",
      "--------\n",
      "philanthropic, 0.510, generous in assistance to the poor; of or relating to or characterized by philanthropy\n",
      "--------\n",
      "mild-mannered, 0.498, behaving in or having a mild or gentle manner\n",
      "--------\n",
      "beauteous, 0.511, (poetic )beautiful, especially to the sight\n",
      "--------\n",
      "visceral, 0.502, relating to or affecting the viscera; obtained through intuition rather than from reasoning or observation\n",
      "--------\n",
      "subordinate, 0.502, lower in rank or importance; subject or submissive to authority or the control of another; (of a clause) unable to stand alone syntactically as a complete sentence\n",
      "--------\n",
      "irritable, 0.505, easily irritated or annoyed; abnormally sensitive to a stimulus; capable of responding to stimuli\n",
      "--------\n",
      "relaxing, 0.515, affording physical or mental rest\n",
      "--------\n",
      "blanket, 0.490, broad in scope or content; ; ; ; ; - T.G.Winner\n",
      "--------\n",
      "self-destructive, 0.510, dangerous to yourself or your interests\n",
      "--------\n",
      "lyrical, 0.489, suitable for or suggestive of singing; expressing deep emotion\n",
      "--------\n",
      "evoked, 0.484, called forth from a latent or potential state by stimulation\n",
      "--------\n",
      "elementary, 0.512, easy and not involved or complicated; of or pertaining to or characteristic of elementary school or elementary education; of or being the essential or basic part\n",
      "--------\n",
      "terrible, 0.515, causing fear or dread or terror; exceptionally bad or displeasing; intensely or extremely bad or unpleasant in degree or quality; extreme in degree or extent or amount or impact\n",
      "--------\n",
      "ubiquitous, 0.518, being present everywhere at once\n",
      "--------\n",
      "beforehand, 0.501, being ahead of time or need\n",
      "--------\n",
      "descriptive, 0.519, serving to describe or inform or characterized by description; describing the structure of a language\n",
      "--------\n",
      "preservative, 0.507, tending or having the power to preserve\n",
      "--------\n",
      "accidental, 0.519, happening by chance or unexpectedly or unintentionally\n",
      "--------\n",
      "pivotal, 0.497, being of crucial importance; ; - Henry Kissinger\n",
      "--------\n",
      "forthright, 0.491, characterized by directness in manner or speech; without subtlety or evasion\n",
      "--------\n",
      "authoritative, 0.481, having authority or ascendancy or influence; of recognized authority or excellence; sanctioned by established authority\n",
      "--------\n",
      "emphasised, 0.501, spoken with emphasis\n",
      "--------\n",
      "sensitive, 0.481, responsive to physical stimuli; being susceptible to the attitudes, feelings, or circumstances of others; able to feel or perceive; hurting; of or pertaining to classified information or matters affecting national security\n",
      "--------\n",
      "omnipresent, 0.518, being present everywhere at once\n",
      "--------\n",
      "brave, 0.514, possessing or displaying courage; able to face and deal with danger or fear without flinching; - Herman Melville; - William Wordsworth; invulnerable to fear or intimidation; brightly colored and showy\n",
      "--------\n",
      "soured, 0.504, having turned bad\n",
      "--------\n",
      "inadvertent, 0.519, happening by chance or unexpectedly or unintentionally\n",
      "--------\n",
      "livelier, 0.494, full of life and energy; full of zest or vigor; quick and energetic; elastic; rebounds readily; filled with events or activity; full of spirit\n",
      "--------\n",
      "entrepreneurial, 0.487, of or relating to an entrepreneur; willing to take risks in order to make a profit\n",
      "--------\n",
      "social, 0.504, relating to human society and its members; living together or enjoying life in communities or organized groups; relating to or belonging to or characteristic of high society; composed of sociable people or formed for the purpose of sociability; tending to move or live together in groups or colonies of the same kind; marked by friendly companionship with others\n",
      "--------\n",
      "unwholesome, 0.512, detrimental to physical or moral well-being\n",
      "--------\n",
      "earthy, 0.481, conspicuously and tastelessly indecent; not far removed from or suggestive of nature; hearty and lusty; of or consisting of or resembling earth; sensible and practical\n",
      "--------\n",
      "clumsy, 0.498, lacking grace in movement or posture; not elegant or graceful in expression; difficult to handle or manage especially because of shape; showing lack of skill or aptitude\n",
      "--------\n",
      "unsuccessful, 0.505, not successful; having failed or having an unfavorable outcome; failing to accomplish an intended result\n",
      "--------\n",
      "salutary, 0.497, tending to promote physical well-being; beneficial to health\n",
      "--------\n",
      "sweetish, 0.492, somewhat sweet\n",
      "--------\n",
      "phantom, 0.499, something apparently sensed but having no physical reality\n",
      "--------\n",
      "overnight, 0.519, lasting, open, or operating through the whole night\n",
      "--------\n",
      "instructive, 0.481, serving to instruct or enlighten or inform\n",
      "--------\n",
      "lousy, 0.507, very bad; infested with lice; vile; despicable\n",
      "--------\n",
      "friendlier, 0.506, characteristic of or befitting a friend; inclined to help or support; not antagonistic or hostile; easy to understand or use; of or belonging to your own country's forces or those of an ally\n",
      "--------\n",
      "bold, 0.509, fearless and daring; clear and distinct; very steep; having a prominent and almost vertical front\n",
      "--------\n",
      "emphasized, 0.501, spoken with emphasis\n",
      "--------\n",
      "lofty, 0.503, of high moral or intellectual value; elevated in nature or style; ; - Oliver Franks; of imposing height; especially standing out above others; having or displaying great dignity or nobility\n",
      "--------\n",
      "satisfying, 0.512, providing abundant nourishment; providing freedom from worry\n",
      "--------\n",
      "boss, 0.490, exceptionally good\n",
      "--------\n",
      "deplorable, 0.518, bad; unfortunate; of very poor quality or condition; bringing or deserving severe rebuke or censure\n",
      "--------\n",
      "synthetic, 0.493, not of natural origin; prepared or made artificially; involving or of the nature of synthesis (combining separate elements to form a coherent whole) as opposed to analysis; - P.S.Welch; systematic combining of root and modifying elements into single words; of a proposition whose truth value is determined by observation or facts; artificial as if portrayed in a film; not genuine or natural; - George Will\n",
      "--------\n",
      "smart, 0.508, showing mental alertness and calculation and resourcefulness; elegant and stylish; characterized by quickness and ease in learning; improperly forward or bold; painfully severe; quick and brisk; capable of independent and apparently intelligent action\n",
      "--------\n",
      "dusky, 0.481, lighted by or as if by twilight; -Henry Fielding; naturally having skin of a dark color\n",
      "--------\n",
      "narcotic, 0.511, of or relating to or designating narcotics; inducing stupor or narcosis; inducing mental lethargy\n",
      "--------\n",
      "starved, 0.490, suffering from lack of food; extremely hungry\n",
      "--------\n",
      "best, 0.488, (superlative of `good') having the most positive qualities; (comparative and superlative of `well') wiser or more advantageous and hence advisable; having desirable or positive qualities especially those suitable for a thing specified; having the normally expected amount; morally admirable; deserving of esteem and respect; promoting or enhancing well-being; agreeable or pleasing; of moral excellence; having or showing knowledge and skill and aptitude; thorough; with or in a close or intimate relationship; financially sound; most suitable or right for a particular purpose; resulting favorably; exerting force or influence; capable of pleasing; appealing to the mind; in excellent physical condition; tending to promote physical well-being; beneficial to health; not forged; not left to spoil; generally admired\n",
      "--------\n",
      "flowery, 0.498, of or relating to or suggestive of flowers; marked by elaborate rhetoric and elaborated with decorative details; ; -John Milton\n",
      "--------\n",
      "suggestive, 0.519, tending to suggest or imply; (usually followed by `of') pointing out or revealing clearly; tending to suggest something improper or indecent\n",
      "--------\n",
      "all-inclusive, 0.490, broad in scope or content; ; ; ; ; - T.G.Winner\n",
      "--------\n",
      "noteworthy, 0.505, worthy of notice; worthy of notice\n",
      "--------\n",
      "mechanic, 0.482, resembling the action of a machine; - Emily Dickenson\n",
      "--------\n",
      "undone, 0.491, not done; doomed to extinction; not fastened or tied or secured; thrown into a state of disorganization or incoherence\n",
      "--------\n",
      "secure, 0.495, free from fear or doubt; easy in mind; free from danger or risk; not likely to fail or give way; immune to attack; incapable of being tampered with; financially sound\n",
      "--------\n",
      "unquenchable, 0.487, impossible to quench\n",
      "--------\n",
      "dainty, 0.502, affectedly dainty or refined; delicately beautiful; especially pleasing to the taste; excessively fastidious and easily disgusted\n",
      "--------\n",
      "gratuitous, 0.502, without cause; costing nothing; unnecessary and unwarranted\n",
      "--------\n",
      "earthiest, 0.481, conspicuously and tastelessly indecent; not far removed from or suggestive of nature; hearty and lusty; of or consisting of or resembling earth; sensible and practical\n",
      "--------\n",
      "chilly, 0.486, not characterized by emotion; -C.W.Cunningham; appreciably or disagreeably cold; lacking warmth of feeling\n",
      "--------\n",
      "flammable, 0.506, easily ignited\n",
      "--------\n",
      "unconsumed, 0.513, not consumed\n",
      "--------\n",
      "homey, 0.507, having a feeling of home; cozy and comfortable\n",
      "--------\n",
      "inviting, 0.508, attractive and tempting\n",
      "--------\n",
      "unopen, 0.496, not open\n",
      "--------\n",
      "stringent, 0.515, demanding strict attention to rules and procedures\n",
      "--------\n",
      "cosy, 0.509, enjoying or affording comforting warmth and shelter especially in a small space\n",
      "--------\n",
      "vibrant, 0.506, vigorous and animated; of sounds that are strong and resonating; of colors that are bright and striking\n",
      "--------\n",
      "unobtrusive, 0.483, not obtrusive or undesirably noticeable\n",
      "--------\n",
      "snotty, 0.495, (used colloquially) overly conceited or arrogant; -Laurent Le Sage; dirty with nasal discharge\n",
      "--------\n",
      "elevated, 0.512, raised above the ground; of high moral or intellectual value; elevated in nature or style; ; - Oliver Franks; increased in amount or degree\n",
      "--------\n",
      "visual, 0.513, relating to or using sight; visible; - Shakespeare\n",
      "--------\n",
      "god-awful, 0.504, very unpleasant\n",
      "--------\n",
      "suspect, 0.507, not as expected\n",
      "--------\n",
      "bolder, 0.509, fearless and daring; clear and distinct; very steep; having a prominent and almost vertical front\n",
      "--------\n",
      "lurid, 0.495, horrible in fierceness or savagery; glaringly vivid and graphic; marked by sensationalism; shining with an unnatural red glow as of fire seen through smoke; ghastly pale\n",
      "--------\n",
      "soulless, 0.511, lacking sensitivity or the capacity for deep feeling\n",
      "--------\n",
      "chillier, 0.486, not characterized by emotion; -C.W.Cunningham; appreciably or disagreeably cold; lacking warmth of feeling\n",
      "--------\n",
      "preferred, 0.510, more desirable than another; preferred above all others and treated with partiality\n",
      "--------\n",
      "susceptible, 0.502, (often followed by `of' or `to') yielding readily to or capable of; easily impressed emotionally\n",
      "--------\n",
      "uninfluenced, 0.503, not influenced or affected; - V.L.Parrington\n",
      "--------\n",
      "postprandial, 0.501, following a meal (especially dinner)\n",
      "--------\n",
      "lousiest, 0.507, very bad; infested with lice; vile; despicable\n",
      "--------\n",
      "induced, 0.511, brought about or caused; not spontaneous\n",
      "--------\n",
      "modified, 0.511, changed in form or character; mediocre\n",
      "--------\n",
      "faulty, 0.500, having a defect; characterized by errors; not agreeing with a model or not following established rules; ; ; the wrong side of the road\"\n",
      "--------\n",
      "open-and-shut, 0.504, so obvious as to be easily solved or decided\n",
      "--------\n",
      "under, 0.489, located below or beneath something else; lower in rank, power, or authority\n",
      "--------\n",
      "changing, 0.510, marked by continuous change or effective action\n",
      "--------\n",
      "unparalleled, 0.487, radically distinctive and without equal\n",
      "--------\n",
      "creditable, 0.504, worthy of often limited commendation\n",
      "--------\n",
      "earthier, 0.481, conspicuously and tastelessly indecent; not far removed from or suggestive of nature; hearty and lusty; of or consisting of or resembling earth; sensible and practical\n",
      "--------\n",
      "worn, 0.508, affected by wear; damaged by long use; showing the wearing effects of overwork or care or suffering; ; ; ; - Charles Dickens\n",
      "--------\n",
      "pedantic, 0.497, marked by a narrow focus on or display of learning especially its trivial aspects\n",
      "--------\n",
      "potent, 0.516, having great influence; having or wielding force or authority; having a strong physiological or chemical effect; ; ; ,; (of a male) capable of copulation\n",
      "--------\n",
      "putrid, 0.491, of or relating to or attended by putrefaction; in an advanced state of decomposition and having a foul odor; - Somerset Maugham; morally corrupt or evil\n",
      "--------\n",
      "beat, 0.518, very tired\n",
      "--------\n",
      "ever-changing, 0.510, marked by continuous change or effective action\n",
      "--------\n",
      "surreptitious, 0.514, marked by quiet and caution and secrecy; taking pains to avoid being observed; conducted with or marked by hidden aims or methods\n",
      "--------\n",
      "indicative, 0.491, relating to the mood of verbs that is used simple in declarative statements; (usually followed by `of') pointing out or revealing clearly\n",
      "--------\n",
      "idiosyncratic, 0.498, peculiar to the individual\n",
      "--------\n",
      "satiated, 0.483, supplied (especially fed) to satisfaction\n",
      "--------\n",
      "uncommon, 0.482, not common or ordinarily encountered; unusually great in amount or remarkable in character or kind; marked by an uncommon quality; especially superlative or extreme of its kind; -J.R.Lowell\n",
      "--------\n",
      "exceptionable, 0.503, liable to objection or debate; used of something one might take exception to\n",
      "--------\n",
      "aesthetic, 0.492, relating to or dealing with the subject of aesthetics; concerning or characterized by an appreciation of beauty or good taste; aesthetically pleasing\n",
      "--------\n",
      "adjunct, 0.500, furnishing added support; of or relating to a person who is subordinate to another\n",
      "--------\n",
      "favourable, 0.516, encouraging or approving or pleasing; (of winds or weather) tending to promote or facilitate; occurring at a convenient or suitable time; presaging or likely to bring good luck\n",
      "--------\n",
      "kosher, 0.505, conforming to dietary laws; proper or legitimate\n",
      "--------\n",
      "dimmer, 0.483, lacking in light; not bright or harsh; lacking clarity or distinctness; made dim or less bright; offering little or no hope; ; ; - J.M.Synge; slow to learn or understand; lacking intellectual acuity; ; ; - Thackeray\n",
      "--------\n",
      "red-faced, 0.497, (especially of the face) reddened or suffused with or as if with blood from emotion or exertion; having a red face from embarrassment or shame or agitation or emotional upset\n",
      "--------\n",
      "academic, 0.481, associated with academia or an academy; hypothetical or theoretical and not expected to produce an immediate or practical result; marked by a narrow focus on or display of learning especially its trivial aspects\n",
      "--------\n",
      "seeming, 0.514, appearing as such but not necessarily so\n",
      "--------\n",
      "mock, 0.507, constituting a copy or imitation of something\n",
      "--------\n",
      "better, 0.503, (comparative of `good') superior to another (of the same class or set or kind) in excellence or quality or desirability or suitability; more highly skilled than another; (comparative of `good') changed for the better in health or fitness; (comparative and superlative of `well') wiser or more advantageous and hence advisable; more than half; having desirable or positive qualities especially those suitable for a thing specified; having the normally expected amount; morally admirable; deserving of esteem and respect; promoting or enhancing well-being; agreeable or pleasing; of moral excellence; having or showing knowledge and skill and aptitude; thorough; with or in a close or intimate relationship; financially sound; most suitable or right for a particular purpose; resulting favorably; exerting force or influence; capable of pleasing; appealing to the mind; in excellent physical condition; tending to promote physical well-being; beneficial to health; not forged; not left to spoil; generally admired; in good health especially after having suffered illness or injury; resulting favorably; wise or advantageous and hence advisable\n",
      "--------\n",
      "incognito, 0.512, with your identity concealed\n",
      "--------\n",
      "preliminary, 0.485, denoting an action or event preceding or in preparation for something more important; designed to orient or acquaint with a situation before proceeding\n",
      "--------\n",
      "vivid, 0.496, evoking lifelike images within the mind; having the clarity and freshness of immediate experience; having striking color; (of color) having the highest saturation\n",
      "--------\n",
      "well, 0.490, in good health especially after having suffered illness or injury; resulting favorably; wise or advantageous and hence advisable\n",
      "--------\n",
      "friendly, 0.506, characteristic of or befitting a friend; inclined to help or support; not antagonistic or hostile; easy to understand or use; of or belonging to your own country's forces or those of an ally\n",
      "--------\n",
      "undifferentiated, 0.503, not differentiated\n",
      "--------\n",
      "weary, 0.482, physically and mentally fatigued\n",
      "--------\n",
      "boldest, 0.509, fearless and daring; clear and distinct; very steep; having a prominent and almost vertical front\n",
      "--------\n",
      "disgusted, 0.505, having a strong distaste from surfeit\n",
      "--------\n",
      "dim, 0.483, lacking in light; not bright or harsh; lacking clarity or distinctness; made dim or less bright; offering little or no hope; ; ; - J.M.Synge; slow to learn or understand; lacking intellectual acuity; ; ; - Thackeray\n",
      "--------\n",
      "opening, 0.508, first or beginning\n",
      "--------\n",
      "toothsome, 0.510, acceptable to the taste or mind; extremely pleasing to the sense of taste; having strong sexual appeal\n",
      "--------\n",
      "piercing, 0.481, having or demonstrating ability to recognize or draw fine distinctions; painful as if caused by a sharp instrument\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# show uncertain words\n",
    "uw=[]\n",
    "for i,w in enumerate(adj['word'].tolist()):        \n",
    "    if pred[i]>0.48 and pred[i]<0.52:\n",
    "        uw.append((w,round(pred[i][0],4)))\n",
    "        \n",
    "random.shuffle(uw)\n",
    "\n",
    "for w,s in uw:\n",
    "    t=adj.loc[adj.word==w,'text'].values[0]\n",
    "    print(\"%s, %.3f, %s\"%(w,s,t))\n",
    "    print('--------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80ab97fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f713e8a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RunTwoMore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fbe05",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We only provide the evaluation results of another two runs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b91afa0c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.889\n",
      "positive::recall 0.667\n",
      "negative::precision 0.836\n",
      "negative::recall 0.953\n",
      "F1: 0.76\n",
      "N F1: 0.89\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.4.2.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb28cc8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.735\n",
      "positive::recall 0.694\n",
      "negative::precision 0.833\n",
      "negative::recall 0.859\n",
      "F1: 0.71\n",
      "N F1: 0.85\n"
     ]
    }
   ],
   "source": [
    "# run another two times\n",
    "\n",
    "pred=joblib.load('Data/pred.v6.4.3.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954a51f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fe093",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d9b16d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# annotate round5 training-samples from most uncertain words in round4\n",
    "desc5=['all-night','fluffier','monotonous','verbal','fictional','economic',\n",
    "       'dressy','soapy','ago','ruined','unwholesome',\n",
    "       'salutary','sweetish','overnight','bold','synthetic','dusky','starved']\n",
    "\n",
    "opin5=['smarter','utopian','corny','freaky','prudish','neurotic','honored','fervent','decided','litigious',\n",
    "       'liveliest','unholy','friendliest','irritable','bold','satisfying','smart','inviting','god-awful',\n",
    "       'preferred',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9028c160",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If any word exists in testset, delete it and resample.\n",
    "for w in desc5+opin5:\n",
    "    if w in testset['word']:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "91f0a308",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "desc_all=desc+desc2+desc3+desc4+desc5\n",
    "opin_all=opin+opin2+opin3+opin4+opin5\n",
    "\n",
    "\n",
    "word_type='adj'\n",
    "trainset=[]\n",
    "for w in desc_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in opin_all:\n",
    "    trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "train=pd.DataFrame()\n",
    "train['word'],train['text'],train['target']=list(zip(*(trainset)))\n",
    "\n",
    "train.to_csv('Data/train.v6.5.round5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28978fad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Training is done by `train.py` with trainset `Data/train.v6.5.round5.csv`. Remember setting Config.is_predict=False in `train.py` before training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf65f910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 3)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9621a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e699a373",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.781\n",
      "positive::recall 0.694\n",
      "negative::precision 0.838\n",
      "negative::recall 0.891\n",
      "F1: 0.74\n",
      "N F1: 0.86\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.5.6.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb5aeeb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.013,0.061]: 4020\n",
      "[0.061,0.110]: 300\n",
      "[0.110,0.158]: 150\n",
      "[0.158,0.207]: 69\n",
      "[0.207,0.255]: 69\n",
      "[0.255,0.304]: 67\n",
      "[0.304,0.352]: 62\n",
      "[0.352,0.400]: 56\n",
      "[0.400,0.449]: 37\n",
      "[0.449,0.497]: 53\n",
      "[0.497,0.546]: 54\n",
      "[0.546,0.594]: 36\n",
      "[0.594,0.642]: 52\n",
      "[0.642,0.691]: 33\n",
      "[0.691,0.739]: 52\n",
      "[0.739,0.788]: 70\n",
      "[0.788,0.836]: 73\n",
      "[0.836,0.884]: 144\n",
      "[0.884,0.933]: 257\n",
      "[0.933,0.981]: 1638\n"
     ]
    }
   ],
   "source": [
    "# show distribution\n",
    "n,p=numpy.histogram(pred,bins=20)\n",
    "for i in range(n.shape[0]):\n",
    "    print(\"[%.3f,%.3f]: %d\"%(p[i],p[i+1],n[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c69c133f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33008777])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred>0.5)/pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c64e5d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### UncertainWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bceed0a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "verifiable\n",
      "distinguished\n",
      "replaceable\n",
      "incontinent\n",
      "erratic\n",
      "four-year-old\n",
      "five-year-old\n",
      "andean\n",
      "ball-shaped\n",
      "flinty\n",
      "unpalatable\n",
      "myopic\n",
      "blooded\n",
      "anglo-indian\n",
      "torturous\n",
      "listed\n",
      "pop\n",
      "unisex\n",
      "going\n",
      "hot\n"
     ]
    }
   ],
   "source": [
    "# Negative Uncertain words\n",
    "uw=[]\n",
    "for i,w in enumerate(adj['word'].tolist()):        \n",
    "    if pred[i]>0.48 and pred[i]<0.5:\n",
    "        uw.append((w,round(pred[i][0],4)))\n",
    "random.shuffle(uw)\n",
    "\n",
    "print(len(uw))\n",
    "\n",
    "for w,s in uw[:K]:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297d2ee",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RunTwoMore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd9ef42",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    We only provide the evaluation results of another two runs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b0738e0",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.826\n",
      "positive::recall 0.528\n",
      "negative::precision 0.779\n",
      "negative::recall 0.938\n",
      "F1: 0.64\n",
      "N F1: 0.85\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.5.8.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e78249b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.758\n",
      "positive::recall 0.694\n",
      "negative::precision 0.836\n",
      "negative::recall 0.875\n",
      "F1: 0.72\n",
      "N F1: 0.85\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v6.5.9.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ff4254",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Annotate 60~70words/iter. Stop at iter5 as performance converges. Precision/Recall of both classes are already above 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98e140",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08259582",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# baseline\n",
    "# randomly annotate words for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "713615a3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "adj_cand=[]\n",
    "for w in adj['word']:\n",
    "    if w not in testset['word']:\n",
    "        adj_cand.append(w)\n",
    "\n",
    "# randomly sampled 100 mentals and 100 physicals as training set\n",
    "rs_trainset=random.sample(adj_cand,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76e28ae0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consuming\n",
      "abnormal\n",
      "splashier\n",
      "dizzy\n",
      "twilight\n",
      "protected\n",
      "incidental\n",
      "plainer\n",
      "medium\n",
      "available\n",
      "vascular\n",
      "enteral\n",
      "lamest\n",
      "softened\n",
      "crimson\n",
      "black-haired\n",
      "hit-or-miss\n",
      "stupidest\n",
      "fat-free\n",
      "age-old\n",
      "egyptian\n",
      "radical\n",
      "air-filled\n",
      "doable\n",
      "absurd\n",
      "undeserving\n",
      "petulant\n",
      "comforting\n",
      "stoned\n",
      "zany\n",
      "unresponsive\n",
      "preferential\n",
      "plastered\n",
      "cardboard\n",
      "low-level\n",
      "qualitative\n",
      "high-power\n",
      "splitting\n",
      "perfected\n",
      "unobtrusive\n",
      "farther\n",
      "instinct\n",
      "head-to-head\n",
      "affected\n",
      "disposable\n",
      "brinier\n",
      "wanton\n",
      "vinegary\n",
      "rising\n",
      "gelatinous\n",
      "bearable\n",
      "nondescript\n",
      "sicker\n",
      "dissatisfied\n",
      "high-tech\n",
      "glace\n",
      "outgoing\n",
      "apocalyptic\n",
      "void\n",
      "mint\n",
      "experienced\n",
      "appreciative\n",
      "blanket\n",
      "29\n",
      "starchy\n",
      "silly\n",
      "jealous\n",
      "grown\n",
      "sedimentary\n",
      "third\n",
      "long-life\n",
      "axillary\n",
      "semisolid\n",
      "untruthful\n",
      "middle\n",
      "recovering\n",
      "expandable\n",
      "drastic\n",
      "fervent\n",
      "pet\n",
      "loamy\n",
      "96\n",
      "chitinous\n",
      "left-handed\n",
      "chipper\n",
      "attentive\n",
      "powdery\n",
      "slushy\n",
      "mexican\n",
      "unimproved\n",
      "siamese\n",
      "augmented\n",
      "tailor-made\n",
      "inadequate\n",
      "lightheaded\n",
      "tidal\n",
      "obscure\n",
      "legible\n",
      "country-style\n",
      "thai\n",
      "latest\n",
      "78\n",
      "truncated\n",
      "good-natured\n",
      "hand-held\n",
      "wanted\n",
      "ritzy\n",
      "unfeasible\n",
      "freaky\n",
      "extrinsic\n",
      "drafty\n",
      "premenstrual\n",
      "squat\n",
      "protean\n",
      "deleterious\n",
      "recurring\n",
      "lit\n",
      "fruitful\n",
      "nitric\n",
      "finite\n",
      "prolific\n",
      "unregulated\n",
      "geographical\n",
      "unrefined\n",
      "slick\n",
      "mushy\n",
      "speediest\n",
      "boring\n",
      "correct\n",
      "fantastic\n",
      "calmer\n",
      "licensed\n",
      "decreased\n",
      "filthy\n",
      "barbaric\n",
      "copious\n",
      "unintentional\n",
      "twenty-nine\n",
      "sensitive\n",
      "vanished\n",
      "sulfurous\n",
      "favorite\n",
      "greasiest\n",
      "cookie-cutter\n",
      "horrific\n",
      "physical\n",
      "110\n",
      "amber\n",
      "fifty-two\n",
      "interesting\n",
      "cultural\n",
      "cupric\n",
      "unsavory\n",
      "resonant\n",
      "awfulest\n",
      "heartsick\n",
      "arthritic\n",
      "groggy\n",
      "feline\n",
      "personalized\n",
      "muscle-bound\n",
      "notched\n",
      "considered\n",
      "fusty\n",
      "euphemistic\n",
      "rocky\n",
      "communicative\n",
      "popular\n",
      "four-year-old\n",
      "broader\n",
      "later\n",
      "heartier\n",
      "external\n",
      "unemployed\n",
      "executive\n",
      "induced\n",
      "traceable\n",
      "occidental\n",
      "dilatory\n",
      "jagged\n",
      "full-strength\n",
      "precooked\n",
      "japanese\n",
      "enhanced\n",
      "tenuous\n",
      "disgusting\n",
      "canny\n",
      "helpless\n",
      "tainted\n",
      "windswept\n",
      "several\n",
      "slow\n",
      "interstate\n",
      "respectable\n",
      "tried\n",
      "visible\n",
      "three-year-old\n",
      "abandoned\n",
      "meek\n",
      "psychoactive\n"
     ]
    }
   ],
   "source": [
    "for w in rs_trainset:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "dc1513df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'marked by exceptional merit; made smooth and bright by or as if by rubbing; reflecting a sheen or glow; reflecting light'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check definition text\n",
    "adj.loc[adj.word=='shining','text'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f600ed1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# labeling\n",
    "# `rs_desc`: `physical` adj, describe physical attributes\n",
    "# `rs_opin`: `mental` adj, usually relates to mental attributes\n",
    "\n",
    "rs_desc=['consuming','abnormal','splashier','twilight','protected','incidental','plainer','medium','available','vascular','enteral','lamest','softened','crimson','black-haired','fat-free','age-old','egyptian','air-filled','doable','preferential','plastered','cardboard','low-level','qualitative','high-power','splitting','perfected','farther','head-to-head','disposable','brinier','vinegary','rising','gelatinous','nondescript','sicker','high-tech','glace','apocalyptic','void','mint','blanket','29','starchy','grown','sedimentary','third','long-life','axillary','semisolid','middle','recovering','expandable','drastic','loamy','96','chitinous','left-handed','powdery','slushy','mexican','unimproved','siamese','augmented','tailor-made','inadequate','tidal','obscure','legible','country-style','thai','latest','78','truncated','hand-held','ritzy','unfeasible','extrinsic','drafty','premenstrual','squat','protean','deleterious','recurring','lit','fruitful','nitric','finite','prolific','unregulated','geographical','unrefined','slick','mushy','speediest','correct','fantastic','licensed','decreased','filthy','barbaric','copious','twenty-nine','vanished','sulfurous','greasiest','cookie-cutter','physical','110','amber','fifty-two','cultural','cupric','unsavory','resonant','arthritic','feline','personalized','muscle-bound','notched','fusty','rocky','popular','four-year-old','broader','later','external','unemployed','executive','induced','traceable','occidental','jagged','full-strength','precooked','japanese','enhanced','tenuous','helpless','tainted','windswept','several','slow','interstate','tried','visible','three-year-old','abandoned','psychoactive']\n",
    "rs_opin=['dizzy','hit-or-miss','stupidest','radical','absurd','undeserving','petulant','comforting','stoned','zany','unresponsive','unobtrusive','instinct','affected','wanton','bearable','dissatisfied','outgoing','experienced','appreciative','silly','jealous','untruthful','fervent','pet','chipper','attentive','lightheaded','good-natured','wanted','freaky','boring','calmer','unintentional','sensitive','favorite','horrific','interesting','awfulest','heartsick','groggy','considered','euphemistic','communicative','heartier','dilatory','disgusting','canny','respectable','meek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "978df9f9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rs_desc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "715c5301",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rs_opin) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926d8469",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    As mental and physical words are distributed unbalancedly, we need to find more mentals for trainset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "006f6687",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown-haired\n",
      "soft-boiled\n",
      "monetary\n",
      "historical\n",
      "faulty\n",
      "leisurely\n",
      "sanitized\n",
      "inconsiderable\n",
      "mnemonic\n",
      "wetter\n",
      "fleshly\n",
      "fewer\n",
      "humic\n",
      "lunatic\n",
      "maniacal\n",
      "indescribable\n",
      "milkier\n",
      "putative\n",
      "all-purpose\n",
      "ravenous\n",
      "moderate-size\n",
      "curricular\n",
      "disabled\n",
      "focused\n",
      "sundried\n",
      "21\n",
      "falsest\n",
      "rough-and-ready\n",
      "incorporated\n",
      "thoughtful\n",
      "angry\n",
      "bilious\n",
      "smallish\n",
      "honeyed\n",
      "time-release\n",
      "full-blown\n",
      "varicose\n",
      "material\n",
      "anticlimactic\n",
      "decayed\n",
      "received\n",
      "foul-smelling\n",
      "counter\n",
      "observed\n",
      "speedy\n",
      "folding\n",
      "hair-raising\n",
      "twisty\n",
      "pasted\n",
      "homemade\n",
      "stirring\n",
      "eccentric\n",
      "brazilian\n",
      "floral\n",
      "continual\n",
      "graduate\n",
      "tamed\n",
      "printable\n",
      "angled\n",
      "human-sized\n",
      "fulfilled\n",
      "convinced\n",
      "senegalese\n",
      "lacking\n",
      "coveted\n",
      "seedless\n",
      "justifiable\n",
      "second-rate\n",
      "thawed\n",
      "chock-full\n",
      "frontal\n",
      "under\n",
      "hard-baked\n",
      "wacky\n",
      "acetic\n",
      "deserving\n",
      "spiffy\n",
      "marvellous\n",
      "unmeasured\n",
      "missionary\n",
      "fifty-eight\n",
      "x\n",
      "devoid\n",
      "worldwide\n",
      "indecisive\n",
      "unwanted\n",
      "thirsty\n",
      "forgotten\n",
      "pastier\n",
      "petty\n",
      "pituitary\n",
      "sun-dried\n",
      "essential\n",
      "separable\n",
      "expected\n",
      "edwardian\n",
      "roundish\n",
      "rural\n",
      "dressed\n",
      "unstirred\n",
      "stuck\n",
      "stretchier\n",
      "purer\n",
      "plushy\n",
      "ocular\n",
      "rousing\n",
      "extralegal\n",
      "pointless\n",
      "unsatisfiable\n",
      "unused\n",
      "early\n",
      "curly-haired\n",
      "kinky\n",
      "stark\n",
      "expectable\n",
      "allusive\n",
      "sunniest\n",
      "psychotic\n",
      "uneatable\n",
      "entire\n",
      "svelte\n",
      "grave\n",
      "90\n",
      "greenest\n",
      "lyrical\n",
      "raucous\n",
      "graphical\n",
      "philosophical\n",
      "usable\n",
      "largish\n",
      "kiln-dried\n",
      "live\n",
      "timed\n",
      "magical\n",
      "indigestible\n",
      "taiwanese\n",
      "nutrient\n",
      "verbal\n",
      "perverse\n",
      "unseasoned\n",
      "scrub\n",
      "postprandial\n",
      "indelible\n",
      "impressed\n",
      "striking\n",
      "inert\n",
      "moldable\n",
      "gigantic\n",
      "alphabetical\n",
      "cut-rate\n",
      "unglazed\n",
      "raunchy\n",
      "drugged\n",
      "thicker\n",
      "existing\n",
      "shakeable\n",
      "unsecured\n",
      "republican\n",
      "biological\n",
      "wasted\n",
      "dented\n",
      "right\n",
      "low-pressure\n",
      "mature\n",
      "subdued\n",
      "lined\n",
      "announced\n",
      "funereal\n",
      "interwoven\n",
      "fibrous\n",
      "earthy\n",
      "norwegian\n",
      "unadventurous\n",
      "up\n",
      "contemplative\n",
      "elapsed\n",
      "sly\n",
      "obtrusive\n",
      "chaotic\n",
      "net\n",
      "trendier\n",
      "orange-colored\n",
      "dun\n",
      "blueish\n",
      "tilted\n",
      "pessimistic\n",
      "runaway\n",
      "factual\n",
      "perishable\n",
      "nonreturnable\n",
      "bacterial\n",
      "quintessential\n",
      "happy\n",
      "southeast\n",
      "gross\n",
      "sadest\n",
      "impotent\n",
      "large-scale\n",
      "part-time\n",
      "quieter\n",
      "dear\n",
      "veritable\n",
      "primordial\n",
      "autistic\n",
      "cyan\n",
      "elliptical\n",
      "undamaged\n",
      "bohemian\n",
      "committed\n",
      "medicinal\n",
      "adhesive\n",
      "queasy\n",
      "adjunct\n",
      "private\n",
      "cost-effective\n",
      "outright\n",
      "revitalized\n",
      "irritating\n",
      "pulpy\n",
      "rigid\n",
      "solvent\n",
      "standardized\n",
      "adored\n",
      "modified\n",
      "charismatic\n",
      "crazier\n",
      "milled\n",
      "hemolytic\n",
      "hand-me-down\n",
      "equine\n",
      "transcendental\n",
      "scrambled\n",
      "gouty\n",
      "restless\n",
      "glorious\n",
      "aquatic\n",
      "sublingual\n",
      "ruffled\n",
      "fragmented\n",
      "made-up\n",
      "vague\n",
      "staple\n",
      "unprecedented\n",
      "puffy\n",
      "eighty-nine\n",
      "quickest\n",
      "seared\n",
      "attractive\n",
      "sec\n",
      "municipal\n",
      "dome-shaped\n",
      "tougher\n",
      "deaf\n",
      "olden\n",
      "opposable\n",
      "foremost\n",
      "narrow\n",
      "world\n",
      "haitian\n",
      "unnatural\n",
      "working\n",
      "rich\n",
      "unabated\n",
      "all-important\n",
      "picky\n",
      "devoted\n",
      "covert\n",
      "jangling\n",
      "rectified\n",
      "fluid\n",
      "investigative\n",
      "forthright\n",
      "enlightening\n",
      "unrestrained\n",
      "tentative\n",
      "baking\n",
      "longish\n",
      "self-conscious\n",
      "unreal\n",
      "proverbial\n",
      "sneaking\n",
      "barbed\n",
      "poetic\n",
      "tartaric\n",
      "serendipitous\n",
      "productive\n",
      "thin-shelled\n",
      "biomedical\n",
      "adult\n",
      "nautical\n",
      "fired\n",
      "unexplained\n",
      "hawaiian\n",
      "il\n",
      "distasteful\n",
      "anticipated\n",
      "oratorical\n",
      "movable\n",
      "reddish\n",
      "synthetic\n",
      "stranger\n",
      "nervy\n",
      "bottom\n",
      "safe\n",
      "remarkable\n",
      "wood-fired\n",
      "gastric\n",
      "poached\n",
      "thirstier\n",
      "streamlined\n",
      "slowest\n",
      "hand-crafted\n",
      "crusted\n",
      "public\n",
      "shelled\n",
      "low-cost\n",
      "polish\n",
      "apart\n",
      "crystallized\n",
      "unseemly\n",
      "adipose\n",
      "blackened\n",
      "thrown\n",
      "pliable\n",
      "blasted\n",
      "sixty-six\n",
      "ironic\n",
      "crafty\n",
      "rigorous\n",
      "open-and-shut\n",
      "stretchy\n",
      "customary\n",
      "honorable\n",
      "pharmacological\n",
      "applied\n",
      "unaffiliated\n",
      "polite\n",
      "abundant\n",
      "pejorative\n",
      "stifled\n",
      "gracious\n",
      "circulatory\n",
      "embedded\n",
      "respected\n",
      "shut\n",
      "top-secret\n",
      "side-to-side\n",
      "unanswered\n",
      "symptomatic\n",
      "northwest\n",
      "cockeyed\n",
      "clearer\n",
      "ruddy\n",
      "brick-shaped\n",
      "dummy\n",
      "furtive\n",
      "fat-soluble\n",
      "professed\n",
      "paradoxical\n",
      "fragile\n",
      "half-dozen\n",
      "unkempt\n",
      "prudent\n",
      "discerning\n",
      "shallow\n",
      "uninfluenced\n",
      "cross-section\n",
      "dryer\n",
      "lame\n",
      "amateur\n",
      "running\n",
      "multicolored\n",
      "prostatic\n",
      "damp\n",
      "sinister\n",
      "rough-and-tumble\n",
      "allergenic\n",
      "furred\n",
      "knockout\n",
      "civil\n",
      "touristy\n",
      "driest\n",
      "ungenerous\n",
      "unsalted\n",
      "fetid\n",
      "lightweight\n",
      "deceased\n",
      "grammatical\n",
      "forty-six\n",
      "handsome\n",
      "boney\n",
      "challenging\n",
      "virile\n",
      "bubbling\n",
      "famed\n",
      "amorphous\n",
      "cordial\n",
      "pitted\n",
      "brand-new\n",
      "oblong\n",
      "spontaneous\n",
      "islamic\n",
      "dusky\n",
      "high-speed\n",
      "prosthetic\n",
      "napping\n",
      "hypertensive\n",
      "fugitive\n",
      "outdated\n",
      "uneconomical\n",
      "xx\n",
      "unapologetic\n",
      "unmemorable\n",
      "glued\n",
      "last-minute\n",
      "preferred\n",
      "miniature\n",
      "orthopedic\n",
      "salaried\n",
      "obsessive-compulsive\n",
      "undigested\n",
      "skinniest\n",
      "gleeful\n",
      "doubtful\n",
      "sorrel\n",
      "poignant\n",
      "toned\n",
      "scariest\n",
      "receptive\n",
      "jam-packed\n",
      "crumpled\n",
      "fundamental\n",
      "comical\n",
      "knobby\n",
      "autoimmune\n",
      "gargantuan\n",
      "banal\n",
      "flesh-colored\n",
      "determining\n",
      "thousand\n",
      "esthetic\n",
      "worrisome\n",
      "175\n",
      "shocked\n",
      "vivid\n",
      "wrinkled\n",
      "sloshed\n",
      "rusty\n",
      "disheartened\n",
      "reported\n",
      "future\n",
      "boneless\n",
      "discretionary\n",
      "problematic\n",
      "bleached\n",
      "structured\n",
      "gone\n",
      "pronounceable\n",
      "up-and-coming\n",
      "heretical\n",
      "embarrassing\n",
      "tolerant\n",
      "sculptured\n",
      "scrubby\n",
      "gamey\n",
      "ramous\n",
      "volatile\n",
      "magnetic\n",
      "bitterish\n",
      "bully\n",
      "hesitating\n",
      "unprocessed\n",
      "indistinguishable\n",
      "einsteinian\n",
      "rough-cut\n",
      "aqueous\n",
      "imperfect\n",
      "puff\n",
      "rounded\n",
      "sinless\n",
      "drizzly\n",
      "underfed\n",
      "discernible\n",
      "exposed\n",
      "unwitting\n",
      "octogenarian\n",
      "multi-coloured\n",
      "refreshed\n",
      "overt\n",
      "fainter\n"
     ]
    }
   ],
   "source": [
    "# add 50 more mentals\n",
    "\n",
    "rs_trainset2=random.sample(adj_cand,500)\n",
    "for w in rs_trainset2:\n",
    "    if w in rs_desc+rs_opin:\n",
    "        continue\n",
    "    else:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "96d35e8f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rs_opin=rs_opin+['ravenous','focused','thoughtful','angry','stirring','wacky','expected','unsatisfiable','expectable','allusive','psychotic','lyrical','philosophical','impressed','striking','pessimistic','happy','autistic','adored','irritating','charismatic','crazier','restless','attractive','picky','devoted','enlightening','anticipated','nervy','prudent','discerning','ungenerous','preferred','gleeful','doubtful','shocked','worrisome','embarrassing','tolerant','hesitating','unwitting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23bdacd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rs_opin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "06148668",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get 100 mentals and 100 physicals for training\n",
    "word_type='adj'\n",
    "rs_trainset=[]\n",
    "for w in rs_desc[:100]:\n",
    "    rs_trainset.append((w,wn_ext_defn(w,word_type),0)) # 0: physical\n",
    "for w in rs_opin[:100]:\n",
    "    rs_trainset.append((w,wn_ext_defn(w,word_type),1)) # 1: mental\n",
    "    \n",
    "    \n",
    "rs_train=pd.DataFrame()\n",
    "rs_train['word'],rs_train['text'],rs_train['target']=list(zip(*(rs_trainset)))\n",
    "\n",
    "rs_train=rs_train.sample(frac=1).reset_index(drop=True)\n",
    "rs_train.to_csv('Data/train.randomSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05bfa081",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fd93b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0101c56e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# use 120 words\n",
    "rs_train=pd.read_csv('Data/train.randomSample.csv')\n",
    "\n",
    "rs_train[:120].to_csv('Data/train.randomSample.r3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b19837",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Train model the same way as Section5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a150d5e7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.658\n",
      "positive::recall 0.694\n",
      "negative::precision 0.823\n",
      "negative::recall 0.797\n",
      "F1: 0.68\n",
      "N F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "\n",
    "pred=joblib.load('Data/pred.v5.12.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "265a6173",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.400\n",
      "positive::recall 0.833\n",
      "negative::precision 0.760\n",
      "negative::recall 0.297\n",
      "F1: 0.54\n",
      "N F1: 0.43\n"
     ]
    }
   ],
   "source": [
    "# another two runs. Only provide evaluations here.\n",
    "\n",
    "pred=joblib.load('Data/pred.v5.1.3.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bf50d4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.558\n",
      "positive::recall 0.667\n",
      "negative::precision 0.789\n",
      "negative::recall 0.703\n",
      "F1: 0.61\n",
      "N F1: 0.74\n"
     ]
    }
   ],
   "source": [
    "# another two runs. Only provide evaluations here.\n",
    "pred=joblib.load('Data/pred.v5.1.4.round3') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214fcc6a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b3712d12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rs_train[:160].to_csv('Data/train.randomSample.r4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae597d71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Train model the same way as Section5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9d4fa35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.750\n",
      "positive::recall 0.583\n",
      "negative::precision 0.792\n",
      "negative::recall 0.891\n",
      "F1: 0.66\n",
      "N F1: 0.84\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v5.2.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0155c7d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.724\n",
      "positive::recall 0.583\n",
      "negative::precision 0.789\n",
      "negative::recall 0.875\n",
      "F1: 0.65\n",
      "N F1: 0.83\n"
     ]
    }
   ],
   "source": [
    "# another two runs. Only provide evaluations here.\n",
    "pred=joblib.load('Data/pred.v5.22.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57555104",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.690\n",
      "positive::recall 0.556\n",
      "negative::precision 0.775\n",
      "negative::recall 0.859\n",
      "F1: 0.62\n",
      "N F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "# another two runs. Only provide evaluations here.\n",
    "pred=joblib.load('Data/pred.v5.2.4.round4') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c403ffd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iter5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6244a4af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rs_train[:200].to_csv('Data/train.randomSample.r5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b43a19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Train model the same way as Section5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4997f64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.792\n",
      "positive::recall 0.528\n",
      "negative::precision 0.776\n",
      "negative::recall 0.922\n",
      "F1: 0.63\n",
      "N F1: 0.84\n"
     ]
    }
   ],
   "source": [
    "pred=joblib.load('Data/pred.v5.3.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "afad70c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.667\n",
      "positive::recall 0.611\n",
      "negative::precision 0.791\n",
      "negative::recall 0.828\n",
      "F1: 0.64\n",
      "N F1: 0.81\n"
     ]
    }
   ],
   "source": [
    "# another two runs. Only provide evaluations here.\n",
    "pred=joblib.load('Data/pred.v5.33.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "946d31c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive::precision 0.610\n",
      "positive::recall 0.694\n",
      "negative::precision 0.814\n",
      "negative::recall 0.750\n",
      "F1: 0.65\n",
      "N F1: 0.78\n"
     ]
    }
   ],
   "source": [
    "# another two runs. Only provide evaluations here.\n",
    "pred=joblib.load('Data/pred.v5.32.round5') # load prediction result\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]\n",
    "\n",
    "\n",
    "testset['pred_score']=testset['word'].apply(lambda x: pred_dict[x])\n",
    "testset['pred_label']=testset['pred_score'].apply(lambda x: 1 if x>0.5 else 0)\n",
    "\n",
    "# positive::precision\n",
    "print(\"positive::precision %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]))\n",
    "print(\"positive::recall %.3f\"%(testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]))\n",
    "\n",
    "\n",
    "print(\"negative::precision %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]))\n",
    "print(\"negative::recall %.3f\"%(testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]))\n",
    "\n",
    "pp=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.pred_label==1)].shape[0]\n",
    "pr=testset.loc[(testset.pred_label==1)&(testset.target==1)].shape[0]/testset.loc[(testset.target==1)].shape[0]\n",
    "\n",
    "print(\"F1: %.2f\"%(2*pp*pr/(pp+pr)))\n",
    "\n",
    "np=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.pred_label==0)].shape[0]\n",
    "nr=testset.loc[(testset.pred_label==0)&(testset.target==0)].shape[0]/testset.loc[(testset.target==0)].shape[0]\n",
    "\n",
    "print(\"N F1: %.2f\"%(2*np*nr/(np+nr)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767ba37",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Annotate 80~100w/iter. Worse performance than HighEntropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce68cd9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e2d3c33c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred=joblib.load('Data/pred.v6.4.3.round4') # load prediction result. We use this version of prediction\n",
    "# as its precision and recall are more balanced.\n",
    "assert pred.shape[0]==adj.shape[0]\n",
    "\n",
    "pred_dict={}\n",
    "for i,w in enumerate(adj['word'].tolist()):\n",
    "    pred_dict[w]=pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8fda1610",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# >0.5, label as \"mental\", otherwise \"physical\"\n",
    "\n",
    "results={}\n",
    "for k,v in pred_dict.items():\n",
    "    results[k]='mental' if v>0.5 else 'physical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7888d7cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"Data/infer_mental_adj.json\", \"w\") as outfile:\n",
    "    json.dump(results, outfile)\n",
    "\n",
    "# load\n",
    "\"\"\"\n",
    "with open(\"Data/infer_sub_adj.json\", \"r\") as infile:\n",
    "    x=json.load(infile)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "525e3554",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3272078990674712\n"
     ]
    }
   ],
   "source": [
    "# mental ratio\n",
    "pos_cnt=0\n",
    "for w,c in results.items():\n",
    "    if c=='mental':\n",
    "        pos_cnt+=1\n",
    "print(pos_cnt/len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261f135b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compare with SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec9823",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "71196096",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentinet=pd.read_csv('Data/SentiWordNet3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6e5809c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>PosScore</th>\n",
       "      <th>NegScore</th>\n",
       "      <th>SynsetTerms</th>\n",
       "      <th>Gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>able#1</td>\n",
       "      <td>(usually followed by `to') having the necessar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>2098.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>unable#1</td>\n",
       "      <td>(usually followed by `to') not having the nece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dorsal#2 abaxial#1</td>\n",
       "      <td>facing away from the axis of an organ or organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>2527.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ventral#2 adaxial#1</td>\n",
       "      <td>nearest to or facing toward the axis of an org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>acroscopic#1</td>\n",
       "      <td>facing or on the side toward the apex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 POS      ID  PosScore  NegScore          SynsetTerms  \\\n",
       "0           0   a  1740.0     0.125      0.00               able#1   \n",
       "1           1   a  2098.0     0.000      0.75             unable#1   \n",
       "2           2   a  2312.0     0.000      0.00   dorsal#2 abaxial#1   \n",
       "3           3   a  2527.0     0.000      0.00  ventral#2 adaxial#1   \n",
       "4           4   a  2730.0     0.000      0.00         acroscopic#1   \n",
       "\n",
       "                                               Gloss  \n",
       "0  (usually followed by `to') having the necessar...  \n",
       "1  (usually followed by `to') not having the nece...  \n",
       "2  facing away from the axis of an organ or organ...  \n",
       "3  nearest to or facing toward the axis of an org...  \n",
       "4              facing or on the side toward the apex  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentinet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6535150",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117660, 7)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentinet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d83c6302",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentinet['ObjScore']=1-(sentinet['PosScore']+sentinet['NegScore'])\n",
    "\n",
    "SentiClass=[]\n",
    "for o,p,n in zip(sentinet['ObjScore'], sentinet['PosScore'], sentinet['NegScore']):\n",
    "    if max(o,p,n)==o:\n",
    "        SentiClass.append('obj')\n",
    "        continue\n",
    "    if max(o,p,n)==p:\n",
    "        SentiClass.append('pos')\n",
    "        continue\n",
    "    if max(o,p,n)==n:\n",
    "        SentiClass.append('neg')\n",
    "        continue\n",
    "    else:\n",
    "        SentiClass.append('unknown')\n",
    "\n",
    "sentinet['SentiClass']=SentiClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0eb7953f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get positive terms from sentinet\n",
    "senti_pos_set=set()\n",
    "for s in sentinet.loc[(sentinet.POS=='a')&(sentinet.SentiClass=='pos'),'SynsetTerms']:\n",
    "    for w in s.split(' '):\n",
    "        _w=w.split('#')[0]\n",
    "        senti_pos_set.add(_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "491d6437",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2098"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(senti_pos_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "022a22e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get negative terms from sentinet\n",
    "senti_neg_set=set()\n",
    "for s in sentinet.loc[(sentinet.POS=='a')&(sentinet.SentiClass=='neg'),'SynsetTerms']:\n",
    "    for w in s.split(' '):\n",
    "        _w=w.split('#')[0]\n",
    "        senti_neg_set.add(_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf746cbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3241"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(senti_neg_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f69b4e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get objective terms from sentinet\n",
    "senti_obj_set=set()\n",
    "for s in sentinet.loc[(sentinet.POS=='a')&(sentinet.SentiClass=='obj'),'SynsetTerms']:\n",
    "    for w in s.split(' '):\n",
    "        _w=w.split('#')[0]\n",
    "        senti_obj_set.add(_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "15cc348c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18241"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(senti_obj_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af08152f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "senti_words=senti_obj_set.union(senti_pos_set.union(senti_neg_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ceaabf11",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21479"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(senti_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b1df8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## GetWordSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc05b6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# If a word only appears in `senti_pos_set` or `senti_neg_set`, it is regarded as `Subjective`. \n",
    "# If a word only appears in `senti_obj_set`, it is regarded as `Objective`. \n",
    "# If a word appears both in `senti_obj_set` and union(`senti_pos_set`, `senti_neg_set`), \n",
    "# it is regarded as `Dual`, which means this word could bear subjective or objective meanings under different\n",
    "# contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2caf6d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pure_senti_sub_set=(senti_pos_set.union(senti_neg_set)).difference(senti_obj_set)\n",
    "\n",
    "pure_senti_obj_set=senti_obj_set.difference(senti_pos_set.union(senti_neg_set))\n",
    "\n",
    "dual_senti_set=(senti_pos_set.union(senti_neg_set)).intersection(senti_obj_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c33dd2e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total adjectives in sentinet: 21479\n",
      "Subjective adjective ratio: 15.08%\n",
      "Objective adjective ratio: 76.38%\n",
      "Dual adjective ratio: 8.54%\n"
     ]
    }
   ],
   "source": [
    "print(\"Total adjectives in sentinet: %d\"%(len(pure_senti_sub_set)+len(pure_senti_obj_set)+len(dual_senti_set)))\n",
    "\n",
    "print(\"Subjective adjective ratio: %.2f%%\"%(100*len(pure_senti_sub_set)/(len(pure_senti_sub_set)+len(pure_senti_obj_set)+len(dual_senti_set))))\n",
    "\n",
    "print(\"Objective adjective ratio: %.2f%%\"%(100*len(pure_senti_obj_set)/(len(pure_senti_sub_set)+len(pure_senti_obj_set)+len(dual_senti_set))))\n",
    "\n",
    "print(\"Dual adjective ratio: %.2f%%\"%(100*len(dual_senti_set)/(len(pure_senti_sub_set)+len(pure_senti_obj_set)+len(dual_senti_set))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245166a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95368075",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# distribution of Subjective, Objective and Dual adjectives in Mental and Physical classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cafb68b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mental_set=set()\n",
    "for w,c in results.items():\n",
    "    if c=='mental':\n",
    "        mental_set.add(w)\n",
    "        \n",
    "physical_set=set()\n",
    "for w,c in results.items():\n",
    "    if c=='physical':\n",
    "        physical_set.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "25530c09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjective in Mental adjs: 28.08%\n",
      "Obj in Mental adjs: 43.00%\n",
      "Dual polarity in Mental adjs: 28.92%\n"
     ]
    }
   ],
   "source": [
    "mental_obj=mental_set.intersection(pure_senti_obj_set)\n",
    "mental_sub=mental_set.intersection(pure_senti_sub_set)\n",
    "mental_dual=mental_set.intersection(dual_senti_set)\n",
    "\n",
    "# process miss words due to comparative format\n",
    "mental_miss=set()\n",
    "for w in mental_set:\n",
    "    if w in mental_obj or w in mental_sub or w in mental_dual:\n",
    "        pass\n",
    "    else:\n",
    "        mental_miss.add(w)\n",
    "\n",
    "mental_obj_c=set()\n",
    "mental_sub_c=set()\n",
    "mental_dual_c=set()\n",
    "\n",
    "# get word prototype\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for w in mental_miss:\n",
    "    _w=lemmatizer.lemmatize(w,pos='a')\n",
    "    if _w in pure_senti_obj_set:\n",
    "        mental_obj_c.add(w)\n",
    "    elif _w in pure_senti_sub_set:\n",
    "        mental_sub_c.add(w)\n",
    "    elif _w in dual_senti_set:\n",
    "        mental_dual_c.add(w)\n",
    "    else:\n",
    "        print(w)\n",
    "        \n",
    "print(\"Subjective in Mental adjs: %.2f%%\"%(100*len(mental_sub.union(mental_sub_c))/(len(mental_set))))\n",
    "\n",
    "print(\"Obj in Mental adjs: %.2f%%\"%(100*len(mental_obj.union(mental_obj_c))/(len(mental_set))))\n",
    "\n",
    "print(\"Dual polarity in Mental adjs: %.2f%%\"%(100*len(mental_dual.union(mental_dual_c))/(len(mental_set))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "032ed3ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "Subjective in Physical adjs: 9.13%\n",
      "Obj in Physical adjs: 74.40%\n",
      "Dual polarity in Physical adjs: 16.45%\n"
     ]
    }
   ],
   "source": [
    "phy_obj=physical_set.intersection(pure_senti_obj_set)\n",
    "phy_sub=physical_set.intersection(pure_senti_sub_set)\n",
    "phy_dual=physical_set.intersection(dual_senti_set)\n",
    "\n",
    "phy_miss=set()\n",
    "for w in physical_set:\n",
    "    if w in phy_obj or w in phy_sub or w in phy_dual:\n",
    "        pass\n",
    "    else:\n",
    "        phy_miss.add(w)\n",
    "print(len(phy_miss))\n",
    "\n",
    "# process comparatives\n",
    "phy_obj_c=set()\n",
    "phy_sub_c=set()\n",
    "phy_dual_c=set()\n",
    "\n",
    "# get word prototype\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for w in phy_miss:\n",
    "    if (not isinstance(w,str)) and numpy.isnan(w):\n",
    "        continue\n",
    "    _w=lemmatizer.lemmatize(w,pos='a')\n",
    "    if _w in pure_senti_obj_set:\n",
    "        phy_obj_c.add(w)\n",
    "    elif _w in pure_senti_sub_set:\n",
    "        phy_sub_c.add(w)\n",
    "    elif _w in dual_senti_set:\n",
    "        phy_dual_c.add(w)\n",
    "    else:\n",
    "        print(w)\n",
    "        \n",
    "print(\"Subjective in Physical adjs: %.2f%%\"%(100*len(phy_sub.union(phy_sub_c))/(len(physical_set))))\n",
    "\n",
    "print(\"Obj in Physical adjs: %.2f%%\"%(100*len(phy_obj.union(phy_obj_c))/(len(physical_set))))\n",
    "\n",
    "print(\"Dual polarity in Physical adjs: %.2f%%\"%(100*len(phy_dual.union(phy_dual_c))/(len(physical_set))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2715e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    From the above distributions, we find that 43% of the Mental adjs are labeled as objectives in sentiwordnet. This indicates the definition of Mental/Physical is different from Subjective/Objective in sentiment analysis task. In fact, many objective words bear mental functionalities. We show word examples below in six categories: emotion, motive, perceiving, reasoning, planning and personality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035015a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get mental-objective adj\n",
    "for w in mental_obj:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4060f61",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "    Emotion: favored, scorned, trustworthy, frisky, gripping, stilted\n",
    "    \n",
    "    Need: devout, deserving, hired, protective, wealthy, rewarding\n",
    "    \n",
    "    Perceive: sensuous, ubiquitous, instinctive, detected, recognized, perceivable\n",
    "    \n",
    "    Reason: suitable, predominate, substandard, critical, relevant, causal\n",
    "    \n",
    "    Plan: committed, aimless, exploited, unplanned, purposeful, executed\n",
    "  \n",
    "    Personality: whimsical, squeamish, entrepreneurial, punctual, shy, intrepid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a768c64",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "229.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}